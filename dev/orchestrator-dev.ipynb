{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-03T03:07:45.011596Z",
     "start_time": "2021-04-03T03:07:45.008460Z"
    }
   },
   "source": [
    "# Orchestrator development notebook\n",
    "Juan-Carlos Maureira<br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-10T06:25:01.734842Z",
     "start_time": "2021-04-10T06:25:01.732546Z"
    },
    "heading_collapsed": true
   },
   "source": [
    "## Deployment environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-18T20:33:27.073939Z",
     "start_time": "2024-04-18T20:33:27.047180Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "from IPython.core.magic import register_cell_magic\n",
    "\n",
    "deploy_path=\"../lib/python\"\n",
    "sys.path.insert(0, os.path.abspath(deploy_path))\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "@register_cell_magic\n",
    "def deploy(target, cell):\n",
    "    'deploy classes coded in the cell'\n",
    "    \n",
    "    full_target = \"%s/%s\" % (deploy_path,target)\n",
    "    if not os.path.exists(os.path.dirname(full_target)):\n",
    "        os.makedirs(os.path.dirname(full_target))\n",
    "        init_file = \"'%s/__init__.py\" % os.path.dirname(full_target)\n",
    "        if not os.path.exists(init_file):\n",
    "            open(init_file,\"w\").close()\n",
    "    \n",
    "    with open(full_target, 'wt') as fd:\n",
    "        fd.write(cell)\n",
    "\n",
    "class StopExecution(Exception):\n",
    "    def _render_traceback_(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-18T20:33:27.238829Z",
     "start_time": "2024-04-18T20:33:27.076461Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4115672/955362447.py:4: DeprecationWarning: Importing display from IPython.core.display is deprecated since IPython 7.14, please import from IPython display\n",
      "  from IPython.core.display import display, HTML\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#from orch.base import *\n",
    "import requests\n",
    "\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-27T03:40:23.774364Z",
     "start_time": "2022-03-27T03:40:23.771690Z"
    }
   },
   "source": [
    "## Base Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-18T20:33:27.306260Z",
     "start_time": "2024-04-18T20:33:27.241349Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "%%deploy /orch/base/slurm.py\n",
    "import sys\n",
    "import subprocess\n",
    "import time\n",
    "import select\n",
    "import os\n",
    "import re\n",
    "import dill\n",
    "import pickle\n",
    "import json\n",
    "import io\n",
    "\n",
    "from .AVROCodec import AVROCodec\n",
    "from ._async import *\n",
    "from .SerializedObject import *\n",
    "\n",
    "from taskit.frontend import FrontEnd, BackendNotAvailableError\n",
    "from taskit.log import FileLogger, DEBUG, INFO, ERROR\n",
    "\n",
    "from threading import Thread, Event\n",
    "\n",
    "from promise import Promise\n",
    "import traceback\n",
    "import tempfile\n",
    "\n",
    "from .AbstractJob import AbstractJob\n",
    "\n",
    "import requests\n",
    "import json\n",
    "\n",
    "import traceback\n",
    "import pandas as pd\n",
    "\n",
    "class SlurmController(object):\n",
    "    BATCH_BIN  = \"/usr/bin/sbatch\"\n",
    "    SRUN_BIN    = \"/usr/bin/srun\"\n",
    "    SCANCEL_BIN = \"/usr/bin/scancel\"\n",
    "    SQUEUE_BIN  = \"/usr/bin/squeue\"\n",
    "\n",
    "    def __init__(self, job):\n",
    "        self.job = job\n",
    "\n",
    "    def squeue(self, steps=False):\n",
    "\n",
    "        squeue_args = ['-o','%all']\n",
    "        if steps:\n",
    "            squeue_args.append('-s')\n",
    "\n",
    "        result = subprocess.run([self.SQUEUE_BIN] + squeue_args, stdout=subprocess.PIPE, shell=False, universal_newlines = True)\n",
    "        output = result.stdout\n",
    "\n",
    "        lines = output.split('\\n')\n",
    "        header_line = lines.pop(0)\n",
    "        header_cols = header_line.split('|')\n",
    "        entries = []\n",
    "        error_lines = [] # do something with this later\n",
    "        for line in lines:\n",
    "            parts = line.split('|')\n",
    "            d = {}\n",
    "            if len(parts) != len(header_cols):\n",
    "                error_lines.append((len(parts), line, parts))\n",
    "            else:\n",
    "                for i, key in enumerate(header_cols):\n",
    "                    if key not in d:\n",
    "                        d[key] = parts[i]\n",
    "            if d:\n",
    "                entries.append(d)\n",
    "        df = pd.DataFrame(entries, columns=header_cols)\n",
    "        df = df.loc[:,~df.columns.duplicated()]\n",
    "        return df\n",
    "\n",
    "    def cancel(self, job_id, steps=False):\n",
    "        df = self.squeue(steps=steps)\n",
    "        if df.loc[df.JOBID==job_id].shape[0]>0:\n",
    "            result = subprocess.run([self.SCANCEL_BIN,job_id], stdout=subprocess.PIPE, shell=False, universal_newlines = True)\n",
    "            if result.returncode==0:\n",
    "                return True\n",
    "            return False\n",
    "        else:\n",
    "            # job_id not in squeue\n",
    "            return False\n",
    "\n",
    "    def getJobInfo(self, job_id, steps=False):\n",
    "        df = self.squeue(steps=steps)\n",
    "\n",
    "        df_job = df.loc[df.JOBID==job_id]\n",
    "        if df_job.shape[0]>0:\n",
    "            return json.loads(df_job.iloc[0].to_json())\n",
    "\n",
    "        return None\n",
    "\n",
    "    def getJobByName(self,job_name, last=False, steps=False):\n",
    "        df = self.squeue(steps=steps)\n",
    "        df_job = df.loc[df.NAME==job_name]\n",
    "        if df_job.shape[0]>0:\n",
    "            return json.loads(df_job.to_json(orient=\"records\"))\n",
    "\n",
    "        return None\n",
    "\n",
    "class Job(AbstractJob):\n",
    "\n",
    "    SBATCH_BIN  = \"/usr/bin/sbatch\"\n",
    "    SRUN_BIN    = \"/usr/bin/srun\"\n",
    "    SCANCEL_BIN = \"/usr/bin/scancel\"\n",
    "    SQUEUE_BIN  = \"/usr/bin/squeue\"\n",
    "\n",
    "    tmp_stdout  = \"./.orch_jobs\"\n",
    "\n",
    "    def __init__(self, params={}):\n",
    "        super().__init__(params)\n",
    "\n",
    "        self.job_id        = None\n",
    "        self.step_id       = None\n",
    "        self.job           = None\n",
    "        self.worker_port   = None\n",
    "        self.host          = None\n",
    "\n",
    "        self._exec_hdl     = None\n",
    "        self.result        = None\n",
    "\n",
    "        self.log_handler   = None\n",
    "\n",
    "        self.max_retry     = 180\n",
    "        self.exception     = None\n",
    "\n",
    "    def __deployBackend(self,function,lock):\n",
    "\n",
    "        print(\"starting deploy of backend\")\n",
    "\n",
    "        cmd = []\n",
    "\n",
    "        steps = False\n",
    "        if not self.as_job:\n",
    "            cmd = [ self.SRUN_BIN, ]\n",
    "            steps = True\n",
    "        else:\n",
    "            cmd = [ self.SBATCH_BIN, ]\n",
    "\n",
    "        # add this when inside a job allocation\n",
    "\n",
    "        if not self.as_job:\n",
    "            if \"SLURM_JOB_ID\" in os.environ:\n",
    "                if self.exclusive:\n",
    "                    cmd.append(\"--exclusive\")\n",
    "\n",
    "                cmd.append(\"--export=ALL\")\n",
    "                cmd.append(\"--unbuffered\")\n",
    "            else:\n",
    "                cmd.append(\"--export=ALL\")\n",
    "                cmd.append(\"--unbuffered\")\n",
    "        else:\n",
    "            cmd.append(\"--export=ALL\")\n",
    "\n",
    "        for key,value in self.params.items():\n",
    "\n",
    "            if key==\"cores\":\n",
    "                key = \"cpus-per-task\"\n",
    "            if key==\"name\":\n",
    "                key = \"job-name\"\n",
    "            if key==\"verbose\":\n",
    "                continue\n",
    "            if key==\"output\":\n",
    "                continue\n",
    "\n",
    "            cmd.append(\"--%s=%s\" % (key,value))\n",
    "\n",
    "        cmd.append(\"%s\")\n",
    "\n",
    "        orch_py=\"'from bupacl.orch.base import Worker; Worker().run()'\"\n",
    "\n",
    "        cmd_py = []\n",
    "\n",
    "        cmd_py.append('python3.9')\n",
    "        cmd_py.append('-u')\n",
    "        cmd_py.append('-c')\n",
    "        cmd_py.append(orch_py)\n",
    "\n",
    "        std_out = \"\"\n",
    "\n",
    "        if self.as_job:\n",
    "            if not os.path.exists(self.tmp_stdout):\n",
    "                os.makedirs(self.tmp_stdout, exist_ok=True)\n",
    "\n",
    "            std_out = tempfile.NamedTemporaryFile(dir=self.tmp_stdout,delete=False).name\n",
    "            worker_cmd = \"--wait -o %s --wrap=\\\"%s\\\"\" % (std_out,\" \".join(cmd_py))\n",
    "            cmd_str = \" \".join(cmd) % worker_cmd\n",
    "        else:\n",
    "            cmd_str = \" \".join(cmd) % \" \".join(cmd_py)\n",
    "\n",
    "        #print(\"cmd:\",cmd_str)\n",
    "        #print(\"as_job:\",self.as_job)\n",
    "\n",
    "        proc = subprocess.Popen(cmd_str, shell=True,stdout=subprocess.PIPE, stderr=subprocess.STDOUT)\n",
    "\n",
    "        poll = select.poll()\n",
    "        r    = proc.poll()\n",
    "\n",
    "        if r is not None and r != 0:\n",
    "            self.exception=RuntimeError(\"srun command failed with exit code %d\" % r)\n",
    "            lock.set()\n",
    "            return\n",
    "\n",
    "        event_mask = select.POLLIN | select.POLLERR | select.POLLHUP | select.EPOLLIN | select.EPOLLPRI\n",
    "\n",
    "        # check for node allocation status\n",
    "        slurm_ctrl = SlurmController(self)\n",
    "        #print(self.params)\n",
    "\n",
    "        if self.as_job:\n",
    "           print(\"running as job\") \n",
    "\n",
    "        for retry in range(0,10):\n",
    "            #print(\"waiting job info %s\" % self.params[\"job-name\"])\n",
    "            job_info_lst = slurm_ctrl.getJobByName(self.params[\"job-name\"],steps=steps)\n",
    "            if job_info_lst is None:\n",
    "                time.sleep(10)\n",
    "            else:\n",
    "                break\n",
    "\n",
    "        if job_info_lst is None:\n",
    "            self.exception=RuntimeError(\"Could not get jobinfo from slurm\")\n",
    "            lock.set()\n",
    "            return \n",
    "\n",
    "        job_info = job_info_lst[-1]  # get the last job in the list\n",
    "        job_id = None\n",
    "        if self.as_job:\n",
    "            job_id = job_info[\"JOBID\"]\n",
    "        else:\n",
    "            job_id = job_info[\"STEPID\"]\n",
    "\n",
    "        wait_time = 10 # segs\n",
    "        is_running = False\n",
    "        if self.as_job:\n",
    "            for retry in range(0,60):\n",
    "                print(\"waiting for job\")\n",
    "                job_info = slurm_ctrl.getJobByName(self.params[\"job-name\"],steps=steps)[-1]  # get the last job in the list\n",
    "                #print(\"job_info:\",job_info)\n",
    "                if job_info[\"STATE\"]==\"RUNNING\":\n",
    "                    is_running = True\n",
    "                    break\n",
    "                time.sleep(wait_time)\n",
    "\n",
    "            if not is_running:\n",
    "                print(\"Worker job not running after 600 segs\")\n",
    "                slurm_ctrl.cancel(job_id)\n",
    "                self.exception = RuntimeError(\"Worker job not running after 300 segs\")\n",
    "                lock.set()\n",
    "                return\n",
    "        else:\n",
    "            #job step\n",
    "            pass\n",
    "\n",
    "        stdout_handler = None\n",
    "        if self.as_job:\n",
    "            retry_count = 0\n",
    "            while not os.path.exists(std_out):\n",
    "                time.sleep(1)\n",
    "                retry_count+=1\n",
    "                if retry_count > self.max_retry:\n",
    "                    self.exception=RuntimeError(\"Submitted job was not executed in %d seconds\" % self.max_retry)\n",
    "                    lock.set()\n",
    "                    return\n",
    "\n",
    "            stdout_handler = open(std_out,\"r\")\n",
    "        else:\n",
    "            stdout_handler = proc.stdout.fileno()\n",
    "\n",
    "        poll.register(stdout_handler, event_mask)\n",
    "\n",
    "        regex=\"JOBID: ([0-9]*) STEP: ([0-9]*) PORT: ([0-9]*) HOST: (.*)\"\n",
    "        prog = re.compile(regex,re.MULTILINE|re.DOTALL)\n",
    "        self.host=\"worker\"\n",
    "\n",
    "        while proc.poll() is None:\n",
    "            events = poll.poll(1)\n",
    "            if events is None:\n",
    "                time.sleep(1)\n",
    "                continue;\n",
    "\n",
    "            for fd, event in events:\n",
    "                if event & select.POLLERR:\n",
    "                    poll_active = False\n",
    "                    break\n",
    "                os.fsync(fd)\n",
    "                if (event & select.POLLIN) or (event & select.POLLHUP):\n",
    "                    data = os.read(fd, 10240)\n",
    "                    if data.decode(errors='replace') == '':\n",
    "                        continue\n",
    "                    lines = data.strip().splitlines()\n",
    "                    for line in lines:\n",
    "                        if self.verbose and self.host!=\"worker\":\n",
    "                            print(\"** %s %d ** %s\" % (self.host, self.job_id, line.decode()),flush=True)\n",
    "\n",
    "                        if self.job_log is not None and self.host!=\"worker\":\n",
    "                            if self.log_handler is None:\n",
    "                                log_file = self.job_log.replace(\"%J\", str(self.job_id))\n",
    "                                if self.step_id is not None:\n",
    "                                    log_file = log_file.replace(\"%S\", str(self.step_id))\n",
    "                                # create the job logfile\n",
    "                                self.log_handler = open(log_file,'w')\n",
    "\n",
    "                            self.log_handler.write(\"%s\\n\" % line.decode())\n",
    "\n",
    "                        #TODO: capture just the first occurence and then discard further headers of prog regex\n",
    "                        m = prog.match(line.decode())\n",
    "\n",
    "                        if m is not None:\n",
    "                            job_id       = int(m.group(1))\n",
    "                            step_id      = int(m.group(2))\n",
    "                            worker_port  = int(m.group(3))\n",
    "                            self.host    = m.group(4)\n",
    "\n",
    "                            if worker_port>0:\n",
    "                                self.worker_port = worker_port\n",
    "                            else:\n",
    "                                self.exception=RuntimeError(\"Returned Worker Port unavailable\")\n",
    "                                lock.set()\n",
    "                                return\n",
    "\n",
    "                            if job_id>0:\n",
    "                                self.job_id = job_id\n",
    "                                self.job = {}\n",
    "\n",
    "                                if self.as_job:\n",
    "                                     self.job[\"batch_host\"] = self.host\n",
    "                                else:\n",
    "                                    self.step_id = step_id\n",
    "                                    self.job[\"node_list\"] = self.host\n",
    "\n",
    "                            else:\n",
    "                                self.exception=RuntimeError(\"Returned JobID is not a number\")\n",
    "                                lock.set()\n",
    "                                return\n",
    "\n",
    "                            lock.set()\n",
    "                            print(\"backend ready \",job_id, self.host)\n",
    "                            break\n",
    "\n",
    "                        if len(line) == 0:\n",
    "                            break\n",
    "\n",
    "        #print(\"waiting for backend to finish\")\n",
    "        exit_code = proc.poll()\n",
    "\n",
    "        if self.log_handler is not None:\n",
    "            self.log_handler.close()\n",
    "\n",
    "        if exit_code>0:\n",
    "            if self.verbose:\n",
    "                #print(\"backend exit_code %d\" % exit_code);\n",
    "                #if self.as_job:\n",
    "                    #print(stdout_handler.read())\n",
    "                #else:\n",
    "                    #print(proc.stdout.read())\n",
    "                pass\n",
    "            lock.set()\n",
    "        else:\n",
    "            if self.as_job:\n",
    "                if self.verbose:\n",
    "                    #print(stdout_handler.read())\n",
    "                    pass\n",
    "                stdout_handler.close()\n",
    "                os.remove(std_out)\n",
    "\n",
    "    def execute(self,function,*args):\n",
    "        @Async\n",
    "        def _exec(function,*args):\n",
    "            result = None\n",
    "            lock = Event()\n",
    "\n",
    "            # deploy the backend\n",
    "            t = Thread(target=self.__deployBackend, args=(function,lock))\n",
    "            t.start()\n",
    "            print(\"waiting for backend\")\n",
    "            lock.wait()\n",
    "            if self.job is not None:\n",
    "                print(\"starting frontend\")\n",
    "                try:\n",
    "                    if self.as_job:\n",
    "                        backend_addr = self.job[\"batch_host\"]\n",
    "                    else:\n",
    "                        backend_addr = self.job[\"node_list\"]\n",
    "\n",
    "                    print(\"Worker running at %s : %d \" % (backend_addr,self.worker_port))\n",
    "                    #log = FileLogger(sys.stdout,[ERROR])\n",
    "\n",
    "                    frontend = FrontEnd([backend_addr],default_port=self.worker_port, codec=bupacl.orch.base.AVROCodec)\n",
    "\n",
    "                    retry = 0\n",
    "                    retry_time = 1\n",
    "                    while retry<5:\n",
    "                        # getting a handle for the function to work with\n",
    "                        fn = None\n",
    "                        try:\n",
    "                            fn = function\n",
    "                        except Exception as e:\n",
    "                            print(\"Error getting the function to call: %s\" % function)\n",
    "                            print(e)\n",
    "                            break\n",
    "                        # unwrap the function if it is wrapped in an AsyncCall\n",
    "                        if isinstance(fn,ThreadAsyncMethod) or isinstance(fn,ProcessAsyncMethod):\n",
    "                            fn = fn.Callable\n",
    "                        # serialize the function\n",
    "                        code_string = dill.dumps(fn)\n",
    "                        # build the function_calller argument to pass the function and the args\n",
    "                        func_handler = {\"func\": code_string, \"name\": fn.__name__, \"args\": args }\n",
    "                        try:\n",
    "                            h = frontend.work('function_caller',func_handler)\n",
    "                            self.result = h\n",
    "                            break;\n",
    "                        except BackendNotAvailableError:\n",
    "                            time.sleep(retry_time)\n",
    "                            retry=retry+1\n",
    "                        except Exception as e:\n",
    "                            print(\"Frontend received exception from backend: \",e)\n",
    "                            self.result = e\n",
    "                            break;\n",
    "\n",
    "                    print(\"sending stop signal to backend %s\" % backend_addr)\n",
    "                    frontend.send_stop(backend_addr)\n",
    "                    t.join()\n",
    "                    return self.result\n",
    "                except Exception as e:\n",
    "                    print(\"exception when sending function to backend: \", e)\n",
    "                    # capture the stacktrace\n",
    "                    st = io.StringIO()\n",
    "                    traceback.print_exc(file=st)\n",
    "                    st.seek(0)\n",
    "                    st_str = st.read()\n",
    "                    self.result = \"%s\\n%s\" % (e, st_str )\n",
    "                    print(\"error read from backend:\",st_str)\n",
    "                    # cancel the job\n",
    "                    job_id = self.job_id\n",
    "                    subprocess.check_output([self.SCANCEL_BIN,\"%d\" % job_id])\n",
    "                    return self.result\n",
    "            else:\n",
    "                self.result = self.exception\n",
    "                return self.result\n",
    "\n",
    "        self._exec_hdl = _exec(function,*args)\n",
    "\n",
    "        return self._exec_hdl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-18T20:33:27.394320Z",
     "start_time": "2024-04-18T20:33:27.308056Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "%%deploy /orch/loggers/__init__.py\n",
    "import logging\n",
    "from logging import warning, info\n",
    "from logging.config import fileConfig\n",
    "import sys\n",
    "\n",
    "class NullLogger:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    def info(*args,**kwargs):\n",
    "        pass\n",
    "    def warning(*args,**kwargs):\n",
    "        pass\n",
    "    def error(*args,**kwargs):\n",
    "        pass\n",
    "    def critical(*args,**kwargs):\n",
    "        pass\n",
    "    def debug(*args,**kwargs):\n",
    "        pass\n",
    "    \n",
    "class BasicLogger:\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        logging.basicConfig(format='%(asctime)s | %(levelname)s : %(message)s',level=logging.INFO, stream=sys.stdout)\n",
    "        self.logger = logging.getLogger(self.name)\n",
    "        \n",
    "    def info(self,*args,**kwargs):\n",
    "        self.logger.info(*args,**kwargs)\n",
    "    def critical(self,*args,**kwargs):\n",
    "        self.logger.critical(*args,**kwargs)\n",
    "    def warning(self,*args,**kwargs):\n",
    "        self.logger.warning(*args,**kwargs)\n",
    "    def error(self,*args,**kwargs):\n",
    "        self.logger.error(*args,**kwargs)\n",
    "    def debug(self,*args,**kwargs):\n",
    "        self.logger.debug(*args,**kwargs)\n",
    "\n",
    "class FileLogger:\n",
    "    def __init__(self, name, config_file=\"etc/logging.ini\", logfile=\"logs/orchestrator.log\"):\n",
    "        self.name = name\n",
    "        fileConfig(config_file)\n",
    "        self.logger = logging.getLogger(self.name)\n",
    "\n",
    "    def info(self,*args,**kwargs):\n",
    "        self.logger.info(*args,**kwargs)\n",
    "    def critical(self,*args,**kwargs):\n",
    "        self.logger.critical(*args,**kwargs)\n",
    "    def warning(self,*args,**kwargs):\n",
    "        self.logger.warning(*args,**kwargs)\n",
    "    def error(self,*args,**kwargs):\n",
    "        self.logger.error(*args,**kwargs)\n",
    "    def debug(self,*args,**kwargs):\n",
    "        self.logger.debug(*args,**kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-18T20:33:27.474744Z",
     "start_time": "2024-04-18T20:33:27.396968Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "%%deploy /orch/base/PersistentDict.py\n",
    "import shelve\n",
    "import os\n",
    "from multiprocessing import Lock\n",
    "\n",
    "class PersistentDict():\n",
    "\n",
    "    def _openDict(self):\n",
    "        mode = \"w\"\n",
    "        if not os.path.exists(self.storage_file):\n",
    "            mode = \"c\"\n",
    "\n",
    "        h = shelve.open(self.storage_file, flag=mode)\n",
    "\n",
    "        return h\n",
    "\n",
    "    def __init__(self, storage_file=\"./.persistentdict/storage.dbm\"):\n",
    "        self.storage_file = storage_file\n",
    "\n",
    "        if not os.path.exists(os.path.dirname(storage_file)):\n",
    "            os.makedirs(os.path.dirname(storage_file))\n",
    "\n",
    "        self.lock = Lock()\n",
    "\n",
    "    def get(self, key):\n",
    "\n",
    "        with self.lock:\n",
    "            db = self._openDict()\n",
    "            value = db[key]\n",
    "            db.close()\n",
    "\n",
    "        return value\n",
    "\n",
    "    def mput(self,key,value, debug=False):\n",
    "\n",
    "        with self.lock:\n",
    "            db = self_openDict()\n",
    "            if key in db:\n",
    "                tval = db[key]\n",
    "                if isinstance(tval,list):\n",
    "                    if debug:\n",
    "                        print(\"key %s has already multiple values %s. adding new value\" % (key, tval))\n",
    "                    if value not in tval:\n",
    "                        tval.append(value)\n",
    "                        db[key] = tval\n",
    "                else:\n",
    "                    if debug:\n",
    "                        print(\"key %s is transformed in multiple values %s\" % (key, tval))\n",
    "\n",
    "                    if tval != value:\n",
    "                        nval = [ tval, value ]\n",
    "                        db[key] = nval\n",
    "\n",
    "            else:\n",
    "                db[key] = value\n",
    "\n",
    "            db.close()\n",
    "\n",
    "        return\n",
    "\n",
    "    def put(self,key,value):\n",
    "        with self.lock:\n",
    "            db = self._openDict()\n",
    "            db[key] = value\n",
    "            db.close()\n",
    "\n",
    "    def exists(self, key):\n",
    "        found = False\n",
    "        with self.lock:\n",
    "            db = self._openDict()\n",
    "            found = key in db\n",
    "            db.close()\n",
    "\n",
    "        return found\n",
    "\n",
    "\n",
    "    def keys(self):\n",
    "        keys = []\n",
    "        with self.lock:\n",
    "            db = self._openDict()\n",
    "            keys = db.keys()\n",
    "            db.close()\n",
    "\n",
    "        return keys\n",
    "\n",
    "    def updateFromTable(self,table,key=None,value=None, allow_multiple_values = False, debug=False):\n",
    "        for idx,row in table.iterrows():\n",
    "            t_key   = row[key]\n",
    "            if t_key.strip()==\"\":\n",
    "                continue\n",
    "            t_value = row[value]\n",
    "            if allow_multiple_values:\n",
    "                self.mput(t_key,t_value, debug=debug)\n",
    "            else:\n",
    "                self.put(t_key,t_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-18T20:33:27.583773Z",
     "start_time": "2024-04-18T20:33:27.476428Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "%%deploy /orch/base/AbstractApiService.py\n",
    "\n",
    "from flask import Flask, render_template, request, jsonify\n",
    "from threading import Thread, Condition\n",
    "from werkzeug.serving import make_server\n",
    "\n",
    "from ..loggers import NullLogger\n",
    "\n",
    "class AbstractApiService(Thread):\n",
    "    def __init__(self,api_name, bind_addr=\"127.0.0.1\", bind_port=8010, templates=None):\n",
    "        Thread.__init__(self)\n",
    "        self.api_name  = api_name\n",
    "        self.bind_addr = bind_addr\n",
    "        self.bind_port = bind_port\n",
    "\n",
    "        self.api       = Flask(api_name, template_folder=templates)\n",
    "        self.srv       = None\n",
    "        self.logger    = NullLogger()\n",
    "        self.running   = False\n",
    "\n",
    "        self.cv        = None\n",
    "        \n",
    "    def __del__(self):\n",
    "        self.stopService()\n",
    "    \n",
    "    def isRunning(self):\n",
    "        return self.running\n",
    "        \n",
    "    def setLogger(self, logger):        \n",
    "        self.logger = logger\n",
    "\n",
    "    def addRule(self, url, name, callback, **kwargs):\n",
    "        self.api.add_url_rule(url, name, callback,**kwargs)\n",
    "\n",
    "    def wait(self):\n",
    "        self.cv = Condition()\n",
    "        with self.cv:\n",
    "            self.cv.wait()\n",
    "            return True\n",
    "    \n",
    "    def release(self):\n",
    "        if self.cv is not None:\n",
    "            with self.cv:\n",
    "                self.cv.notifyAll()\n",
    "    \n",
    "    def stopService(self):\n",
    "        if self.srv is not None:\n",
    "            self.srv.shutdown()\n",
    "\n",
    "        # wait for thread to finish\n",
    "        self.join()\n",
    "        \n",
    "        self.logger.info(\"%s : stopped\" % self.api_name)\n",
    "        self.running = False\n",
    "        \n",
    "    def run(self):\n",
    "        self.logger.info(\"%s : starting\" % self.api_name)\n",
    "        self.srv  = make_server(self.bind_addr, self.bind_port, self.api)\n",
    "        self.ctx  = self.api.app_context()\n",
    "        self.running = True\n",
    "        self.srv.serve_forever()\n",
    "        self.logger.info(\"%s : finishing\" % self.api_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-18T20:33:27.670525Z",
     "start_time": "2024-04-18T20:33:27.585872Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "%%deploy /orch/base/db/DataBaseBackend.py\n",
    "# DataBaseBackend \n",
    "\n",
    "import time\n",
    "import sqlalchemy as sal\n",
    "from sqlalchemy import create_engine, and_\n",
    "from sqlalchemy.sql import func\n",
    "from sqlalchemy.sql import text\n",
    "from sqlalchemy.orm import sessionmaker\n",
    "from sqlalchemy.orm import scoped_session\n",
    "from sqlalchemy.orm import defer\n",
    "from sqlalchemy.orm import undefer\n",
    "\n",
    "\n",
    "class DataBaseBackend(object):\n",
    "        \n",
    "    def __init__(self, conn_str):\n",
    "        try:\n",
    "            self.engine = sal.create_engine(conn_str)\n",
    "        except Exception as e:\n",
    "            raise e\n",
    "            \n",
    "        session_factory = sessionmaker(self.engine,expire_on_commit=False)\n",
    "        self.session = scoped_session(session_factory)\n",
    "            \n",
    "    def getEngine(self):\n",
    "        return self.engine\n",
    "    \n",
    "    def existTable(self,table_name):\n",
    "        engine = self.getEngine()\n",
    "        ins = sal.inspect(engine)\n",
    "        if not ins.has_table(table_name):\n",
    "            return False\n",
    "        return True\n",
    "    \n",
    "    def getTable(self,table_name):\n",
    "        if self.existTable(table_name):\n",
    "            engine = self.getEngine()            \n",
    "            metadata = sal.MetaData(engine)\n",
    "            table = sal.Table(table_name, metadata, autoload=True, autoload_with=engine)\n",
    "        \n",
    "            return table\n",
    "        raise TableDoesNotExist(table_name)\n",
    "        \n",
    "    def initialize(self, p_object):\n",
    "        if not self.existTable(p_object.__tablename__):\n",
    "            engine = self.getEngine()\n",
    "            try:\n",
    "                # Implement the creation\n",
    "                p_object.metadata.create_all(engine)\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "                return False\n",
    "            return True\n",
    "        \n",
    "        return True\n",
    "    \n",
    "    def query(self, query):\n",
    "        try:\n",
    "            statement = text(query)\n",
    "            rs = self.session.execute(statement)\n",
    "            return rs\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(\"error in query: %s\" % query)\n",
    "            raise e\n",
    "    \n",
    "    def getObjects(self, p_obj, *args, defer_cols=[], **kwargs):\n",
    "        \n",
    "        sess = self.session()\n",
    "        rs = None\n",
    "        try:\n",
    "            if len(kwargs)>0 or len(args)>0:\n",
    "                if len(defer_cols)>0:\n",
    "                    defer_lst = list([defer(x) for x in defer_cols])                    \n",
    "                    if len(kwargs)>0:\n",
    "                        rs = sess.query(p_obj).filter_by(**kwargs).options(*defer_lst).all()\n",
    "                    else:\n",
    "                        rs = sess.query(p_obj).filter(*args).options(*defer_lst).all()\n",
    "                else:\n",
    "                    if len(kwargs)>0:\n",
    "                        rs = sess.query(p_obj).filter_by(**kwargs).all()\n",
    "                    else:\n",
    "                        rs = sess.query(p_obj).filter(*args).all()\n",
    "            else:\n",
    "                if len(defer_cols)>0:\n",
    "                    defer_lst = list([defer(x) for x in defer_cols])\n",
    "                    rs = sess.query(p_obj).options(*defer_lst).all()\n",
    "                else:\n",
    "                    rs = sess.query(p_obj).all()\n",
    "        except Exception as e:\n",
    "            raise e\n",
    "        finally:\n",
    "            if len(defer_cols)==0:\n",
    "                self.session.remove()\n",
    "        \n",
    "        return rs\n",
    "        \n",
    "    def refreshObject(self, p_obj):\n",
    "        sess = self.session()\n",
    "        try:\n",
    "            sess.expire(p_obj)\n",
    "            sess.refresh(p_obj)            \n",
    "        except Exception as e:\n",
    "            raise e        \n",
    "        finally:\n",
    "            self.session.remove()\n",
    "            \n",
    "        return True\n",
    "    \n",
    "    def commit(self):\n",
    "        sess = self.session()\n",
    "        try:\n",
    "            sess.commit()\n",
    "        except Exception as e:\n",
    "            raise e\n",
    "        finally:\n",
    "            self.session.remove()\n",
    "        return True\n",
    "    \n",
    "    def updateObjects(self, p_obj, *args, **kw_args):\n",
    "        sess = self.session()\n",
    "        try:\n",
    "            rs = sess.query(p_obj).filter(*args).update(kw_args)\n",
    "            sess.commit()\n",
    "        except Exception as e:\n",
    "            raise e\n",
    "        finally:\n",
    "            self.session.remove()\n",
    "            \n",
    "        return rs\n",
    "    \n",
    "    def saveObject(self, p_obj):\n",
    "        sess = self.session()\n",
    "        try:\n",
    "            sess.add(p_obj)\n",
    "            e = None\n",
    "            done=False\n",
    "            for r in range(0,10):\n",
    "                try:\n",
    "                    sess.commit()\n",
    "                    done=True\n",
    "                    break\n",
    "                except Exception as e:\n",
    "                    print(\"retry commit\")\n",
    "                    time.sleep(5)\n",
    "            if not done:\n",
    "                raise RuntimeError(\"could not save object to database:\",e)\n",
    "                \n",
    "        except Exception as e:\n",
    "            raise e\n",
    "        finally:    \n",
    "            self.session.remove()\n",
    "    \n",
    "        return True\n",
    "\n",
    "    def destroyObject(self, p_obj):\n",
    "        sess = self.session()\n",
    "        try:\n",
    "            sess.delete(p_obj)\n",
    "            sess.commit()\n",
    "        except Exception as e:\n",
    "            raise e\n",
    "        finally:    \n",
    "            self.session.remove()\n",
    "\n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-18T20:33:27.756645Z",
     "start_time": "2024-04-18T20:33:27.672505Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "%%deploy /orch/base/ActionListener.py\n",
    "\n",
    "class ActionListener(object):    \n",
    "    def actionPerformed(self, evt):\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-18T20:33:27.834927Z",
     "start_time": "2024-04-18T20:33:27.758358Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "%%deploy /orch/base/ActionEvent.py\n",
    "\n",
    "class ActionEvent(object):\n",
    "    def __init__(self, *args, **kw_args):\n",
    "        self.source = None\n",
    "    \n",
    "    def setSource(self, src):\n",
    "        self.source = src\n",
    "        \n",
    "    def getSource(self):\n",
    "        return self.source\n",
    "        \n",
    "    def __repr__(self):\n",
    "        return \"%s[source=%s]\" % (type(self).__name__, type(self.source).__name__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-18T20:33:27.915320Z",
     "start_time": "2024-04-18T20:33:27.836649Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "%%deploy /orch/base/Observable.py\n",
    "\n",
    "from . import ActionListener\n",
    "\n",
    "class Observable(object):\n",
    "    def __init__(self,*args, **kw_args):\n",
    "        self.listeners = []\n",
    "        \n",
    "    def addActionListener(self,al):\n",
    "        if issubclass(type(al), ActionListener):\n",
    "            if not hasattr(self,\"listeners\"):\n",
    "                self.listeners = []\n",
    "            self.listeners.append(al)\n",
    "            return self\n",
    "        raise RuntimeError(\"%s must inhnerit from ActionListener\" % type(al).__name__)\n",
    "\n",
    "    def actionPerformed(self, evt):\n",
    "        evt.setSource(self)\n",
    "        if not hasattr(self,\"listeners\"):\n",
    "            self.listeners = []\n",
    "            \n",
    "        for al in self.listeners:\n",
    "            al.actionPerformed(evt)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-18T20:33:28.000772Z",
     "start_time": "2024-04-18T20:33:27.918936Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "%%deploy /orch/base/SerializedObject.py\n",
    "class SerializedObject(object):\n",
    "    _data =  {}\n",
    "    def __init__(self,data={}):\n",
    "        self._data = data\n",
    "\n",
    "    def __del__(self):\n",
    "        del self._data\n",
    "\n",
    "    def get(self,key):\n",
    "        return self._data[key]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-18T20:33:28.077144Z",
     "start_time": "2024-04-18T20:33:28.002675Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "%%deploy /orch/base/AVROCodec.py\n",
    "import select \n",
    "import os \n",
    "import re \n",
    "import jsonpickle as jp\n",
    "from .SerializedObject import SerializedObject\n",
    "\n",
    "# CLEAN THIS CLASS FROM SCHEMA RELATED TO ASTRONOMY\n",
    "\n",
    "class AVROCodec(object):\n",
    " \n",
    "    \"\"\"\n",
    "    AVRO codec using jsonpickle for encoding. \n",
    "    \"\"\"\n",
    "\n",
    "    hdu_schema = '{\"namespace\": \"example.avro\",\\\n",
    "        \"type\": \"record\",\\\n",
    "        \"name\": \"FITS-HDU\",\\\n",
    "        \"fields\": [\\\n",
    "            {\"name\": \"image\"       ,\"type\": \"bytes\"},\\\n",
    "            {\"name\": \"header\"      ,\"type\": \"bytes\"}\\\n",
    "        ]\\\n",
    "    }'\n",
    "    \n",
    "    @staticmethod\n",
    "    def encode(obj):\n",
    "        #print(\"encoding \",obj, type(obj))\n",
    "\n",
    "        if isinstance(obj,bool):\n",
    "            #print(\"encoding bool\")\n",
    "            s = SerializedObject({\"type\":type(obj), \"value\": str(obj) })\n",
    "            return jp.dumps(s)\n",
    "\n",
    "        if isinstance(obj,str):\n",
    "            #print(\"encoding string\")\n",
    "            s = SerializedObject({\"type\":type(obj), \"value\": obj })\n",
    "            return jp.dumps(s)\n",
    "\n",
    "        if isinstance(obj,int):\n",
    "            #print(\"encoding int\")\n",
    "            s = SerializedObject({\"type\":type(obj), \"value\": str(obj) })\n",
    "            return jp.dumps(s)\n",
    "\n",
    "        if isinstance(obj, (list, tuple) ):\n",
    "            #print(\"encoding list\")\n",
    "            l = [AVROCodec.encode(o) for o in obj]\n",
    "            return jp.dumps(l)\n",
    "\n",
    "        #print(\"encoding obj \",obj, type(obj))\n",
    "        #s = time.time()\n",
    "        l = jp.dumps(obj)\n",
    "        #e = time.time()\n",
    "        #print(\"done encoding %s\" % (e-s))\n",
    "        return l\n",
    "\n",
    "    @staticmethod\n",
    "    def decode(enc):\n",
    "        obj = None\n",
    "        try:\n",
    "            obj = jp.loads(enc)\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "\n",
    "        if isinstance(obj, (list, tuple)):\n",
    "            #print(\"decoding list\")\n",
    "            return [ AVROCodec.decode(o) for o in obj ]\n",
    "\n",
    "        if isinstance(obj,SerializedObject):\n",
    "            #print(\"decoding serializedObject\")\n",
    "            o = obj.get(\"type\")()\n",
    "\n",
    "            if isinstance(o,bool):\n",
    "                return obj.get(\"value\")\n",
    "\n",
    "            if isinstance(o,int):\n",
    "                return int(obj.get(\"value\"))\n",
    "\n",
    "            if isinstance(o,str):\n",
    "                return str(obj.get(\"value\"))\n",
    "\n",
    "        return obj\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-18T20:33:28.155265Z",
     "start_time": "2024-04-18T20:33:28.078945Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "%%deploy /orch/base/LocalJob.py\n",
    "from .AbstractJob import AbstractJob\n",
    "\n",
    "from threading import Thread, Event\n",
    "from promise import Promise\n",
    "import traceback\n",
    "import tempfile\n",
    "import dill\n",
    "\n",
    "from ._async import *\n",
    "\n",
    "class LocalJob(AbstractJob):\n",
    "    def __init__(self, params={}):\n",
    "        super(LocalJob,self).__init__(params)\n",
    "\n",
    "    def execute(self, function, *args):\n",
    "\n",
    "        #import psutil\n",
    "        #max_cores = psutil.cpu_count()\n",
    "\n",
    "        @ProcessAsync\n",
    "        def _exec(f, *args):\n",
    "            self.result = f(*args)\n",
    "            return self.result\n",
    "\n",
    "        fn = None\n",
    "        try:\n",
    "            fn = function\n",
    "        except Exception as e:\n",
    "            print(\"Error getting the function to call: %s\" % function)\n",
    "            print(e)\n",
    "            raise(e)\n",
    "\n",
    "        # unwrap the function if it is wrapped in an AsyncCall\n",
    "        if isinstance(fn,ThreadAsyncMethod) or isinstance(fn,ProcessAsyncMethod):\n",
    "            fn = fn.Callable\n",
    "\n",
    "        self._exec_hdl = _exec(fn, *args)\n",
    "        return self._exec_hdl\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-18T20:33:28.241385Z",
     "start_time": "2024-04-18T20:33:28.157357Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "%%deploy /orch/base/_async.py\n",
    "# Async decorator\n",
    "# with threads and processes\n",
    "#\n",
    "import multiprocessing as mp\n",
    "import jsonpickle\n",
    "import ctypes\n",
    "import random \n",
    "import string \n",
    "from .argument import Argument\n",
    "import psutil\n",
    "import signal\n",
    "import threading\n",
    "import os\n",
    "\n",
    "import sys, traceback\n",
    "\n",
    "from promise import Promise\n",
    "\n",
    "class TimeoutError(RuntimeError):\n",
    "    pass\n",
    "\n",
    "class ProcessAsyncCall(object):\n",
    "\n",
    "    pool_cnt = {}\n",
    "\n",
    "    def __init__(self, fnc, pool_size, callback = None):\n",
    "        \n",
    "        self.p_id      = ''.join([random.choice(string.ascii_letters + string.digits) for n in range(32)]) \n",
    "\n",
    "        self.single    = False\n",
    "\n",
    "        if pool_size is None:\n",
    "            self.single    = True\n",
    "            self.pool_size = 1\n",
    "        else:\n",
    "            self.pool_size = pool_size\n",
    "\n",
    "        self.Callable  = fnc\n",
    "        self.Callback  = callback\n",
    "        self.Result    = None\n",
    "        self.Manager = mp.Manager()\n",
    "        self.pool      = None\n",
    "\n",
    "        self.parent_pid = os.getpid()\n",
    "\n",
    "    def cancel(self, sig=signal.SIGTERM):\n",
    "        try:\n",
    "            parent = psutil.Process(self.parent_pid)\n",
    "        except psutil.NoSuchProcess:\n",
    "              return\n",
    "        children = parent.children(recursive=True)\n",
    "        for process in children:\n",
    "            process.send_signal(sig)\n",
    "        \n",
    "    def getPool(self):\n",
    "        if self.Callable.__name__ not in self.pool_cnt:\n",
    "            if self.Manager is None:\n",
    "                self.Manager = mp.Manager()\n",
    "            self.pool_cnt[self.Callable.__name__] = {\"queue\": self.Manager.list()  ,\"running\" : self.Manager.list() }\n",
    "        return self.pool_cnt[self.Callable.__name__]\n",
    "\n",
    "    def __call__(self, *args, **kwargs):\n",
    "        self.Result  = self.Manager.Value(ctypes.c_wchar,'')\n",
    " \n",
    "        if self.single :\n",
    "            self.proc = mp.Process(target = self.run, args = args, kwargs = kwargs)\n",
    "            #self.proc.daemon = True\n",
    "            self.proc.start()\n",
    "        else:\n",
    "            if self.Callable.__name__ not in self.pool_cnt:\n",
    "            #   print(\"creating pool record\",self.pool_size)\n",
    "            \tself.pool_cnt[self.Callable.__name__] = {\"queue\": self.Manager.list()  ,\"running\" : self.Manager.list() }\n",
    "\n",
    "            pool = self.getPool()\n",
    "        \n",
    "            self.proc = mp.Process(target = self.run, name = self.Callable.__name__, args = args, kwargs = kwargs)\n",
    "\n",
    "            self.lock = self.Manager.Lock()\n",
    "\n",
    "            if len(pool[\"running\"]) < self.pool_size:\n",
    "                #print(\"running\",self.p_id)\n",
    "                pool[\"running\"].append(self.p_id)\n",
    "                #print(len(pool[\"queue\"]),len(pool[\"running\"]))\n",
    "\n",
    "                self.proc.start()\n",
    "\n",
    "            else:\n",
    "                #print(\"queueing \",self.p_id)\n",
    "                self.lock.acquire()\n",
    "                pool[\"queue\"].append(self.lock) \n",
    "                #print(len(pool[\"queue\"]),len(pool[\"running\"]))\n",
    "\n",
    "                def start_proc(proc):\n",
    "                    #print(\"start proc adquire\", self.p_id)\n",
    "                    try:\n",
    "                        proc.lock.acquire()\n",
    "                        proc.lock.release()\n",
    "                    except Exception as e:\n",
    "                        print(\"error trying to acquire lock.\",e)\n",
    "\n",
    "                    #print(\"start proc released\", self.p_id)\n",
    "                    pool = proc.getPool()\n",
    "                    pool[\"running\"].append(self.p_id)\n",
    "                    proc.proc.start()\n",
    "                    return\n",
    "\n",
    "                t = threading.Thread(target=lambda p: start_proc(p) , args=(self,) )\n",
    "                t.start()\n",
    "                t.join()\n",
    "\n",
    "        return self\n",
    "    \n",
    "    def then(self, fn):\n",
    "        response = self.get()\n",
    "        return fn(*response)\n",
    "\n",
    "    def wait(self, timeout = None):        \n",
    "        if self.proc.is_alive():\n",
    "            self.proc.join(timeout)\n",
    "            if self.proc.is_alive():\n",
    "                raise TimeoutError()\n",
    "        return True\n",
    "\n",
    "    def get(self, default = None):\n",
    "        if self.Result.value == '':\n",
    "            self.wait()\n",
    "       \n",
    "        if self.proc.is_alive():\n",
    "            self.proc.join()\n",
    "            \n",
    "        try:\n",
    "            self.proc.terminate()\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        self.proc.close()\n",
    "\n",
    "        ret = default\n",
    "        try:\n",
    "            ret = jsonpickle.decode(self.Result.value)\n",
    "        except Exception as e:\n",
    "            print(\"error decoding result value\",e)\n",
    "            pass\n",
    "\n",
    "        self.Result = None\n",
    "        if self.single:\n",
    "            self.Manager.shutdown()\n",
    "            self.Manager = None\n",
    "        else:\n",
    "            pool = self.getPool()\n",
    "            if len(pool[\"running\"])==0 and self.Manager is not None and len(pool[\"queue\"])==0:\n",
    "                #print(\"shutting down manager\")\n",
    "                # kill the manager when all running processes are done\n",
    "                self.Manager.shutdown()\n",
    "                self.Manager = None\n",
    "                del self.pool_cnt[self.Callable.__name__] \n",
    "\n",
    "        return ret\n",
    "\n",
    "    def run(self, *args, **kwargs):\n",
    "        try:\n",
    "            result = self.Callable(*args, **kwargs)\n",
    "            try: \n",
    "                packed_result = jsonpickle.encode(result)\n",
    "                self.Result.value = \"%s\" % packed_result\n",
    "            except Exception as e:\n",
    "                print(\"error calling function:\",e)\n",
    "                try:\n",
    "                    self.lock.release()\n",
    "                except:\n",
    "                    pass\n",
    "                raise e\n",
    "                \n",
    "            if self.Callback:\n",
    "                self.Callback(self.Result)\n",
    "        except Exception as e:\n",
    "            print(e, args, kwargs)\n",
    "            try:\n",
    "                self.lock.release()\n",
    "            except:\n",
    "                pass\n",
    "            raise e\n",
    "\n",
    "        try:\n",
    "            self.lock.release()\n",
    "            self.lock = None\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        if not self.single:\n",
    "            pool = self.getPool()\n",
    "            #print(\"removing \",self.p_id)\n",
    "            pool[\"running\"].remove(self.p_id) \n",
    "            #print(len(pool[\"queue\"]),len(pool[\"running\"]))\n",
    "\n",
    "            pool_len = len(pool[\"running\"])\n",
    "            if pool_len < self.pool_size:\n",
    "                if len(pool[\"queue\"])>0:\n",
    "                    proc_avai = self.pool_size - pool_len\n",
    "                    #print(\"releasing %d processes\" % proc_avai)\n",
    "                    for i in range(0,proc_avai):\n",
    "                        try:\n",
    "                            l = pool[\"queue\"].pop(0)\n",
    "                            l.release()\n",
    "                        except Exception as e:\n",
    "                            print(\"error releasing the lock in dequeue\",e)\n",
    "\n",
    "        return\n",
    "    \n",
    "class ThreadAsyncCall(object):\n",
    "    def __init__(self, fnc, callback = None):\n",
    "        self.Callable = fnc\n",
    "        self.Callback = callback\n",
    "        self.Result   = None\n",
    "        self.Thread   = None\n",
    "        \n",
    "    def __call__(self, *args, **kwargs):\n",
    "        self.Thread = threading.Thread(target = self.run, name = self.Callable.__name__, args = args, kwargs = kwargs)\n",
    "        self.Thread.start()\n",
    "        return self\n",
    "\n",
    "    def wait(self, timeout = None):\n",
    "        self.Thread.join(timeout)\n",
    "        \n",
    "        if self.Thread.is_alive():\n",
    "            raise TimeoutError()\n",
    "        else:\n",
    "            return self.Result\n",
    "\n",
    "    def get(self):\n",
    "        if self.Result is None:\n",
    "            self.wait()\n",
    "\n",
    "        self.Thread.join()\n",
    "        del self.Thread\n",
    "\n",
    "        while isinstance(self.Result, (ThreadAsyncCall, ProcessAsyncCall, Argument)):\n",
    "            self.Result = self.Result.get()\n",
    "           \n",
    "        if isinstance(self.Result, RuntimeError):\n",
    "            raise(self.Result)\n",
    " \n",
    "        return self.Result\n",
    "\n",
    "    def run(self, *args, **kwargs):\n",
    "        try:\n",
    "            self.Result = self.Callable(*args, **kwargs)\n",
    "            if self.Callback:\n",
    "                self.Callback(self.Result)\n",
    "        except Exception as e:\n",
    "            print(e, args, kwargs)\n",
    "            traceback.print_exc(file=sys.stdout)\n",
    "\n",
    "class ThreadAsyncMethod(object):\n",
    "    def __init__(self, fnc, callback=None):\n",
    "        self.Callable = fnc \n",
    "        self.Callback = callback\n",
    "\n",
    "    def __call__(self, *args, **kwargs):\n",
    "        return ThreadAsyncCall(self.Callable, self.Callback)(*args, **kwargs)\n",
    "\n",
    "class ProcessAsyncMethod(object):\n",
    "    def __init__(self, fnc, callback=None, pool_size = 1):\n",
    "        self.pool_size = pool_size\n",
    "        self.Callable  = fnc \n",
    "        self.Callback  = callback\n",
    "\n",
    "    def __call__(self, *args, **kwargs):\n",
    "        return ProcessAsyncCall(self.Callable, self.pool_size, self.Callback)(*args, **kwargs)\n",
    "\n",
    "def ProcessAsync(arg = None, callback = None):\n",
    "    if isinstance(arg, int):\n",
    "        def ProcessAsyncWrapper(fnc = None,  callback = None):\n",
    "            if fnc == None:\n",
    "                def AddAsyncCallback(fnc):\n",
    "                    return ProcessAsyncMethod(fnc, callback, arg)\n",
    "                return AddAsyncCallback\n",
    "            else:\n",
    "                return ProcessAsyncMethod(fnc, callback, arg)\n",
    "        return ProcessAsyncWrapper\n",
    "    else:\n",
    "        return ProcessAsyncMethod(arg, callback, None)\n",
    "\n",
    "def Async(fnc = None, callback = None):\n",
    "    if fnc == None:\n",
    "        def AddAsyncCallback(fnc):\n",
    "            return ThreadAsyncMethod(fnc, callback)\n",
    "        return AddAsyncCallback\n",
    "    else:\n",
    "        return ThreadAsyncMethod(fnc, callback)\n",
    "\n",
    "class AsyncDummyMethod(object):\n",
    "    def __init__(self, function, result):\n",
    "        self.function = function\n",
    "        self.result = result\n",
    "\n",
    "    def __call__(self, *args, **kwargs):\n",
    "        self.result = self.function(*args, **kwargs)\n",
    "        return self\n",
    "\n",
    "    def wait(self):\n",
    "        return self.result\n",
    "\n",
    "    def get(self):\n",
    "        return self.result\n",
    "\n",
    "def AsyncDummy(fnc = None, callback = None):\n",
    "    if fnc == None:\n",
    "        def AddAsyncDummyCallback(fnc):\n",
    "            return AsyncDummyMethod(fnc, callback)\n",
    "        return AddAsyncDummyCallback\n",
    "    else:\n",
    "        return AsyncDummyMethod(fnc, callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-18T20:33:28.323918Z",
     "start_time": "2024-04-18T20:33:28.243384Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "%%deploy /orch/base/argument.py\n",
    "import pickle\n",
    "import os\n",
    "import tempfile\n",
    "import jsonpickle as jp\n",
    "import dill\n",
    "\n",
    "class Argument:\n",
    "    def __init__(self, value, persistent = False, pkl_path = \"./tmp\"):\n",
    "        self.value = value\n",
    "        self.persistent = persistent\n",
    "        self.got   = 0\n",
    "        self.pkl_path = pkl_path\n",
    "\n",
    "        if not os.path.exists(self.pkl_path):\n",
    "            os.makedirs(self.pkl_path)\n",
    "\n",
    "        self.pkl_file = tempfile.NamedTemporaryFile(dir=self.pkl_path,delete=False).name\n",
    "        #pickle.dump(jp.dumps(self.value), )\n",
    "        with open(self.pkl_file, 'wb') as fd:\n",
    "            dill.dump(self.value,fd)\n",
    "            \n",
    "        self.value = None\n",
    "\n",
    "    def __del__(self):\n",
    "        if not self.persistent and os.path.exists(self.pkl_file) and self.got:\n",
    "            os.remove(self.pkl_file)\n",
    "\n",
    "    def type(self):\n",
    "        if self.value is not None:\n",
    "            return type(self.value)\n",
    "        return None\n",
    "\n",
    "    def destroy(self):\n",
    "         if os.path.exists(self.pkl_file):\n",
    "            os.remove(self.pkl_file)\n",
    "\n",
    "    def saveAs(self, outfile):\n",
    "        from shutil import copyfile\n",
    "        copyfile(self.pkl_file, outfile)\n",
    "        \n",
    "    def get(self):\n",
    "        with open(self.pkl_file,'rb') as fd:\n",
    "            self.value = dill.load(fd) \n",
    "    \n",
    "        self.got = 1\n",
    "        return self.value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-18T20:33:28.402009Z",
     "start_time": "2024-04-18T20:33:28.325930Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "%%deploy /orch/base/worker.py\n",
    "from . import AVROCodec\n",
    "import subprocess\n",
    "import time\n",
    "import os\n",
    "import sys\n",
    "import socket\n",
    "import importlib\n",
    "import codecs\n",
    "\n",
    "import select\n",
    "import os\n",
    "import re\n",
    "import jsonpickle as jp\n",
    "\n",
    "from taskit.backend import BackEnd, ADMIN_TASKS\n",
    "from taskit.log import FileLogger, DEBUG, INFO, ERROR\n",
    "\n",
    "from promise import Promise\n",
    "from contextlib import closing\n",
    "\n",
    "def function_caller(arg):\n",
    "    import dill, types, traceback, sys\n",
    "\n",
    "    try:\n",
    "        func_name = arg[\"name\"]\n",
    "        f_args = arg[\"args\"]\n",
    "        func = dill.loads(arg[\"func\"])\n",
    "        r = func(*f_args)\n",
    "        return r\n",
    "    except Exception as e:\n",
    "        print(\"exception raised when calling function by the worker\",e)\n",
    "        traceback.print_exc(file=sys.stdout)\n",
    "        return e\n",
    "    return None\n",
    "\n",
    "def error_maker():\n",
    "    assert False, 'Why ever did you call this!?'\n",
    "\n",
    "class Worker():\n",
    "    call = None\n",
    "\n",
    "    def __init__(self):\n",
    "        #print(\"Worker constructor\")\n",
    "        pass\n",
    "\n",
    "    def __del__(self):\n",
    "        #print(\"Worker destructor\") \n",
    "        pass\n",
    "\n",
    "    def get_free_port(self):\n",
    "        with closing(socket.socket(socket.AF_INET, socket.SOCK_STREAM)) as s:\n",
    "            s.bind(('', 0))\n",
    "            return s.getsockname()[1]\n",
    "\n",
    "    def run(self):\n",
    "\n",
    "        my_host = os.uname()[1]\n",
    "        tasks = {'function_caller': function_caller, 'get-error': error_maker }\n",
    "        tasks.update(ADMIN_TASKS)\n",
    "\n",
    "        port = self.get_free_port()\n",
    "        job_id = os.getenv(\"SLURM_JOB_ID\")\n",
    "        step = os.getenv(\"SLURM_STEP_ID\")\n",
    "        if step == None:\n",
    "            step = 0\n",
    "\n",
    "        #home_pwd=os.environ[\"HOME\"]\n",
    "        #f = open(\"%s/tmp/backend-%s.%s\" % (home_pwd, job_id,step), \"w+\")\n",
    "        #log = FileLogger(f,[DEBUG, INFO, ERROR])\n",
    "\n",
    "        #backend = BackEnd(tasks,host=my_host, port=port, codec=bupacl.orch.base.AVROCodec, tracebacks=True, logger=log)\n",
    "        backend = BackEnd(tasks,host=my_host, port=port, codec=bupacl.orch.base.AVROCodec, tracebacks=True)\n",
    "\n",
    "        print(\"JOBID: %s STEP: %s PORT: %d HOST: %s\" % (os.getenv(\"SLURM_JOB_ID\"),step,port,os.getenv(\"SLURMD_NODENAME\")),flush=True)\n",
    "\n",
    "        backend.main()\n",
    "\n",
    "        #print(\"Backend finished\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-18T20:33:28.489705Z",
     "start_time": "2024-04-18T20:33:28.404021Z"
    },
    "code_folding": [
     0,
     122
    ]
   },
   "outputs": [],
   "source": [
    "%%deploy /orch/base/__init__.py\n",
    "name=\"orch\"\n",
    "version=\"1.2\"\n",
    "author=\"Juan Carlos Maureira\"\n",
    "\n",
    "from .ActionEvent import ActionEvent\n",
    "from .ActionListener import ActionListener\n",
    "from .Observable import Observable\n",
    "from .SerializedObject import *\n",
    "from ._async import *\n",
    "from .worker import Worker\n",
    "from .AbstractJob import AbstractJob\n",
    "from .argument import Argument\n",
    "from .AbstractApiService import AbstractApiService\n",
    "from .AbstractApiClient import AbstractApiClient\n",
    "from .PersistentDict import PersistentDict\n",
    "\n",
    "from .slurm import SlurmController\n",
    "from .slurm import *\n",
    "from .LocalJob import *\n",
    "\n",
    "# Decorators\n",
    "\n",
    "def asJob(*f, **arg):  \n",
    "    def submitJob(job_params, function, *args, **kwargs):\n",
    "        if \"name\" not in job_params and \"job-name\" not in job_params:\n",
    "            job_params[\"job-name\"] = function.__name__\n",
    "\n",
    "        job = Job(params = job_params)\n",
    "        if \"verbose\" in job_params:\n",
    "            job.setVerbose(job_params['verbose'])\n",
    "        else:\n",
    "            job.setVerbose(False)\n",
    "\n",
    "        if \"output\" in job_params:\n",
    "            job.setJobLog(job_params['output'])\n",
    "\n",
    "        job.asJob(True)\n",
    "        ret = job.run(function, *args, **kwargs)\n",
    "        return ret\n",
    "    \n",
    "    params = {\"ntasks\":\"1\",\"cpus-per-task\":1, \"mem\": \"4000M\",\"nodes\":1}\n",
    "    \n",
    "    if f != () and callable(*f):\n",
    "        # call without arguments\n",
    "        def wrapper(*args, **kwargs):\n",
    "            return submitJob(params, f[0], *args, **kwargs)\n",
    "        return wrapper\n",
    "    else:\n",
    "        def jobFunction(func):\n",
    "            params = {\"ntasks\":\"1\"}\n",
    "            if len(arg)>0 :\n",
    "                params.update(arg)\n",
    "\n",
    "            def wrapper(*args, **kwargs):\n",
    "                return submitJob(params, func, *args, **kwargs)\n",
    "            return wrapper\n",
    "        return jobFunction \n",
    "\n",
    "def asLocalJob(*f, **arg):  \n",
    "    def submitJob(job_params, function, *args, **kwargs):\n",
    "        if \"name\" not in job_params and \"job-name\" not in job_params:\n",
    "            job_params[\"job-name\"] = function.__name__\n",
    "\n",
    "        job = LocalJob(params = job_params)\n",
    "        if \"verbose\" in job_params:\n",
    "            job.setVerbose(job_params['verbose'])\n",
    "        else:\n",
    "            job.setVerbose(False)\n",
    "\n",
    "        if \"output\" in job_params:\n",
    "            job.setJobLog(job_params['output'])\n",
    "\n",
    "        job.asJob(True)\n",
    "        ret = job.run(function, *args, **kwargs)\n",
    "        return ret\n",
    "    \n",
    "    params = {\"ntasks\":\"1\",\"cpus-per-task\":1, \"mem\": \"4000M\",\"nodes\":1}\n",
    "    \n",
    "    if f != () and callable(*f):\n",
    "        # call without arguments\n",
    "        def wrapper(*args, **kwargs):\n",
    "            return submitJob(params, f[0], *args, **kwargs)\n",
    "        return wrapper\n",
    "    else:\n",
    "        def jobFunction(func):\n",
    "            params = {\"ntasks\":\"1\"}\n",
    "            if len(arg)>0 :\n",
    "                params.update(arg)\n",
    "\n",
    "            def wrapper(*args, **kwargs):\n",
    "                return submitJob(params, func, *args, **kwargs)\n",
    "            return wrapper\n",
    "        return jobFunction \n",
    "\n",
    "def asStep(*f, **arg):\n",
    "    \n",
    "    def submitJob(job_params, function, *args, **kwargs):\n",
    "        job_params[\"job-name\"] = function.__name__\n",
    "        job = Job(params = job_params)\n",
    "        job.setVerbose(True)\n",
    "        job.setExclusive(False)\n",
    "        ret = job.run(function, *args, **kwargs)\n",
    "        return ret\n",
    "    \n",
    "    params = {\"ntasks\":\"1\",\"cpus-per-task\":1, \"mem\": \"4000M\",\"nodes\":1}\n",
    "    \n",
    "    if f != () and callable(*f):\n",
    "        # call without arguments\n",
    "        def wrapper(*args, **kwargs):\n",
    "            return submitJob(params, f[0], *args, **kwargs)\n",
    "        return wrapper\n",
    "    else:\n",
    "        def jobFunction(func):\n",
    "            params = {\"ntasks\":\"1\",\"cpus-per-task\":1, \"mem\": \"4000M\",\"nodes\":1}\n",
    "            if len(arg)>0 :\n",
    "                params.update(arg)\n",
    "            def wrapper(*args, **kwargs):\n",
    "                return submitJob(params, func, *args, **kwargs)\n",
    "            return wrapper\n",
    "        return jobFunction\n",
    "      \n",
    "def asExclusiveStep(*f, **arg):\n",
    "    def submitJob(job_params, function, *args, **kwargs):\n",
    "        job_params[\"job-name\"] = function.__name__\n",
    "        job = Job(params = job_params)\n",
    "        if \"verbose\" in job_params:\n",
    "            job.setVerbose(job_params['verbose'])\n",
    "        else:\n",
    "            job.setVerbose(False)\n",
    "\n",
    "        job.setExclusive(True)\n",
    "        ret = job.run(function, *args, **kwargs)\n",
    "        return ret\n",
    "    \n",
    "    params = {\"ntasks\":\"1\",\"cpus-per-task\":1, \"mem\": \"4000M\",\"nodes\":1}\n",
    "    \n",
    "    if f != () and callable(*f):\n",
    "        # call without arguments\n",
    "        def wrapper(*args, **kwargs):\n",
    "            return submitJob(params, f[0], *args, **kwargs)\n",
    "        return wrapper\n",
    "    else:\n",
    "        def jobFunction(func):\n",
    "            params = {\"ntasks\":\"1\",\"cpus-per-task\":1, \"mem\": \"4000M\",\"nodes\":1}\n",
    "            if len(arg)>0 :\n",
    "                params.update(arg)\n",
    "            def wrapper(*args, **kwargs):\n",
    "                return submitJob(params, func, *args, **kwargs)\n",
    "            return wrapper\n",
    "        return jobFunction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-18T20:33:28.561725Z",
     "start_time": "2024-04-18T20:33:28.491445Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "%%deploy /orch/base/db/__init__.py\n",
    "\n",
    "from .DataBaseBackend import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-18T20:33:28.647794Z",
     "start_time": "2024-04-18T20:33:28.563849Z"
    },
    "code_folding": [
     0
    ],
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%deploy /orch/exceptions/__init__.py\n",
    "\n",
    "# exceptions\n",
    "\n",
    "class InitializeError(Exception):\n",
    "    def __init__(self,table_name):\n",
    "        super(InitializeError, self).__init__(table_name)\n",
    "\n",
    "class TableDoesNotExist(Exception):\n",
    "    def __init__(self,table_name):\n",
    "        super(TableDoesNotExist, self).__init__(table_name)\n",
    "\n",
    "class PipelineAlreadyRegistered(Exception):\n",
    "    def __init__(self,label):\n",
    "        super(PipelineAlreadyRegistered, self).__init__(label)\n",
    "\n",
    "class PipelineNotRegistered(Exception):\n",
    "    def __init__(self,label):\n",
    "        super(PipelineNotRegistered, self).__init__(label)\n",
    "\n",
    "class PipelineNotFound(Exception):\n",
    "    def __init__(self,label):\n",
    "        super(PipelineNotFound, self).__init__(label)\n",
    "        \n",
    "class MultiplePipelineFound(Exception):\n",
    "    def __init__(self,label):\n",
    "        super(MultiplePipelineFound, self).__init__(label)\n",
    "        \n",
    "class MultipleActivePipelineRegistered(Exception):\n",
    "    def __init__(self,label):\n",
    "        super(MultipleActivePipelineRegistered, self).__init__(label)\n",
    "        \n",
    "class NoActivePipelineRegistered(Exception):\n",
    "    def __init__(self,label):\n",
    "        super(NoActivePipelineRegistered, self).__init__(label)\n",
    "        \n",
    "class ImplementationIsNotAFunction(Exception):\n",
    "    def __init__(self,name):\n",
    "        super(ImplementationIsNotAFunction, self).__init__(name)\n",
    "\n",
    "class MultipleExecutionIDFound(Exception):\n",
    "    def __init__(self,uuid):\n",
    "        super(MultipleExecutionIDFound, self).__init__(uuid)\n",
    "        \n",
    "class ExecutionIdNotFound(Exception):\n",
    "    def __init__(self,uuid):\n",
    "        super(ExecutionIdNotFound, self).__init__(uuid)\n",
    "\n",
    "class APIResponseError(Exception):\n",
    "    def __init__(self,code):\n",
    "        super(APIResponseError, self).__init__(code)\n",
    "\n",
    "class PipelineExecutionError(Exception):\n",
    "    def __init__(self,e):\n",
    "        super(PipelineExecutionError, self).__init__(e)\n",
    "\n",
    "class PipelineSchedulingError(Exception):\n",
    "    def __init__(self,e):\n",
    "        super(PipelineSchedulingError, self).__init__(e)\n",
    "\n",
    "class PipelineNotSavedInCatalog(Exception):\n",
    "    def __init__(self,name):\n",
    "        super(PipelineNotSavedInCatalog, self).__init__(name)\n",
    "\n",
    "class EventInThePast(Exception):\n",
    "    def __init__(self,name, time):\n",
    "        super(EventInThePast, self).__init__(\"%s @ %s\" % (name,time))        \n",
    "        \n",
    "class EventWithNoRecurrence(Exception):\n",
    "    def __init__(self,name):\n",
    "        super(EventWithNoRecurrence, self).__init__(name)\n",
    "\n",
    "class MultipleScheduledEventFound(Exception):\n",
    "    def __init__(self,uuid):\n",
    "        super(MultipleScheduledEventFound, self).__init__(uuid) \n",
    "        \n",
    "class NotificationNotRegistered(Exception):\n",
    "    def __init__(self,label):\n",
    "        super(NotificationNotRegistered, self).__init__(label)\n",
    "\n",
    "class SubscriberNotRegistered(Exception):\n",
    "    def __init__(self,label):\n",
    "        super(SubscriberNotRegistered, self).__init__(label)\n",
    "\n",
    "class NoSuchKeyInDictionary(Exception):\n",
    "    def __init__(self,label):\n",
    "        super(NoSuchKeyInDictionary, self).__init__(label)\n",
    "\n",
    "class NoSuchDictionary(Exception):\n",
    "    def __init__(self,label):\n",
    "        super(NoSuchDictionary, self).__init__(label)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-03T12:06:29.770598Z",
     "start_time": "2023-01-03T12:06:29.759885Z"
    }
   },
   "source": [
    "## PipelineManager Classes (server side)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-18T20:33:28.730511Z",
     "start_time": "2024-04-18T20:33:28.649667Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "%%deploy /orch/pipelinemanager/AbstractPipeline.py\n",
    "import base64\n",
    "import dill\n",
    "\n",
    "# AbstractPipeline\n",
    "\n",
    "class AbstractPipeline: \n",
    "    def __repr__(self):\n",
    "        return \"<Pipeline(id=%s, name='%s', owner='%s', version=%d, active='%s'>\" % (\n",
    "            str(self.id), self.name, self.owner_id, self.version, self.active\n",
    "        )\n",
    "                \n",
    "    def getFunction(self):\n",
    "        # include decryption\n",
    "        return dill.loads(base64.b64decode(self.impl_fn))\n",
    "        \n",
    "    def setActive(self, state):\n",
    "        self.active = state\n",
    "        return True\n",
    "    \n",
    "    def isActive(self):\n",
    "        return self.active\n",
    "        \n",
    "    def asJson(self):\n",
    "        impl_fn_b64 = \"\"\n",
    "        if self.impl_fn is not None:\n",
    "            impl_fn_b64 = base64.b64encode(self.impl_fn).decode(\"utf8\")\n",
    "            \n",
    "        return {\n",
    "            \"id\"          : self.id,\n",
    "            \"name\"        : self.name,\n",
    "            \"owner_id\"    : self.owner_id,\n",
    "            \"creation\"    : self.creation,\n",
    "            \"version\"     : self.version,\n",
    "            \"tags\"        : self.tags,\n",
    "            \"changed\"     : self.changed,\n",
    "            \"active\"      : self.active,\n",
    "            \"impl_fn\"     : impl_fn_b64\n",
    "        }\n",
    "        \n",
    "    \n",
    "    # arguments are volatile. only used to set arguments for execution \n",
    "    def setArguments(self, args):\n",
    "        self.args = args\n",
    "        \n",
    "    # keywords arguments are volatile. only used to set arguments for execution \n",
    "    def setKeywordArguments(self, kw_args):\n",
    "        self.kw_args = kw_args\n",
    "    \n",
    "    def getArguments(self):\n",
    "        if hasattr(self,\"args\"):\n",
    "            return self.args\n",
    "        return []\n",
    "    \n",
    "    def getKeywordArguments(self):\n",
    "        if hasattr(self,\"kw_args\"):\n",
    "            return self.kw_args\n",
    "        return {}\n",
    "    \n",
    "    def addVariable(self, key, value):\n",
    "        if not hasattr(self,\"vars\"):\n",
    "            self.vars = {}\n",
    "        self.vars[key]=value\n",
    "    \n",
    "    def getVariable(self, key):\n",
    "        if hasattr(self,\"vars\"):\n",
    "            if key in self.vars:\n",
    "                return self.vars[key]\n",
    "\n",
    "        return None\n",
    "    \n",
    "    def getVariables(self):\n",
    "        if hasattr(self,\"vars\"):\n",
    "            return self.vars\n",
    "        else:\n",
    "            return {}\n",
    "    \n",
    "    @classmethod\n",
    "    def fromJson(cls, json):\n",
    "        pipeline = cls()\n",
    "        pipeline.id          = json[\"id\"]\n",
    "        pipeline.name        = json[\"name\"]\n",
    "        pipeline.owner_id    = json[\"owner_id\"]\n",
    "        pipeline.creation    = json[\"creation\"]\n",
    "        pipeline.version     = json[\"version\"]\n",
    "        pipeline.tags        = json[\"tags\"]\n",
    "        pipeline.changed     = json[\"changed\"]\n",
    "        pipeline.active      = json[\"active\"]\n",
    "        pipeline.impl_fn     = base64.b64decode(json[\"impl_fn\"].encode(\"utf8\"))\n",
    "        \n",
    "        return pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-18T20:33:28.809478Z",
     "start_time": "2024-04-18T20:33:28.732585Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "%%deploy /orch/pipelinemanager/AbstractExecutor.py\n",
    "import base64\n",
    "import dill\n",
    "import inspect\n",
    "\n",
    "# AbstractExecutor\n",
    "\n",
    "class AbstractExecutor(object):\n",
    "    @classmethod\n",
    "    \n",
    "    def fromJson(cls, json):\n",
    "        obj = cls()\n",
    "        \n",
    "        for k,v in json.items():\n",
    "            setattr(obj, k, v)\n",
    "        \n",
    "        obj.handler     = None\n",
    "        obj.job_handler = None    \n",
    "        \n",
    "        return obj\n",
    "\n",
    "    def asJson(self):\n",
    "        if self.end_ts is None:\n",
    "            end_ts_str = \"None\"\n",
    "        else:\n",
    "            end_ts_str = self.end_ts.strftime(\"%m/%d/%Y %H:%M:%S\")\n",
    "\n",
    "        if self.exec_time is None:\n",
    "            exec_time_sec = None\n",
    "        else:\n",
    "            exec_time_sec = self.exec_time.total_seconds()\n",
    "\n",
    "        json_obj = {\n",
    "            \"id\"            : self.id,\n",
    "            \"name\"          : self.name,\n",
    "            \"version\"       : self.version,\n",
    "            \"owner_id\"      : self.owner_id,\n",
    "            \"uuid\"          : self.uuid,\n",
    "            \"creation\"      : self.creation.strftime(\"%m/%d/%Y %H:%M:%S\"),\n",
    "            \"start_ts\"      : self.start_ts.strftime(\"%m/%d/%Y %H:%M:%S\"),\n",
    "            \"end_ts\"        : end_ts_str,\n",
    "            \"exec_time\"     : exec_time_sec,\n",
    "            \"state\"         : self.state\n",
    "        }\n",
    "        return json_obj\n",
    "\n",
    "    def getOutput(self):\n",
    "        if self.output is not None:\n",
    "            return base64.b64decode(self.output).decode(\"utf8\")\n",
    "        return None\n",
    "\n",
    "    def getReturnValue(self):\n",
    "        if self.pipeline_ret is not None:\n",
    "            return dill.loads(base64.b64decode(self.pipeline_ret))\n",
    "        return None\n",
    "    \n",
    "    def getErrors(self):\n",
    "        if self.error is not None:\n",
    "            return base64.b64decode(self.error).decode(\"utf8\")\n",
    "        return None\n",
    "    \n",
    "    def getArguments(self):\n",
    "        return dill.loads(base64.b64decode(self.pipeline_args.encode(\"utf8\")))\n",
    "    \n",
    "    def getFunction(self):\n",
    "        # return the function as a function handler\n",
    "        return dill.loads(base64.b64decode(self.pipeline_fn.encode(\"utf8\")))\n",
    "\n",
    "    def isPreparing(self):\n",
    "        return self.state == 1 or self.state==2\n",
    "    \n",
    "    def isRunning(self):\n",
    "        return self.state ==3\n",
    "        \n",
    "    def isDone(self):\n",
    "        return self.state == 4 or self.state == 5\n",
    "\n",
    "    def isSuccessful(self):\n",
    "        return self.state == 4\n",
    "    \n",
    "    def isFailed(self):\n",
    "        return self.state == 5\n",
    "    \n",
    "    def getExecutionId(self):\n",
    "        # TODO: assert for empty uuid         \n",
    "        return self.uuid\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return \"<Execution[id=%d, when=%s, exec_time=%s, uuid=%s, state=%d, pipeline_name=%s, version=%d]>\" % (self.id, self.creation, self.exec_time, self.uuid, self.state, self.name, self.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-18T20:33:28.887413Z",
     "start_time": "2024-04-18T20:33:28.811400Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "%%deploy /orch/pipelinemanager/Pipeline.py\n",
    "import sqlalchemy as sal\n",
    "from sqlalchemy import create_engine, and_\n",
    "from sqlalchemy.sql import func\n",
    "import base64\n",
    "import dill\n",
    "\n",
    "# Pipeline\n",
    "from . import AbstractPipeline\n",
    "from sqlalchemy.ext.declarative import declarative_base\n",
    "Base = declarative_base()\n",
    "\n",
    "class Pipeline(AbstractPipeline,Base):\n",
    "    __tablename__ = 'pipelines'\n",
    "    \n",
    "    id         = sal.Column('id', sal.Integer, primary_key=True, nullable=False)\n",
    "    name       = sal.Column('name', sal.String)\n",
    "    owner_id   = sal.Column('owner_id', sal.String)\n",
    "    creation   = sal.Column('creation', sal.DateTime(timezone=True),server_default=func.now())\n",
    "    version    = sal.Column('version', sal.Integer)\n",
    "    tags       = sal.Column('tags', sal.String)\n",
    "    changed    = sal.Column('changed', sal.DateTime(timezone=True),onupdate=func.now())\n",
    "    active     = sal.Column('active', sal.Boolean)\n",
    "    impl_fn    = sal.Column('impl_fn', sal.TEXT)\n",
    "    \n",
    "    catalog    = None\n",
    "    manager    = None\n",
    "\n",
    "    def setActive(self, state):\n",
    "        self.active = state\n",
    "        if self.catalog is not None:\n",
    "            self.catalog.deactivateAll(self.name)\n",
    "            if not self.catalog.saveObject(self):\n",
    "                return False\n",
    "        \n",
    "        return True\n",
    "\n",
    "    def getExecutions(self,**kw_args):\n",
    "        if self.manager is not None:\n",
    "            return self.manager.get_execution_list(self.name, **kw_args)\n",
    "        return []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-18T20:33:28.997335Z",
     "start_time": "2024-04-18T20:33:28.889724Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "%%deploy /orch/pipelinemanager/PipelineCatalog.py\n",
    "\n",
    "# PipelineCatalog    \n",
    "import base64\n",
    "import dill\n",
    "import pandas as pd\n",
    "\n",
    "from sqlalchemy.sql import func\n",
    "\n",
    "from ..base.db import DataBaseBackend\n",
    "from ..exceptions import InitializeError, PipelineAlreadyRegistered, PipelineNotFound, PipelineNotSavedInCatalog\n",
    "from . import Pipeline\n",
    "\n",
    "class PipelineCatalog(DataBaseBackend):\n",
    "\n",
    "    def __init__(self, manager, db_conn_str = \"sqlite:///orchestrator.sqlite\"):\n",
    "        \n",
    "        super().__init__(db_conn_str)\n",
    "        \n",
    "        self.manager = manager\n",
    "        \n",
    "        if not self.initialize(Pipeline):\n",
    "            raise InitializeError(Pipeline.__tablename__)\n",
    "            \n",
    "    def isRegistered(self,name,**kw_args):\n",
    "        result = self.getObjects(Pipeline, name=name,**kw_args)\n",
    "        if len(result)>0:\n",
    "            return True\n",
    "        return False\n",
    "\n",
    "    def register(self, name, owner_id, pipeline_fn, tags=[], new_version = False ):\n",
    "        if not new_version:\n",
    "            if not self.isRegistered(name):\n",
    "            \n",
    "                #TODO: encrypt serialization with owner_key\n",
    "                pipeline_serialized = base64.b64encode(dill.dumps(pipeline_fn))\n",
    "\n",
    "                tags_str = \",\".join(tags)\n",
    "\n",
    "                new_pipeline = Pipeline(\n",
    "                    name          = name,\n",
    "                    owner_id      = owner_id,\n",
    "                    version       = 1,\n",
    "                    tags          = tags_str,\n",
    "                    active        = False,\n",
    "                    impl_fn       = pipeline_serialized\n",
    "                )                \n",
    "                if self.saveObject(new_pipeline):\n",
    "                    saved_pipeline = self.getObjects(Pipeline,\n",
    "                        name      = name, \n",
    "                        owner_id  = owner_id,\n",
    "                        version   = 1,\n",
    "                        tags      = tags_str,\n",
    "                        active    = False\n",
    "                    )\n",
    "                    return saved_pipeline\n",
    "                else:\n",
    "                    raise PipelineNotSavedInCatalog(name)\n",
    "            raise PipelineAlreadyRegistered(name)   \n",
    "            \n",
    "        else:\n",
    "            if self.isRegistered(name):\n",
    "                df = pd.read_sql(\"SELECT max(version) as version FROM pipelines where name=='%s'\"% name, con=self.getEngine())\n",
    "                \n",
    "                cur_version = int(df.version.values[0])\n",
    "                new_version = cur_version+1\n",
    "            \n",
    "                #TODO: encrypt serialization with owner_key\n",
    "                pipeline_serialized = base64.b64encode(dill.dumps(pipeline_fn))\n",
    "\n",
    "                tags_str = \",\".join(tags)\n",
    "\n",
    "                new_pipeline = Pipeline(\n",
    "                    name          = name,\n",
    "                    owner_id      = owner_id,\n",
    "                    version       = new_version,\n",
    "                    tags          = tags_str,\n",
    "                    active        = False,\n",
    "                    impl_fn       = pipeline_serialized\n",
    "                )\n",
    "\n",
    "                if self.saveObject(new_pipeline):\n",
    "                    saved_pipeline = self.getObjects(Pipeline,\n",
    "                        name      = name, \n",
    "                        owner_id  = owner_id,\n",
    "                        version   = new_version,\n",
    "                        tags      = tags_str,\n",
    "                        active    = False\n",
    "                    )\n",
    "\n",
    "                    return saved_pipeline[0]\n",
    "                else:\n",
    "                    raise PipelineNotSavedInCatalog(name)\n",
    "    \n",
    "            raise PipelineAlreadyRegistered(name)   \n",
    "        \n",
    "    def get(self, *args, **kwargs):\n",
    "        results = self.getObjects(Pipeline,*args,**kwargs)\n",
    "\n",
    "        # assign for each object the manager where they come from\n",
    "        for i in range(0,len(results)):\n",
    "            results[i].catalog = self\n",
    "            results[i].manager = self.manager\n",
    "            \n",
    "        if len(results)==0:        \n",
    "            raise PipelineNotFound(\"%s\" % kwargs)    \n",
    "        return results\n",
    "    \n",
    "    def deactivateAll(self, name):\n",
    "        return self.updateObjects(Pipeline, Pipeline.name == name, active = False )>0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-18T20:33:29.205199Z",
     "start_time": "2024-04-18T20:33:28.999434Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "%%deploy /orch/pipelinemanager/Executor.py\n",
    "# Executor\n",
    "import sys\n",
    "import io\n",
    "from io import StringIO\n",
    "from uuid import uuid4\n",
    "import base64\n",
    "import dill\n",
    "import jsonpickle\n",
    "import inspect\n",
    "import time\n",
    "from datetime import date, datetime, timezone\n",
    "from tzlocal import get_localzone \n",
    "import traceback\n",
    "import re\n",
    "\n",
    "import sqlalchemy as sal\n",
    "from sqlalchemy.ext.declarative import declarative_base\n",
    "from sqlalchemy.sql import func\n",
    "\n",
    "from ..exceptions import ImplementationIsNotAFunction, PipelineExecutionError\n",
    "from ..base import Argument, Async, asJob\n",
    "from ..base import Observable\n",
    "from ..orchestrator import OrchestratorAccess\n",
    "\n",
    "from . import AbstractExecutor\n",
    "from .Events import *\n",
    "from .executePipelineAsJob import *\n",
    "\n",
    "Base = declarative_base()\n",
    "\n",
    "class Executor(AbstractExecutor, Base, Observable):\n",
    "    \n",
    "    __tablename__ = 'executions'\n",
    "    \n",
    "    id             = sal.Column('id', sal.Integer, primary_key=True, nullable=False)\n",
    "    name           = sal.Column('name', sal.String)\n",
    "    version        = sal.Column('version', sal.Integer)\n",
    "    owner_id       = sal.Column('owner_id', sal.String)\n",
    "    uuid           = sal.Column('uuid', sal.String)\n",
    "    sch_evt_uuid   = sal.Column('sch_evt_uuid', sal.String)\n",
    "    creation       = sal.Column('creation', sal.DateTime(timezone=True),server_default=func.now())\n",
    "    start_ts       = sal.Column('start_ts', sal.DateTime(timezone=True))\n",
    "    end_ts         = sal.Column('end_ts', sal.DateTime(timezone=True))\n",
    "    exec_time      = sal.Column('exec_time', sal.Interval(second_precision=3))\n",
    "    state          = sal.Column('state', sal.Integer)    \n",
    "    pipeline_fn    = sal.Column('pipeline_fn', sal.TEXT)\n",
    "    pipeline_args  = sal.Column('pipeline_args', sal.TEXT)\n",
    "    pipeline_ret   = sal.Column('pipeline_ret', sal.TEXT)\n",
    "    output         = sal.Column('output', sal.TEXT)\n",
    "    error          = sal.Column('error', sal.TEXT)\n",
    "    \n",
    "    def __init__(self, em, pipeline, local=True, cores=1, partition=None, memory=None):\n",
    "        \n",
    "        Observable.__init__(self)\n",
    "        # non persistent attributes\n",
    "        self.em          = em\n",
    "        self.pipeline    = pipeline\n",
    "        self.handler     = None\n",
    "        self.job_handler = None\n",
    "        self.cores       = cores\n",
    "        self.local_job   = local\n",
    "        self.partition   = partition\n",
    "        self.memory      = memory\n",
    "        \n",
    "        # persistent attributes\n",
    "        self.name        = pipeline.name\n",
    "        self.version     = pipeline.version\n",
    "        self.owner_id    = pipeline.owner_id\n",
    "        self.creation    = datetime.now(timezone.utc).astimezone(get_localzone())\n",
    "        self.pipeline_fn = pipeline.impl_fn\n",
    "        self.uuid        = str(uuid4())\n",
    "        self.state       = 1  # created\n",
    "        \n",
    "        if hasattr(pipeline,\"scheduled_event_uuid\"):\n",
    "            self.sch_evt_uuid = pipeline.scheduled_event_uuid\n",
    "        \n",
    "        if not self.em.saveObject(self):\n",
    "            print(\"error saving executor\")\n",
    "\n",
    "    def __not_persistent_init__(self,em):\n",
    "        Observable.__init__(self)\n",
    "\n",
    "        self.em          = em\n",
    "        self.handler     = None\n",
    "        self.job_handler = None\n",
    "            \n",
    "    def setLocalJob(self, b):\n",
    "        self.local_job = b\n",
    "\n",
    "    def setCores(self, cores):\n",
    "        self.cores = cores\n",
    "\n",
    "    def refresh(self):\n",
    "        self.em.refreshObject(self)        \n",
    "    \n",
    "    def run(self, *args, **kwargs):\n",
    "        name = self.pipeline.name\n",
    "       \n",
    "        self.pipeline.setArguments(args)\n",
    "        self.pipeline.setKeywordArguments(kwargs)\n",
    "        self.pipeline.report = None\n",
    "\n",
    "        orch_access = OrchestratorAccess(self.em.owner.owner, self.pipeline)\n",
    "        \n",
    "        pipeline_fn = self.pipeline.getFunction()\n",
    "\n",
    "        pipeline_args = {\n",
    "            'args': args, \n",
    "            'kwargs': kwargs\n",
    "        }\n",
    "       \n",
    "        self.pipeline_args = base64.b64encode(dill.dumps(pipeline_args))\n",
    "        self.state         = 2  # initialized        \n",
    "        \n",
    "        if not self.em.saveObject(self):\n",
    "            print(\"error saving executor\")\n",
    "        \n",
    "        # add this executor to the executor manager active list\n",
    "        self.em.active[self.uuid] = self \n",
    "\n",
    "        if inspect.isfunction(pipeline_fn):\n",
    "            \n",
    "            result = None\n",
    "            \n",
    "            output = StringIO()\n",
    "            error  = StringIO()\n",
    "            \n",
    "            def oprint(*args):\n",
    "                print(*args, file=output)\n",
    "                \n",
    "            def eprint(*args):\n",
    "                print(*args, file=error)\n",
    "\n",
    "            # trigger execution start event\n",
    "            self.actionPerformed(ExecutionStarted(self.pipeline))\n",
    "            \n",
    "            start_ts = datetime.now(timezone.utc).astimezone(get_localzone())\n",
    "            oprint(\"Pipeline Execution\")\n",
    "            oprint(\"pipeline          : %s\" % name)\n",
    "            oprint(\"pipeline version  : %d\" % self.pipeline.version)\n",
    "            oprint(\"cores             : %d\" % self.cores)\n",
    "            oprint(\"start time        : \",start_ts)\n",
    "            oprint(\"arguments         : %s %s\" % (str(args), str(kwargs)))\n",
    "\n",
    "            # execute the pipeline as a process in order to wait for the result \n",
    "            # or eventually cancel the execution\n",
    "            \n",
    "            exec_info = orch_access.exec_info\n",
    "            \n",
    "            @Async\n",
    "            def execute_pipeline():\n",
    "\n",
    "                # execution process which trigger the pipeline as job \n",
    "                # and wait for it to finish\n",
    " \n",
    "                exec_info = orch_access.exec_info\n",
    "               \n",
    "                try:\n",
    "                    returned_arg = None\n",
    "                    \n",
    "                    orch_access_manager  = orch_access.manager\n",
    "                    orch_access_pipeline = orch_access.pipeline\n",
    "                    \n",
    "                    if self.local_job:\n",
    "                        oprint(\"executing pipeline as process\")\n",
    "                        #orch_access.pipeline = None\n",
    "                        self.job_handler = execute_pipeline_as_local(self.cores, pipeline_fn, orch_access, args, kwargs )\n",
    "                    else:\n",
    "                        oprint(\"executing pipeline as job\")\n",
    "                        # TODO: until providing a better orch_access to be used from compute nodes\n",
    "                        orch_access.pipeline = None\n",
    "                        orch_access.manager = None\n",
    "\n",
    "                        self.job_handler = execute_pipeline_as_job(self.cores, pipeline_fn, orch_access, args, kwargs )\n",
    "\n",
    "                    oprint(\"waiting for pipeline to finish\")\n",
    "                    \n",
    "                    self.start_ts = start_ts\n",
    "                    self.state    = 3  # running\n",
    "\n",
    "                    if not self.em.saveObject(self):\n",
    "                        eprint(\"error saving executor\")\n",
    "                    \n",
    "                    try:\n",
    "                        # wait for the result (the second get is to get the returned argument value)\n",
    "                        if self.local_job:\n",
    "                            h = self.job_handler.get()\n",
    "                            if h is not None:\n",
    "                                returned_arg = h.get()\n",
    "                            else:\n",
    "                                returned_arg = None\n",
    "                        else:\n",
    "                            returned_arg = self.job_handler.get()\n",
    "\n",
    "                        #print(\"returned arg:\",returned_arg)\n",
    "                    except Exception as e:\n",
    "                        print(\"Exception raised when waiting for job:\",e)\n",
    "                        \n",
    "                    success = False\n",
    "                    result = None\n",
    "                    b64_output = None\n",
    "                    b64_error = None\n",
    "\n",
    "                    if returned_arg is not None:\n",
    "                        success, result, b64_output, b64_error, exec_info = returned_arg\n",
    "                        \n",
    "                    if success:\n",
    "                        oprint(\"pipeline execution successfully finished\")\n",
    "                        self.state    = 4  # finished\n",
    "                    else:\n",
    "                        oprint(\"pipeline execution failed\")\n",
    "                        self.state    = 5  # error\n",
    "                    \n",
    "                    if exec_info is not None:\n",
    "                        # update variables and report from orch_access exec_info\n",
    "                        self.pipeline.vars     = exec_info.vars\n",
    "                        self.pipeline.report   = exec_info.report\n",
    "\n",
    "                    self.pipeline.state    = self.state\n",
    "                    \n",
    "                    # get the output\n",
    "                    self.pipeline_ret = base64.b64encode(dill.dumps(result))\n",
    "                    self.pipeline.result = self.pipeline_ret\n",
    "\n",
    "                    self.actionPerformed(ExecutionFinished(self.pipeline))\n",
    "                    \n",
    "                    end_ts = datetime.now(timezone.utc).astimezone(get_localzone())\n",
    "                    self.end_ts = end_ts\n",
    "                    self.exec_time = end_ts - start_ts\n",
    "    \n",
    "                    exec_output = \"No captured output\"\n",
    "                    if b64_output is not None:\n",
    "                        exec_output = base64.b64decode(b64_output).decode('utf8')\n",
    "                \n",
    "                    exec_error = \"No captured output\"\n",
    "                    if b64_error is not None:\n",
    "                        exec_error  = base64.b64decode(b64_error).decode('utf8')\n",
    "            \n",
    "                    exec_output = re.sub(\"(.*):\\/\\/(.*):(.*)@(.*)\",\"\\\\1://*****:******@\\\\4\",exec_output)\n",
    "                    exec_error = re.sub(\"(.*):\\/\\/(.*):(.*)@(.*)\",\"\\\\1://*****:******@\\\\4\",exec_error)\n",
    "   \n",
    "                    if self.pipeline.report is not None:\n",
    "                        oprint(\"=================================================\")\n",
    "                        oprint(\"execution report start\")\n",
    "                        oprint(self.pipeline.report)\n",
    "                        oprint(\"execution report end\")\n",
    "                        oprint(\"=================================================\")\n",
    "    \n",
    "                    oprint(\"=================================================\")\n",
    "                    oprint(\"execution output start\")\n",
    "                    oprint(exec_output)\n",
    "                    eprint(exec_error)\n",
    "                    oprint(\"execution output end\")\n",
    "                    oprint(\"=================================================\")\n",
    "\n",
    "                    oprint(\"pipeline return value\")\n",
    "                    oprint(result)\n",
    "\n",
    "                    oprint(\"pipeline execution complete\")\n",
    "\n",
    "                    output.seek(0)\n",
    "                    error.seek(0)\n",
    "\n",
    "                    self.output   = base64.b64encode(output.read().encode('utf8'))\n",
    "                    self.error    = base64.b64encode(error.read().encode('utf8'))\n",
    "\n",
    "                    if not self.em.saveObject(self):\n",
    "                        eprint(\"error saving executor\")\n",
    "\n",
    "                    # check for execution notification\n",
    "                    if exec_info.notify_execution:\n",
    "                        self.em.sendExecutionNotification(self.pipeline, self.uuid, exec_info.notification_target, show=exec_info.notification_show)\n",
    "    \n",
    "                    # remove the executor from active list in the executor manager\n",
    "                    if self.uuid in self.em.active:\n",
    "                        del self.em.active[self.uuid]\n",
    "                    \n",
    "                    return result\n",
    "                \n",
    "                except Exception as e:\n",
    "                    self.state    = 5  # error\n",
    "                    self.error    = \"%s\" % e\n",
    "\n",
    "                    print(\"exception when running the pipeline %s\" % name)\n",
    "                    print(\"Exception reported:\",e)\n",
    "                    print(traceback.format_exc())\n",
    "                                        \n",
    "                    st = io.StringIO()\n",
    "                    traceback.print_exc(file=st)\n",
    "                    st.seek(0)\n",
    "                    st_str = st.read()\n",
    "\n",
    "                    eprint(e)\n",
    "                    eprint(st_str)\n",
    "                    \n",
    "                    output.seek(0)\n",
    "                    error.seek(0)\n",
    "\n",
    "                    if self.uuid in self.em.active:\n",
    "                        del self.em.active[self.uuid]\n",
    "                    \n",
    "                    if exec_info is None:\n",
    "                        exec_info = orch_access.exec_info\n",
    "                                            \n",
    "                    self.output   = base64.b64encode(output.read().encode('utf8'))\n",
    "                    self.error    = base64.b64encode(error.read().encode('utf8'))\n",
    "\n",
    "                    if not self.em.saveObject(self):\n",
    "                        print(\"error saving executor\")\n",
    "\n",
    "                    # check for execution notification\n",
    "                    if exec_info.notify_execution:\n",
    "                        self.em.sendExecutionNotification(self.pipeline, self.uuid, exec_info.notification_target, show=exec_info.notification_show)\n",
    "                    \n",
    "                    return e\n",
    "                \n",
    "            try:\n",
    "                # execute pipeline as job\n",
    "                self.handler = execute_pipeline()\n",
    "\n",
    "            except Exception as e:\n",
    "                self.output   = None\n",
    "                self.error    = \"%s\" % e\n",
    "                print(e)\n",
    "                \n",
    "            return self\n",
    "        else:\n",
    "            raise ImplementationIsNotAFunction(name)\n",
    "\n",
    "    def cancel(self):\n",
    "        if self.handler is not None:\n",
    "            if self.job_handler is not None:\n",
    "                self.job_handler.cancel()\n",
    "                self.state = 6 # cancelled\n",
    "                \n",
    "                if self.uuid in self.em.active:\n",
    "                    del self.em.active[self.uuid]\n",
    "                    \n",
    "                if not self.em.saveObject(self):\n",
    "                    print(\"error saving executor when cancelling executing\")\n",
    "                else:\n",
    "                    return True\n",
    "        else:\n",
    "            self.state = 6 # cancelled\n",
    "            if self.uuid in self.em.active:\n",
    "                del self.em.active[self.uuid]\n",
    "                \n",
    "            if not self.em.saveObject(self):\n",
    "                print(\"error saving executor when cancelling executing\")\n",
    "            else:\n",
    "                return True\n",
    "        \n",
    "        return False\n",
    "            \n",
    "    def serialize(self):\n",
    "        s_output = None\n",
    "        if self.output is not None:\n",
    "            s_output = self.output.decode(\"utf8\")\n",
    "            \n",
    "        s_error = None\n",
    "        if self.error is not None:\n",
    "            s_error = self.error.decode(\"utf8\")\n",
    "            \n",
    "        s_args = None\n",
    "        if self.pipeline_args is not None:\n",
    "            s_args = self.pipeline_args.decode(\"utf8\")\n",
    "            \n",
    "        obj = {\n",
    "            \"id\"            : self.id,\n",
    "            \"name\"          : self.name,\n",
    "            \"version\"       : self.version,\n",
    "            \"owner_id\"      : self.owner_id,\n",
    "            \"uuid\"          : self.uuid,\n",
    "            \"creation\"      : self.creation,\n",
    "            \"start_ts\"      : self.start_ts,\n",
    "            \"end_ts\"        : self.end_ts,\n",
    "            \"exec_time\"     : self.exec_time,\n",
    "            \"state\"         : self.state,\n",
    "            \"pipeline_fn\"   : self.pipeline_fn.decode(\"utf8\"),            \n",
    "            \"pipeline_args\" : s_args,\n",
    "            \"output\"        : s_output,\n",
    "            \"error\"         : s_error\n",
    "        }\n",
    "        # dict is serialized as b64 dill\n",
    "        sobj = { \"uuid\": self.uuid, \"sobj\": base64.b64encode(dill.dumps(obj)).decode(\"utf8\") }\n",
    "\n",
    "        return sobj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-18T20:33:29.288504Z",
     "start_time": "2024-04-18T20:33:29.207188Z"
    },
    "code_folding": [
     0,
     74
    ]
   },
   "outputs": [],
   "source": [
    "%%deploy /orch/pipelinemanager/ExecutorManager.py\n",
    "# ExecutorManager\n",
    "\n",
    "from ..base import ActionListener, Observable\n",
    "from ..base.db import DataBaseBackend\n",
    "from . import Executor\n",
    "from ..exceptions import InitializeError,MultipleExecutionIDFound,ExecutionIdNotFound\n",
    "\n",
    "from email.message import EmailMessage\n",
    "from email.utils import make_msgid\n",
    "import pandas as pd\n",
    "import smtplib\n",
    "import traceback\n",
    "import re\n",
    "import time\n",
    "import ssl\n",
    "\n",
    "class ExecutorManager(DataBaseBackend,ActionListener, Observable):\n",
    "    \n",
    "    active = {}\n",
    "\n",
    "    def sendMail(self,mail_dst,subject=None, mail_cc=[],bounce_dest=None, mail_content=None, mail_content_html=None, attachments=None):\n",
    "        # compose the email\n",
    "\n",
    "        if self.smtp_crd is None:\n",
    "            print(\"No SMTP configured. unable to send mails\")\n",
    "            return False\n",
    "        \n",
    "        smtp_crd = self.smtp_crd\n",
    "        \n",
    "        sender    = smtp_crd[\"sender\"]\n",
    "        recipient = mail_dst\n",
    "        rcpt = recipient + mail_cc\n",
    "\n",
    "        if bounce_dest is None:\n",
    "            bounce_dest = sender\n",
    "\n",
    "        asparagus_cid = make_msgid()\n",
    "\n",
    "        # bupa relay\n",
    "        server = smtp_crd[\"smtp_host\"]\n",
    "        context = ssl.create_default_context()\n",
    "        with smtplib.SMTP_SSL(server,context=context) as s:\n",
    "            s.set_debuglevel(0)\n",
    "            s.login(smtp_crd[\"username\"],smtp_crd[\"password\"])\n",
    "            msg = EmailMessage()\n",
    "            msg.set_content(mail_content)\n",
    "\n",
    "            msg.add_alternative(mail_content_html, subtype='html')\n",
    "\n",
    "            if attachments is not None:\n",
    "                for file in attachments:\n",
    "\n",
    "                    mime = magic.Magic(mime=True)\n",
    "                    mime_type = mime.from_file(file)\n",
    "\n",
    "                    main_type = mime_type.split(\"/\")[0]\n",
    "                    sub_type = mime_type.split(\"/\")[1]\n",
    "\n",
    "                    with open(file, 'rb') as content_file:\n",
    "                        content = content_file.read()\n",
    "                        msg.add_attachment(content, maintype=main_type, subtype=sub_type, filename=os.path.basename(file))\n",
    "\n",
    "            print(\"sending mail to %s\" % rcpt)\n",
    "\n",
    "            msg['Subject'] = subject\n",
    "            msg['From'] = sender\n",
    "            msg['To'] = recipient\n",
    "            msg['Cc'] = mail_cc\n",
    "\n",
    "            s.sendmail(bounce_dest, rcpt, msg.as_string())\n",
    "\n",
    "            s.quit()\n",
    "\n",
    "    def __init__(self,owner,db_conn_str=\"sqlite:///orchestrator.sqlite\"):\n",
    "        super().__init__(db_conn_str)\n",
    "        self.owner = owner\n",
    "        self.smtp_crd = owner.smtp_crd\n",
    "        if not self.initialize(Executor):\n",
    "            raise InitializeError(Executor.__tablename__)\n",
    "\n",
    "    def create(self,pipeline, *args, **kw_args):\n",
    "        executor = Executor(self, pipeline, *args, **kw_args)\n",
    "        executor.addActionListener(self)\n",
    "        return executor\n",
    "\n",
    "    def getExecutorByID(self, executor_id):\n",
    "        # check executor in active list\n",
    "        if executor_id in self.active:\n",
    "            executor = self.active[executor_id]\n",
    "            return executor\n",
    "        else:\n",
    "            # executor not active. trying to get it from persistency backend\n",
    "            try:\n",
    "                executors = self.getObjects(Executor, uuid=executor_id)                \n",
    "                if len(executors) == 1:\n",
    "                    executors[0].__not_persistent_init__(self)\n",
    "                    executors[0].addActionListener(self)\n",
    "                    \n",
    "                    return executors[0]\n",
    "                elif len(executors) > 1:\n",
    "                    raise MultipleExecutionIDFound(executor_id)\n",
    "                else:\n",
    "                    raise ExecutionIdNotFound(executor_id)\n",
    "            except Exception as e:\n",
    "                raise e\n",
    "            \n",
    "        return None\n",
    "    \n",
    "    def getExecutionList(self, pipeline_name, **kw_args):\n",
    "        exec_list = []\n",
    "        # get the active executions first\n",
    "        for uuid, ex in self.active.items():\n",
    "            if ex.name == pipeline_name:\n",
    "                exec_list.append(ex)\n",
    "                        \n",
    "        # get the executions stored in persistency backend\n",
    "        try:\n",
    "            executors = self.getObjects(Executor, defer_cols=[\"output\",\"error\"],name=pipeline_name, **kw_args)\n",
    "            exec_list = exec_list + executors\n",
    "        except Exception as e:\n",
    "            raise e\n",
    "\n",
    "        return executors\n",
    "    \n",
    "    def getExecutionsBy(self, where, **kw_args):\n",
    "        exec_list = []\n",
    "        \n",
    "        # get the executions stored in persistency backend\n",
    "        try:\n",
    "            rs = self.query(\"select id from executions where %s\" % where)\n",
    "            id_lst = []\n",
    "            for r_id in rs:\n",
    "                id_lst.append(r_id[0])\n",
    "                  \n",
    "            exec_list = self.getObjects(Executor, Executor.id.in_(id_lst), defer_cols=[\"output\",\"error\"])\n",
    "            \n",
    "        except Exception as e:\n",
    "            raise e\n",
    "\n",
    "        return exec_list\n",
    "    \n",
    "    def getRunningExecutions(self):\n",
    "        exec_list = list(self.active.values())\n",
    "        return exec_list\n",
    "    \n",
    "    def sendExecutionNotification(self, pipeline, exec_id, target, show=\"all\"):\n",
    "        \n",
    "        show_arr = show.split(\",\")\n",
    "        for show_item in show_arr:\n",
    "            if not show_item in [\"all\", \"output\",\"error\",\"report\"]:\n",
    "                raise(RuntimeError(\"sendExecutionNotification: show must be a string list (separated by ,) of the following options: all, output,error or report\"))\n",
    "        \n",
    "        print(\"notifying exceution to %s\" % target)\n",
    "        print(\"pipeline:\",pipeline)\n",
    "        \n",
    "        last_exec = self.getExecutorByID(exec_id)\n",
    "        print(\"last execution:\",last_exec)\n",
    "        \n",
    "        show_output    = \"output\" in show_arr\n",
    "        show_error     = \"error\" in show_arr\n",
    "        show_report    = \"report\" in show_arr\n",
    "        \n",
    "        if show==\"all\":\n",
    "            show_output    = True\n",
    "            show_error     = True\n",
    "            show_report    = True\n",
    "        \n",
    "        try:\n",
    "            exec_output = None\n",
    "            exec_error  = None\n",
    "            report      = None\n",
    "            \n",
    "            if show_output or show_error:\n",
    "                for retry in range(0,5):\n",
    "                    last_exec = self.getExecutorByID(exec_id)\n",
    "                    exec_output = last_exec.getOutput()\n",
    "\n",
    "                    if exec_output is None:\n",
    "                        print(\"output not yet ready\")\n",
    "                        time.sleep(10)\n",
    "                    else:\n",
    "                        break\n",
    "\n",
    "                for retry in range(0,5):\n",
    "                    last_exec = self.getExecutorByID(exec_id)\n",
    "                    exec_error  = last_exec.getErrors()\n",
    "\n",
    "                    if exec_error is None:\n",
    "                        print(\"error output not yet ready\")\n",
    "                        time.sleep(10)\n",
    "                    else:\n",
    "                        break\n",
    "\n",
    "                # remove credentials from url like strings\n",
    "                exec_output = re.sub(\"(.*):\\/\\/(.*):(.*)@(.*)\",\"\\\\1://*****:******@\\\\4\",exec_output)\n",
    "                exec_error = re.sub(\"(.*):\\/\\/(.*):(.*)@(.*)\",\"\\\\1://*****:******@\\\\4\",exec_error)\n",
    "\n",
    "            if show_report:\n",
    "                if hasattr(pipeline,\"report\"):\n",
    "                    report = pipeline.report\n",
    "            \n",
    "            subject=\"Pipeline Execution Report: %s\" % pipeline.name\n",
    "\n",
    "            mail_cnt_output  = \"\"\n",
    "            mail_cnt_error   = \"\"\n",
    "            mail_cnt_report  = \"\"\n",
    "            mail_cnt_report_html = \"\"\n",
    "            mail_cnt_output_html = \"\"\n",
    "            mail_cnt_error_html  = \"\"\n",
    "            \n",
    "            if show_output:\n",
    "                mail_cnt_output = f\"\"\"Registro de Ejecucin:\\n{exec_output}\\n\\n\"\"\"\n",
    "                mail_cnt_output_html = f\"\"\"<h2>Registro de Ejecucion</h2><pre>{exec_output}</pre>\"\"\"\n",
    "            if show_error: \n",
    "                mail_cnt_error  = f\"\"\"Registro de Errores:\\n{exec_error}\\n\\n\"\"\"\n",
    "                mail_cnt_error_html  = f\"\"\"<h2>Registro de Errores</h2><pre>{exec_error}</pre>\"\"\"\n",
    "            if show_report:\n",
    "                mail_cnt_report = f\"\"\"Reporte de Ejecucin:\\n{report}\\n\\n\"\"\"\n",
    "                if isinstance(pipeline.report, pd.DataFrame):\n",
    "                    mail_cnt_report_html = f\"\"\"<h2>Reporte de Ejecucin</h2><pre>{report.to_html()}</pre>\"\"\"\n",
    "                else:\n",
    "                    mail_cnt_report_html = f\"\"\"<h2>Reporte de Ejecucin</h2><pre>{report}</pre>\"\"\"\n",
    "            \n",
    "            mail_content=f\"\"\"{mail_cnt_report}{mail_cnt_output}{mail_cnt_error}\\n------------------------------\"\"\"\n",
    "            mail_content_html=f\"\"\"{mail_cnt_report_html}{mail_cnt_output_html}{mail_cnt_error_html}\\n------------------------------\"\"\"\n",
    "            \n",
    "            self.sendMail(target,subject=subject,mail_content=str(mail_content), mail_content_html=str(mail_content_html))\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(\"Error notifying execution to %s\" % target)\n",
    "            print(e)\n",
    "\n",
    "            trc_bk = traceback.format_exc()\n",
    "\n",
    "            print(trc_bk)\n",
    "\n",
    "            subject=\"Pipeline Execution Report: %s\" % pipeline.name\n",
    "\n",
    "            mail_content=f\"\"\"Registro de Ejecucin:\\n{e}\\nRegistro de Errores:\\n{trc_bk}\\n------------------------------\"\"\"\n",
    "            mail_content_html=f\"\"\"<h2>Registro de Ejecucion:</h2><pre>{e}</pre><h2>Registro de Errores:</h2><pre>{trc_bk}</pre>------------------------------\"\"\"\n",
    "            self.sendMail(target,subject=subject,mail_content=str(mail_content), mail_content_html=str(mail_content_html))\n",
    "            \n",
    "        print(\"notification sent to %s\" % target)\n",
    "\n",
    "    def actionPerformed(self, evt):\n",
    "        # onyl forward the event to all listeners\n",
    "        Observable.actionPerformed(self,evt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-18T20:33:29.373633Z",
     "start_time": "2024-04-18T20:33:29.290726Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "%%deploy /orch/pipelinemanager/PipelineManager.py\n",
    "from flask import request, jsonify\n",
    "from multiprocessing import Process, Queue, Manager\n",
    "\n",
    "from datetime import date, datetime, timezone\n",
    "from tzlocal import get_localzone \n",
    "import jsonpickle\n",
    "import dill\n",
    "import inspect\n",
    "import time\n",
    "\n",
    "from ..base import Observable, ActionListener\n",
    "from ..orchestrator import OrchestratorManager\n",
    "from . import PipelineCatalog\n",
    "from . import ExecutorManager\n",
    "from ..exceptions import MultipleActivePipelineRegistered, NoActivePipelineRegistered, PipelineExecutionError, PipelineNotRegistered\n",
    "from .Events import *\n",
    "\n",
    "class PipelineManager(ActionListener, Observable):\n",
    "    def __init__(self, owner,db_conn_str = \"sqlite:///orchestrator.sqlite\"):\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        self.owner            = owner\n",
    "        self.smtp_crd         = owner.smtp_crd\n",
    "        self.catalog          = PipelineCatalog(self,db_conn_str=db_conn_str)\n",
    "        self.executor_manager = ExecutorManager(self, db_conn_str=db_conn_str)\n",
    "        self.db_conn_str = db_conn_str\n",
    "        \n",
    "        self.executor_manager.addActionListener(self)\n",
    "        \n",
    "    def register(self, name, pipeline_fn, new_version = False):\n",
    "        if not new_version:\n",
    "            if not self.catalog.isRegistered(name):\n",
    "                try:\n",
    "                    #TODO: handle the owner in the api\n",
    "                    new_pipeline = self.catalog.register(name,\"jcm\",pipeline_fn)\n",
    "                    return new_pipeline\n",
    "                except Exception as e:\n",
    "                    raise e\n",
    "            # already registered\n",
    "            return self.catalog.get(name=name)\n",
    "        else:\n",
    "            if self.catalog.isRegistered(name):\n",
    "                try:\n",
    "                    #TODO: handle the owner in the api\n",
    "                    new_pipeline = self.catalog.register(name,\"jcm\",pipeline_fn, new_version = True) \n",
    "                    return new_pipeline\n",
    "                except Exception as e:\n",
    "                    raise e\n",
    "            else:\n",
    "                if new_version:\n",
    "                    raise(PipelineNotRegistered(name))\n",
    "                \n",
    "            # already registered\n",
    "            \n",
    "            return self.catalog.get(name=name)\n",
    "\n",
    "    def isRegistered(self,name, **kw_args):\n",
    "        return self.catalog.isRegistered(name,**kw_args)\n",
    "        \n",
    "    def get(self, name, **kw_args): \n",
    "        if self.catalog.isRegistered(name):\n",
    "            try:\n",
    "                pipelines = self.catalog.get(name=name, **kw_args)\n",
    "                return pipelines\n",
    "            except Exception as e:\n",
    "                raise e\n",
    "        \n",
    "        # pipele not registered\n",
    "        return False\n",
    "    \n",
    "    def activate(self, pipeline):\n",
    "        #TODO: check if pipeline is instance of pipeline\n",
    "        if pipeline.isActive():\n",
    "            return True\n",
    "\n",
    "        # deactivate all the pipelines with given name\n",
    "        self.catalog.deactivateAll(pipeline.name)\n",
    "\n",
    "        # activate the pipeline\n",
    "        if pipeline.setActive(True):\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "\n",
    "    def deactivate(self, pipeline):\n",
    "        if not pipeline.isActive():\n",
    "            return True\n",
    "        # deactivate the pipeline\n",
    "        if pipeline.setActive(False):\n",
    "            return True\n",
    "\n",
    "        return False\n",
    "\n",
    "    def deactivateAll(self, pipeline):\n",
    "        return self.catalog.deactivateAll(pipeline.name)\n",
    "\n",
    "    def execution_status(self, exec_id):\n",
    "        executor = self.executor_manager.getExecutorByID(exec_id)        \n",
    "        if executor is not None:            \n",
    "            return executor.state\n",
    "        else:\n",
    "            return None\n",
    "    \n",
    "    def get_execution(self, exec_id):\n",
    "        executor = self.executor_manager.getExecutorByID(exec_id)\n",
    "        \n",
    "        if executor is not None:\n",
    "            return executor\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "    def cancel_execution(self, exec_id):\n",
    "        executor = self.executor_manager.getExecutorByID(exec_id)\n",
    "        \n",
    "        if executor is not None:\n",
    "            return executor.cancel()\n",
    "        else:\n",
    "            return False\n",
    "        \n",
    "    def execute(self, pipeline, *pipeline_args, **pipeline_kwargs):\n",
    "        try:        \n",
    "            executor = self.executor_manager.create(pipeline)\n",
    "            executor.run(*pipeline_args,**pipeline_kwargs)\n",
    "            return executor\n",
    "                \n",
    "        except Exception as e:\n",
    "            raise e\n",
    "\n",
    "    def createExecutor(self, pipeline, *args, **kw_args):\n",
    "        try:        \n",
    "            executor = self.executor_manager.create(pipeline,*args, **kw_args)\n",
    "            return executor\n",
    "                \n",
    "        except Exception as e:\n",
    "            raise e\n",
    "           \n",
    "    def get_execution_list(self,pipeline_name, **kw_args):\n",
    "        if self.catalog.isRegistered(pipeline_name):            \n",
    "            executions = self.executor_manager.getExecutionList(pipeline_name, **kw_args)\n",
    "            \n",
    "            if len(executions)>0:                \n",
    "                return executions\n",
    "            else:\n",
    "                return []\n",
    "\n",
    "        raise PipelineNotRegistered(pipeline_name)\n",
    "        \n",
    "    def get_executions_by(self, where):\n",
    "        executions = self.executor_manager.getExecutionsBy(where)\n",
    "\n",
    "        if len(executions)>0:                \n",
    "            return executions\n",
    "        else:\n",
    "            return []\n",
    "    \n",
    "    def get_running_executions(self):\n",
    "        executions = self.executor_manager.getRunningExecutions()\n",
    "\n",
    "        if len(executions)>0:\n",
    "            return executions\n",
    "        else:\n",
    "            return []\n",
    "    \n",
    "    def actionPerformed(self, evt):\n",
    "        # only forward the event to all listeners\n",
    "        Observable.actionPerformed(self, evt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-18T20:33:29.457943Z",
     "start_time": "2024-04-18T20:33:29.375794Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "%%deploy /orch/pipelinemanager/Events.py\n",
    "from ..base import ActionEvent\n",
    "\n",
    "class ExecutionStarted(ActionEvent):\n",
    "    def __init__(self,pipeline, *args,**kw_args):\n",
    "        super().__init__()\n",
    "        self.pipeline_name = pipeline.name\n",
    "        self.pipeline      = pipeline\n",
    "        \n",
    "class ExecutionFinished(ActionEvent):\n",
    "    def __init__(self,pipeline,*args,**kw_args):\n",
    "        super().__init__()\n",
    "        self.pipeline_name = pipeline.name\n",
    "        self.pipeline      = pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-18T20:33:29.542603Z",
     "start_time": "2024-04-18T20:33:29.460024Z"
    },
    "code_folding": [
     0,
     88
    ]
   },
   "outputs": [],
   "source": [
    "%%deploy /orch/pipelinemanager/executePipelineAsJob.py\n",
    "def execute_pipeline_as_local(cores, pipeline_fn, orch_access, args, kwargs):\n",
    "    from ..base import Argument, asLocalJob\n",
    "    @asLocalJob(cores=cores, verbose=True)\n",
    "    #def run_pipeline_as_local(args):\n",
    "    def run_pipeline_as_local(pipeline_fn, args, kwargs):\n",
    "\n",
    "        import base64\n",
    "        from io import StringIO\n",
    "        import sys\n",
    "        import traceback\n",
    "        import platform\n",
    "        from orch.base import Argument\n",
    "        from contextlib import redirect_stdout, redirect_stderr\n",
    "\n",
    "        import os, psutil\n",
    "\n",
    "        #pipeline_fn, args, kwargs = args.get()\n",
    "       \n",
    "        p_output = StringIO()\n",
    "        p_error  = StringIO()\n",
    "        \n",
    "        result     = None \n",
    "        success    = False\n",
    "        b64_output = \"\"\n",
    "        b64_error  = \"\"\n",
    "       \n",
    "        with redirect_stderr(p_error) as e:\n",
    "            with redirect_stdout(p_output) as o:\n",
    "                try:\n",
    "\n",
    "                    print(\"Execution at        : \", platform.node())\n",
    "                    print(\"executing function  :\",pipeline_fn)\n",
    "                    print(\"Orchestrator Access :\",orch_access)\n",
    "                    \n",
    "                    # make available the orch_access instance to the pipeline\n",
    "                    pipeline_fn.__globals__[\"orch_access\"] = orch_access\n",
    "                    \n",
    "                    result = pipeline_fn(*args,**kwargs)\n",
    "                    \n",
    "                    # memory consumption of current process\n",
    "                    process = psutil.Process(os.getpid())\n",
    "                    orch_access.exec_info.memory = process.memory_full_info().rss\n",
    "                    print(\"Memory Consumption :\",process.memory_info().rss, \"bytes\") \n",
    "\n",
    "                    success = True\n",
    "                except Exception as ex:\n",
    "                    print(\"Exeption when running process as local job:\",ex)\n",
    "                    exc_info = sys.exc_info()\n",
    "                    traceback.print_exception(*exc_info)\n",
    "\n",
    "                    result = ex\n",
    "\n",
    "                    # memory consumption of current process\n",
    "                    process = psutil.Process(os.getpid())\n",
    "                    print(\"Memory Consumption :\",process.memory_info().rss, \"bytes\") \n",
    "                    orch_access.exec_info.memory = process.memory_info().rss\n",
    "                    del exc_info\n",
    "\n",
    "        try:\n",
    "\n",
    "            o.flush()\n",
    "            e.flush()\n",
    "\n",
    "            output = o.getvalue()\n",
    "            error  = e.getvalue()\n",
    "\n",
    "            b64_output = base64.b64encode(output.encode('utf8'))\n",
    "            b64_error  = base64.b64encode(error.encode('utf8'))\n",
    "        except Exception as ex:\n",
    "            print(\"Error encoding output:\",ex)\n",
    "            err_str = \"%s\" % ex\n",
    "\n",
    "            o.flush()\n",
    "            e.flush()\n",
    "\n",
    "            output = o.getvalue()\n",
    "            error  = e.getvalue()\n",
    "\n",
    "            b64_error  = base64.b64encode(err_str.encode('utf8'))\n",
    "            b64_output = base64.b64encode(error.encode('utf8'))\n",
    "        \n",
    "        return Argument((success, result, b64_output ,b64_error, orch_access.exec_info ))\n",
    "\n",
    "    return run_pipeline_as_local(pipeline_fn, args, kwargs )\n",
    "\n",
    "\n",
    "# execute the pipeline as job\n",
    "def execute_pipeline_as_job(cores, pipeline_fn, orch_access, args, kwargs):\n",
    "    from ..base import Argument, asJob\n",
    "\n",
    "    #TODO: handle partition and memory in decorator with defaults \n",
    "    @asJob(cores=cores, verbose=True)\n",
    "    def run_pipeline_as_job(args):\n",
    "        import base64\n",
    "        from io import StringIO\n",
    "        import sys\n",
    "        import traceback\n",
    "        import platform\n",
    "        from orch.base import Argument\n",
    "        from contextlib import redirect_stdout, redirect_stderr\n",
    " \n",
    "        pipeline_fn, args, kwargs = args.get()\n",
    "       \n",
    "        p_output = StringIO()\n",
    "        p_error  = StringIO()\n",
    "        \n",
    "        result     = None \n",
    "        success    = False\n",
    "        b64_output = \"\"\n",
    "        b64_error  = \"\"\n",
    "       \n",
    "        with redirect_stderr(p_error) as e:\n",
    "            with redirect_stdout(p_output) as o:\n",
    "                try:\n",
    "\n",
    "                    print(\"Execution at: \", platform.node())\n",
    "                    print(\"executing function:\",pipeline_fn)\n",
    "\n",
    "                    pipeline_fn.__globals__[\"orch_access\"] = orch_access\n",
    "                    \n",
    "                    result = pipeline_fn(*args,**kwargs)\n",
    "                    success = True\n",
    "                except Exception as ex:\n",
    "                    print(\"Exeption when running function:\",ex)\n",
    "                    exc_info = sys.exc_info()\n",
    "                    traceback.print_exception(*exc_info)\n",
    "\n",
    "                    result = ex\n",
    "\n",
    "                    del exc_info\n",
    "\n",
    "        try:\n",
    "            output = o.getvalue()\n",
    "            error  = e.getvalue()\n",
    "\n",
    "            b64_output = base64.b64encode(output.encode('utf8'))\n",
    "            b64_error  = base64.b64encode(error.encode('utf8'))\n",
    "        except Exception as ex:\n",
    "            print(\"Error encoding output:\",ex)\n",
    "            err_str = \"%s\" % ex\n",
    "            b64_error  = base64.b64encode(err_str.encode('utf8'))\n",
    "            \n",
    "        return Argument( (success, result, b64_output ,b64_error, orch_access) )\n",
    "\n",
    "    return run_pipeline_as_job(Argument( (pipeline_fn, args, kwargs) ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-18T20:33:29.626112Z",
     "start_time": "2024-04-18T20:33:29.549795Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "%%deploy /orch/pipelinemanager/__init__.py\n",
    "\n",
    "from ..base.db import *\n",
    "from .Events import *\n",
    "from .AbstractExecutor import *\n",
    "from .AbstractPipeline import *\n",
    "from .Pipeline import *\n",
    "from .PipelineCatalog import *\n",
    "from .Executor import *\n",
    "from .ExecutorManager import *\n",
    "from .PipelineManager import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-17T03:58:11.638365Z",
     "start_time": "2021-04-17T03:58:11.623858Z"
    }
   },
   "source": [
    "## Scheduler Classes (Server side)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-18T20:33:29.710952Z",
     "start_time": "2024-04-18T20:33:29.627824Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "%%deploy /orch/scheduler/AbstractScheduledEvent.py\n",
    "import base64\n",
    "import dill\n",
    "import inspect\n",
    "\n",
    "# AbstractScheduledEvent\n",
    "\n",
    "class AbstractScheduledEvent(object):\n",
    "    @classmethod\n",
    "    def fromJson(cls, json):\n",
    "        obj = cls()\n",
    "        for k,v in json.items():\n",
    "            setattr(obj, k, v)\n",
    "        return obj\n",
    "    \n",
    "    def setArguments(self,pipeline_args):\n",
    "        self.args = base64.b64encode(dill.dumps(pipeline_args))\n",
    "        \n",
    "    def setKeywordArguments(self,pipeline_kw_args):\n",
    "        self.kw_args = base64.b64encode(dill.dumps(pipeline_kw_args))\n",
    "        \n",
    "    def getArguments(self):\n",
    "        if self.args is not None:\n",
    "            return dill.loads(base64.b64decode(self.args))\n",
    "        else:\n",
    "            return ()\n",
    "\n",
    "    def getKeywordArguments(self):\n",
    "        if self.kw_args is not None:\n",
    "            return dill.loads(base64.b64decode(self.kw_args))\n",
    "        else:\n",
    "            return {}\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return \"<ScheduledEvent[name=%s, owner=%s, uuid=%s, trigger_time=%s, recurrency=%s, active=%s, pipeline=%s]>\" % (\n",
    "            self.name,\n",
    "            self.owner_id,\n",
    "            self.uuid,\n",
    "            self.trigger_time,\n",
    "            self.recurrency,\n",
    "            self.active,\n",
    "            self.pipeline\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-18T20:33:29.799775Z",
     "start_time": "2024-04-18T20:33:29.713140Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "%%deploy /orch/scheduler/TimeEvent.py\n",
    "import time\n",
    "from datetime import timedelta\n",
    "from datetime import datetime\n",
    "from dateutil import parser\n",
    "from pytimeparse.timeparse import timeparse\n",
    "from dateutil.relativedelta import relativedelta\n",
    "\n",
    "from ctparse import ctparse\n",
    "from ctparse.types import Time as ctTime\n",
    "from ctparse.types import Duration as ctDuration\n",
    "from ctparse.types import DurationUnit\n",
    "\n",
    "from ..base import ActionEvent \n",
    "from ..exceptions import EventInThePast\n",
    "\n",
    "class TimeEvent(ActionEvent):\n",
    "\n",
    "    def getTime2Trigger(self,when, recurrency=None, reference=datetime.now()):\n",
    "        evt_time = when\n",
    "        if recurrency is not None:\n",
    "            evt_time = \"%s %s\" % (when, recurrency)\n",
    "        \n",
    "        ctr = ctparse(evt_time,reference).resolution\n",
    "        next_evt_date = None\n",
    "        if isinstance(ctr,ctDuration):\n",
    "            #print(\"duration\",ctr, ctr.unit)\n",
    "            td = None\n",
    "            t = 0\n",
    "            if ctr.unit == DurationUnit.MONTHS:\n",
    "                td = relativedelta(months=ctr.value)\n",
    "                t = 1 \n",
    "            elif ctr.unit == DurationUnit.DAYS:\n",
    "                td = relativedelta(days=ctr.value)\n",
    "                t = 1\n",
    "            elif ctr.unit == DurationUnit.HOURS:\n",
    "                td = relativedelta(hours=ctr.value)\n",
    "            elif ctr.unit == DurationUnit.MINUTES:\n",
    "                td = relativedelta(minutes=ctr.value)\n",
    "            else:\n",
    "                print(\"DurationUnit not handled\",ctr.unit)\n",
    "\n",
    "            ref = parser.parse(when)\n",
    "            if t == 0:\n",
    "                next_evt_date = reference + td\n",
    "            else:\n",
    "                if ref > reference:\n",
    "                    next_evt_date = ref\n",
    "                else:\n",
    "                    next_evt_date = ref + td\n",
    "\n",
    "        elif isinstance(ctr,ctTime):\n",
    "            #print(\"time\",ctr)\n",
    "            if ctr.hasTime:\n",
    "                next_evt_date = datetime(year=ctr.year, month=ctr.month,day=ctr.day, hour=ctr.hour, minute=ctr.minute)\n",
    "            else:\n",
    "                when_tm = time.strptime(when,\"%H:%M\")\n",
    "                next_evt_date = datetime(year=ctr.year, month=ctr.month,day=ctr.day, hour=when_tm.tm_hour, minute=when_tm.tm_min)\n",
    "\n",
    "        return next_evt_date\n",
    "\n",
    "    def __init__(self, label, when=datetime.now(), recurrency_str=None, resolution=1):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.label             = label\n",
    "        self.when              = when\n",
    "        \n",
    "        if recurrency_str is not None and recurrency_str!=\"\":\n",
    "            self.recurrency    = recurrency_str\n",
    "        else:\n",
    "            self.recurrency    = None\n",
    "    \n",
    "        self.evt_time          = None\n",
    "        self.resolution        = resolution\n",
    "\n",
    "        try:\n",
    "            self.evt_time          = self.getTime2Trigger(self.when, self.recurrency)\n",
    "            print(\"Event scheduled at\",self.evt_time)\n",
    "        except Exception as e:\n",
    "            print(\"error computing next event time\")\n",
    "\n",
    "    def updateEventTime(self):\n",
    "      \n",
    "        print(\"updating event time\")\n",
    "        tm = datetime.now()\n",
    "        try:\n",
    "            next_evt_ts = self.getTime2Trigger(self.when, self.recurrency ,tm)\n",
    "\n",
    "            print(\"evt_time      \",self.evt_time)\n",
    "            print(\"next_evt_time \",next_evt_ts)\n",
    "\n",
    "            if self.evt_time is None:\n",
    "                self.evt_time = parser.parse(self.when)\n",
    "\n",
    "            if next_evt_ts > tm:\n",
    "                self.evt_time = next_evt_ts\n",
    "                print(\"Time Event updated:\",self.evt_time)\n",
    "            else:\n",
    "                print(\"next event time in the past\",next_evt_ts, tm)\n",
    "\n",
    "            return next_evt_ts\n",
    "        except Exception as e:\n",
    "            print(\"error computing next event time\")\n",
    "\n",
    "        return None\n",
    "\n",
    "    def isRecurrent(self):\n",
    "        if self.recurrency is not None:\n",
    "            return True\n",
    "        return False\n",
    "        \n",
    "    def getRecurrency(self):\n",
    "        if self.isRecurrent():\n",
    "            try:\n",
    "                evt_time = \"%s %s\" % (self.when, self.recurrency)\n",
    "                ctr = ctparse(evt_time,datetime.now()).resolution\n",
    "                return ctr\n",
    "            except Exception as e:\n",
    "                return self.recurrency\n",
    "        return None\n",
    "        \n",
    "    def trigger(self, tm):\n",
    "        try:\n",
    "            if self.evt_time < tm:\n",
    "                return True\n",
    "        except Exception as e:\n",
    "            print(\"error determining triggering condition for\",self)\n",
    "\n",
    "        return False\n",
    "        \n",
    "    def __repr__(self):\n",
    "        return \"TimeEvent[label=%s,next_evt_time=%s,recurrency=%s]\" % (self.label, self.evt_time, self.getRecurrency())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-18T20:33:29.896923Z",
     "start_time": "2024-04-18T20:33:29.801724Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "%%deploy /orch/scheduler/TimeManager.py\n",
    "from threading import Thread\n",
    "import time\n",
    "from datetime import datetime, timedelta\n",
    "from pytimeparse.timeparse import timeparse\n",
    "import re\n",
    "\n",
    "from ..base import Observable\n",
    "from . import TimeEvent\n",
    "from ..exceptions import EventWithNoRecurrence\n",
    "\n",
    "class TimeManager(Thread, Observable):\n",
    "    def __init__(self, resolution=\"1s\"):\n",
    "        Thread.__init__(self)\n",
    "        Observable.__init__(self)\n",
    "        try:        \n",
    "            self.resolution = timeparse(resolution)\n",
    "        except Exception as e:\n",
    "            raise e\n",
    "        self.running = False\n",
    "        \n",
    "        self.event_list = {}\n",
    "        \n",
    "        self.start()\n",
    "        self.localtime = datetime.now()\n",
    "\n",
    "    def addTimeEvent(self, label, trigger_time_str, recurrency_str=None):\n",
    "        # translate short recurrency format to long one\n",
    "        re_dur  = \"([0-9]*)(m|h|d|M)\"\n",
    "        t = None\n",
    "        \n",
    "        if recurrency_str is not None:\n",
    "            if re.match(re_dur, recurrency_str):\n",
    "                match = re.search(re_dur, recurrency_str)\n",
    "                if match.group(2)==\"m\":\n",
    "                    t = \"%d minutes\" % int(match.group(1))\n",
    "                if match.group(2)==\"h\":\n",
    "                    t = \"%d hours\" % int(match.group(1))\n",
    "                if match.group(2)==\"d\":\n",
    "                    t = \"%d days\" % int(match.group(1))\n",
    "                if match.group(2)==\"M\":\n",
    "                    t = \"%d months\" % int(match.group(1))\n",
    "                recurrency_str = t\n",
    "\n",
    "        self.event_list[label] = TimeEvent(label, trigger_time_str, recurrency_str, self.resolution)\n",
    "        \n",
    "    def removeTimeEvent(self, evt_label):\n",
    "        if evt_label in self.event_list:\n",
    "            del self.event_list[evt_label] \n",
    "            return True\n",
    "        \n",
    "        return False\n",
    "        \n",
    "    def stop(self):\n",
    "        self.running = False\n",
    "        \n",
    "    def run(self):\n",
    "        \n",
    "        print(\"TimeManager starting time:\",datetime.now())\n",
    "        self.running = True\n",
    "        while self.running:\n",
    "            time.sleep(self.resolution)\n",
    "            self.localtime = datetime.now()\n",
    "            for evt_label, evt in list(self.event_list.items()):\n",
    "                try:\n",
    "                    if evt.trigger(self.localtime):\n",
    "                        print(\"triggerred\",evt)\n",
    "                        if evt.isRecurrent():\n",
    "                            # update next event time\n",
    "                            self.event_list[evt_label].updateEventTime()\n",
    "                            \n",
    "                        else:\n",
    "                            print(\"one time event list. removing it\")\n",
    "                            # one time event. removing it from event list\n",
    "                            del self.event_list[evt_label]\n",
    "                            \n",
    "                        # trigger the event to the listeners\n",
    "                        self.actionPerformed(evt)\n",
    "\n",
    "                except Exception as e:\n",
    "                    print(\"TimeManager Exception:\",e)\n",
    "                    print(\"Event:\",evt)\n",
    "\n",
    "        print(\"TimeManager ending time:\",datetime.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-18T20:33:29.980063Z",
     "start_time": "2024-04-18T20:33:29.898762Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "%%deploy /orch/scheduler/ScheduledEvent.py\n",
    "import sqlalchemy as sal\n",
    "from sqlalchemy.ext.declarative import declarative_base\n",
    "from sqlalchemy import create_engine, and_\n",
    "from sqlalchemy.sql import func\n",
    "from uuid import uuid4\n",
    "import base64\n",
    "import dill\n",
    "\n",
    "from ..base import ActionEvent\n",
    "from . import AbstractScheduledEvent\n",
    "\n",
    "# ScheduledEvent\n",
    "# \n",
    "# register the scheduled execution of a pipeline identified by name\n",
    "# the execution time is denoted by trigger time and recurrency\n",
    "# all scheduled events have a name to identify them easily\n",
    "\n",
    "Base = declarative_base()\n",
    "\n",
    "class ScheduledEvent(AbstractScheduledEvent, Base, ActionEvent):\n",
    "    __tablename__ = 'scheduled_events'\n",
    "    \n",
    "    id           = sal.Column('id', sal.Integer, primary_key=True, nullable=False)\n",
    "    name         = sal.Column('name', sal.String)\n",
    "    owner_id     = sal.Column('owner_id', sal.String)\n",
    "    uuid         = sal.Column('uuid', sal.String)\n",
    "    creation     = sal.Column('creation', sal.DateTime(timezone=True),server_default=func.now())\n",
    "    tags         = sal.Column('tags', sal.String)\n",
    "    changed      = sal.Column('changed', sal.DateTime(timezone=True),onupdate=func.now())\n",
    "    active       = sal.Column('active', sal.Boolean)\n",
    "    trigger_time = sal.Column('trigger_time', sal.DateTime(timezone=True))\n",
    "    recurrency   = sal.Column('recurrency', sal.Integer)\n",
    "    pipeline     = sal.Column('pipeline', sal.String)\n",
    "    args         = sal.Column('pipeline_args', sal.TEXT)\n",
    "    kw_args      = sal.Column('pipeline_kw_args', sal.TEXT)\n",
    "    \n",
    "    def __init__(self, schm, label):\n",
    "        self.schm = schm\n",
    "        self.name = label\n",
    "        self.uuid = str(uuid4())\n",
    "        \n",
    "    def serialize(self):\n",
    "        s_args = None\n",
    "        if self.args is not None:\n",
    "            s_args = self.args.decode(\"utf8\")\n",
    "            \n",
    "        s_kw_args = None\n",
    "        if self.kw_args is not None:\n",
    "            s_kw_args = self.kw_args.decode(\"utf8\")\n",
    "            \n",
    "        obj = {\n",
    "            \"id\"            : self.id,\n",
    "            \"name\"          : self.name,\n",
    "            \"owner_id\"      : self.owner_id,\n",
    "            \"uuid\"          : self.uuid,\n",
    "            \"creation\"      : self.creation,\n",
    "            \"tags\"          : self.tags,\n",
    "            \"changed\"       : self.changed,\n",
    "            \"active\"        : self.active,\n",
    "            \"trigger_time\"  : self.trigger_time,\n",
    "            \"recurrency\"    : self.recurrency,            \n",
    "            \"pipeline\"      : self.pipeline,\n",
    "            \"args\"          : s_args,\n",
    "            \"kw_args\"       : s_kw_args\n",
    "        }\n",
    "        # dict is serialized as b64 dill\n",
    "        sobj = { \"uuid\": self.uuid, \"sobj\": base64.b64encode(dill.dumps(obj)).decode(\"utf8\") }\n",
    "\n",
    "        return sobj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-18T20:33:30.062338Z",
     "start_time": "2024-04-18T20:33:29.982093Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "%%deploy /orch/scheduler/Events.py\n",
    "from ..base import ActionEvent\n",
    "\n",
    "class ExecutePipeline(ActionEvent):\n",
    "    def __init__(self,sch_evt_uuid, pipeline, args, kw_args):\n",
    "        super().__init__()\n",
    "        self.sch_evt_uuid = sch_evt_uuid\n",
    "        self.pipeline     = pipeline\n",
    "        self.args         = args\n",
    "        self.kw_args      = kw_args\n",
    "    def __repr__(self):\n",
    "        return \"<ExecutePipeline[sch_evt_uuid=%s, pipeline=%s, args=%s, kw_args=%s]>\" % (\n",
    "            self.sch_evt_uuid,\n",
    "            self.pipeline,\n",
    "            self.args,\n",
    "            self.kw_args\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-18T20:33:30.145647Z",
     "start_time": "2024-04-18T20:33:30.064441Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "%%deploy /orch/scheduler/SchedulerManager.py\n",
    "from datetime import datetime\n",
    "from dateutil import parser\n",
    "\n",
    "from ..base import ActionListener, Observable\n",
    "from ..base.db import DataBaseBackend\n",
    "from ..exceptions import MultipleScheduledEventFound\n",
    "from .TimeManager import TimeManager\n",
    "from .TimeEvent import TimeEvent\n",
    "from .ScheduledEvent import ScheduledEvent\n",
    "from .Events import *\n",
    "\n",
    "class SchedulerManager(DataBaseBackend, ActionListener, Observable):\n",
    "    def __init__(self,owner, time_resolution=\"1s\", db_conn_str=\"sqlite:///orchestrator.sqlite\"):\n",
    "        Observable.__init__(self)\n",
    "        self.owner = owner\n",
    "        self.tm    = TimeManager(time_resolution)\n",
    "\n",
    "        self.tm.addActionListener(self)\n",
    "        super().__init__(db_conn_str)\n",
    "        \n",
    "        if not self.initialize(ScheduledEvent):\n",
    "            raise InitializeError(ScheduledEvent.__tablename__)\n",
    "            \n",
    "        # activate current scheduled pipelines\n",
    "        self.activateScheduledPipelines()\n",
    "            \n",
    "    def activateScheduledPipelines(self):\n",
    "        print(\"activating current scheduled events\")\n",
    "        active_scheduled_events = self.getObjects(ScheduledEvent, active=True)\n",
    "        for sch_evt in active_scheduled_events:\n",
    "            trigger_time_str = sch_evt.trigger_time.strftime(\"%H:%M:%S\")\n",
    "            print(\"scheduling %s\" % sch_evt)\n",
    "            try:\n",
    "                self.tm.addTimeEvent(sch_evt.uuid,trigger_time_str,sch_evt.recurrency)\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "\n",
    "    def scheduleAt(self, pipeline, label = None, trigger_time_str=datetime.now().strftime(\"%H:%M:%S\"), recurrency=None, tags=[]):\n",
    "        \n",
    "        if label is None:\n",
    "            label = pipeline.name\n",
    "        \n",
    "        sch_evt      = ScheduledEvent(self,label)\n",
    "        trigger_time = parser.parse(trigger_time_str)\n",
    "        \n",
    "        sch_evt.owner_id      = self.owner.getOwner()\n",
    "        sch_evt.tags          = \",\".join(tags)\n",
    "        sch_evt.trigger_time  = trigger_time\n",
    "        sch_evt.recurrency    = recurrency\n",
    "        sch_evt.pipeline      = pipeline.name\n",
    "        \n",
    "        if hasattr(pipeline,\"args\"):\n",
    "            print(\"execution args:\",pipeline.args)\n",
    "            sch_evt.setArguments(pipeline.args)\n",
    "        else:\n",
    "            sch_evt.setArguments(tuple())\n",
    "            \n",
    "        if hasattr(pipeline,\"kw_args\"):\n",
    "            print(\"execution kw_args:\",pipeline.kw_args)\n",
    "            sch_evt.setKeywordArguments(pipeline.kw_args)\n",
    "        else:\n",
    "            sch_evt.setKeywordArguments({})\n",
    "            \n",
    "        sch_evt.active        = True\n",
    "        try:\n",
    "            if self.saveObject(sch_evt):\n",
    "                self.tm.addTimeEvent(sch_evt.uuid,trigger_time_str,recurrency)\n",
    "                return True\n",
    "        except Exception as e:\n",
    "            print(\"could not schedule the pipeline\")\n",
    "            raise e\n",
    "\n",
    "    def cancelEvent(self, uuid):\n",
    "        sch_evt_list = self.getObjects(ScheduledEvent, uuid=uuid)\n",
    "            \n",
    "        if len(sch_evt_list)==1:\n",
    "            sch_evt = sch_evt_list[0]\n",
    "            sch_evt.active = False\n",
    "            \n",
    "            if self.saveObject(sch_evt):\n",
    "                self.tm.removeTimeEvent(uuid)\n",
    "                return True\n",
    "            \n",
    "            return False\n",
    "        elif len(sch_evt_list)>1:\n",
    "            print(\"FATAL: multiple scheduled pipelines under the same uuid\",uuid)\n",
    "        else:\n",
    "            print(\"no ScheduledEvent found for uuid\",uuid)\n",
    "        return False\n",
    "            \n",
    "    def actionPerformed(self, evt):\n",
    "        print(\"SchedulerManager: actionEvent arrived\", evt)\n",
    "        sch_evt_list = self.getObjects(ScheduledEvent, uuid=evt.label)\n",
    "        if len(sch_evt_list)==1:\n",
    "            sch_evt = sch_evt_list[0]\n",
    "            if sch_evt.active:\n",
    "            \n",
    "                args = sch_evt.getArguments()\n",
    "                kw_args = sch_evt.getKeywordArguments()\n",
    "\n",
    "                if not evt.isRecurrent():\n",
    "                    print(\"scheduled event not recurrent.\")\n",
    "                    sch_evt.active = False\n",
    "                    self.saveObject(sch_evt)\n",
    "\n",
    "                Observable.actionPerformed(self,ExecutePipeline(sch_evt.uuid, sch_evt.pipeline, args, kw_args))\n",
    "            else:\n",
    "                print(\"SchedulerManager: scheduled event not active. ignoring time event\")\n",
    "                \n",
    "        elif len(sch_evt_list)>1:\n",
    "            print(\"multiple scheduled pipelines under the same uuid.\")\n",
    "        else:\n",
    "            print(\"no ScheduledEvent found for \",evt)\n",
    "            \n",
    "    def getScheduledEvents(self, pipeline, **kw_args):\n",
    "        sch_evt_list = self.getObjects(ScheduledEvent, pipeline=pipeline.name, **kw_args)\n",
    "        return sch_evt_list\n",
    "    \n",
    "    def getScheduledEventById(self, scheduled_event_id):\n",
    "        sch_evt_list = self.getObjects(ScheduledEvent, uuid=scheduled_event_id)\n",
    "        if len(sch_evt_list)==1:\n",
    "            return sch_evt_list[0]\n",
    "        elif len(sch_evt_list)==0:\n",
    "            return None\n",
    "        else:\n",
    "            raise MultipleScheduledEventFound(scheduled_event_id)\n",
    "    \n",
    "    def stop(self):\n",
    "        self.tm.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-18T20:33:30.230582Z",
     "start_time": "2024-04-18T20:33:30.147412Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "%%deploy /orch/scheduler/__init__.py\n",
    "\n",
    "from .TimeEvent import *\n",
    "from .TimeManager import *\n",
    "from .Events import *\n",
    "from .AbstractScheduledEvent import *\n",
    "from .ScheduledEvent import *\n",
    "from .SchedulerManager import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-17T03:59:35.527399Z",
     "start_time": "2021-04-17T03:59:35.513282Z"
    }
   },
   "source": [
    "## Orchestrator Classes (Manager, service and API)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-18T20:33:30.316188Z",
     "start_time": "2024-04-18T20:33:30.232613Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "%%deploy /orch/orchestrator/AbstractRemoteProcedureNotification.py\n",
    "import base64\n",
    "import dill\n",
    "import json\n",
    "\n",
    "# AbstractRemoteProcedureNotification\n",
    "\n",
    "class AbstractRemoteProcedureNotification: \n",
    "    \n",
    "    def addTrigger(self, pipeline_name):\n",
    "\n",
    "        if not hasattr(self, 'data'):\n",
    "            self.data = {}\n",
    "        else:\n",
    "            if isinstance(self.data, str):\n",
    "                self.data = json.loads(self.data)\n",
    "\n",
    "        if \"triggers\" not in self.data:\n",
    "            self.data[\"triggers\"] = []\n",
    "            \n",
    "        self.data[\"triggers\"].append(pipeline_name)\n",
    "  \n",
    "        self.data = json.dumps(self.data)\n",
    "\n",
    "    def getData(self):\n",
    "        if not hasattr(self, 'data'):\n",
    "            self.data = {}\n",
    "            \n",
    "        return json.loads(self.data)\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return \"<RemoteProcedureNotification(id=%s, label='%s', owner='%s', uuid='%s', creation=%s, data='%s'>\" % (\n",
    "            str(self.id), self.label, self.owner_id, self.uuid, self.creation, self.data\n",
    "        )\n",
    "\n",
    "    def __gt__(self, other):\n",
    "        return self.creation > other.creation\n",
    "    \n",
    "    def asJson(self):\n",
    "        return {\n",
    "            \"id\"            : self.id,\n",
    "            \"label\"         : self.label,\n",
    "            \"owner_id\"      : self.owner_id,\n",
    "            \"uuid\"          : self.uuid,\n",
    "            \"creation\"      : self.creation,\n",
    "            \"data\"          : json.dumps(self.data)\n",
    "        }\n",
    "        \n",
    "    @classmethod\n",
    "    def fromJson(cls, json_obj):\n",
    "        obj = cls()\n",
    "        obj.id          = json_obj[\"id\"]\n",
    "        obj.label       = json_obj[\"label\"]\n",
    "        obj.owner_id    = json_obj[\"owner_id\"]\n",
    "        obj.creation    = json_obj[\"creation\"]\n",
    "        obj.uuid        = json_obj[\"uuid\"]\n",
    "        obj.data        = json.loads(json_obj[\"data\"])\n",
    "        \n",
    "        return obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-18T20:33:30.400076Z",
     "start_time": "2024-04-18T20:33:30.317880Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "%%deploy /orch/orchestrator/RemoteProcedureNotification.py\n",
    "import sqlalchemy as sal\n",
    "from sqlalchemy import create_engine, and_\n",
    "from sqlalchemy.sql import func\n",
    "from uuid import uuid4\n",
    "import base64\n",
    "import dill\n",
    "\n",
    "# Remote Procedure Notification\n",
    "from sqlalchemy.ext.declarative import declarative_base\n",
    "from .AbstractRemoteProcedureNotification import *\n",
    "Base = declarative_base()\n",
    "\n",
    "class RemoteProcedureNotification(AbstractRemoteProcedureNotification,Base):\n",
    "    __tablename__ = 'remoteprocedurenotification'\n",
    "    \n",
    "    id         = sal.Column('id', sal.Integer, primary_key=True, nullable=False)\n",
    "    label      = sal.Column('label', sal.String)\n",
    "    owner_id   = sal.Column('owner_id', sal.String)\n",
    "    uuid       = sal.Column('uuid', sal.String)\n",
    "    creation   = sal.Column('creation', sal.DateTime(timezone=True),server_default=func.now())\n",
    "    data       = sal.Column('data', sal.TEXT)\n",
    "    \n",
    "    def serialize(self):            \n",
    "        obj = self.asJson()\n",
    "        # dict is serialized as b64 dill\n",
    "        sobj = { \"uuid\": self.uuid, \"sobj\": base64.b64encode(dill.dumps(obj)).decode(\"utf8\") }\n",
    "\n",
    "        return sobj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-18T20:33:30.488517Z",
     "start_time": "2024-04-18T20:33:30.402169Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "%%deploy /orch/orchestrator/RemoteProcedureNotificationManager.py\n",
    "# RemoteProcedureNotificationManager    \n",
    "import base64\n",
    "import pandas as pd\n",
    "import getpass\n",
    "from uuid import uuid4\n",
    "import json\n",
    "\n",
    "from sqlalchemy.sql import func\n",
    "\n",
    "from ..base import Observable\n",
    "from ..base.db import DataBaseBackend\n",
    "from ..exceptions import InitializeError, NoActivePipelineRegistered, SubscriberNotRegistered, NotificationNotRegistered\n",
    "from .RemoteProcedureNotification import RemoteProcedureNotification\n",
    "\n",
    "from .RemoteProcedureNotificationSubscriber import *\n",
    "\n",
    "class RemoteProcedureNotificationManager(DataBaseBackend,Observable):\n",
    "\n",
    "    def __init__(self, manager, db_conn_str = \"sqlite:///orchestrator.sqlite\"):\n",
    "        \n",
    "        super().__init__(db_conn_str)\n",
    "        \n",
    "        self.manager = manager\n",
    "        \n",
    "        if not self.initialize(RemoteProcedureNotification):\n",
    "            raise InitializeError(RemoteProcedureNotification.__tablename__)\n",
    "\n",
    "        if not self.initialize(RemoteProcedureNotificationSubscriber):\n",
    "            raise InitializeError(RemoteProcedureNotificationSubscriber.__tablename__)\n",
    "\n",
    "    def subscribePipeline(self, label, pipeline_name, owner_id=None):\n",
    "        uuid = str(uuid4())\n",
    "        \n",
    "        if owner_id is None:\n",
    "            owner_id = getpass.getuser()\n",
    "\n",
    "        # verify whether the pipeline exists \n",
    "        pipeline = None\n",
    "        try:\n",
    "            pipeline = self.manager.getActivePipeline(pipeline_name)\n",
    "        except Exception as e:\n",
    "            raise NoActivePipelineRegistered(pipeline_name)\n",
    "\n",
    "        new_subscriber = RemoteProcedureNotificationSubscriber(\n",
    "            label          = label,\n",
    "            owner_id       = owner_id,\n",
    "            uuid           = uuid,\n",
    "            pipeline_name  = pipeline_name\n",
    "        )\n",
    "\n",
    "        if self.saveObject(new_subscriber):\n",
    "            saved_subscriber = self.getObjects(RemoteProcedureNotificationSubscriber,\n",
    "                label     = label, \n",
    "                owner_id  = owner_id,\n",
    "                uuid      = uuid\n",
    "            )\n",
    "            if len(saved_subscriber)==1:\n",
    "                return saved_subscriber[0]\n",
    "            else:\n",
    "                raise SubscriberNotRegistered(label)\n",
    "        else:\n",
    "            raise SubscriberNotRegistered(label)         \n",
    "\n",
    "    def getSubscribedPipelines(self, label, **kw_args):\n",
    "        result = self.getObjects(RemoteProcedureNotificationSubscriber, label=label,**kw_args)\n",
    "        if len(result)>0:\n",
    "            return result\n",
    "        return []\n",
    "\n",
    "    def getSubscriptionsByPipeline(self, pipeline_name, **kw_args):\n",
    "        result = self.getObjects(RemoteProcedureNotificationSubscriber, pipeline_name=pipeline_name,**kw_args)\n",
    "        if len(result)>0:\n",
    "            return result\n",
    "        return []\n",
    "\n",
    "    def unsubscribrePipeline(self, uuid):\n",
    "        result = self.getObjects(RemoteProcedureNotificationSubscriber, uuid=uuid)\n",
    "        if len(result)>0:\n",
    "            for subscriber in result:\n",
    "                self.destroyObject(subscriber)\n",
    "            return True\n",
    "\n",
    "        return False\n",
    "\n",
    "    def getNotifications(self, label, **kw_args):\n",
    "        result = self.getObjects(RemoteProcedureNotification, label=label,**kw_args)\n",
    "        if len(result)>0:\n",
    "            return result\n",
    "        return []\n",
    "\n",
    "    def getLastNotification(self,label,**kw_args):\n",
    "        lst = self.getNotifications(label,**kw_args)\n",
    "        if len(lst)>0:\n",
    "            return max(lst)\n",
    "        return None\n",
    "    \n",
    "    def createNotification(self, label, owner_id=None, data={}):\n",
    "        uuid = str(uuid4())\n",
    "        \n",
    "        if owner_id is None:\n",
    "            owner_id = getpass.getuser()\n",
    "            \n",
    "        new_notification = RemoteProcedureNotification(\n",
    "            label    = label,\n",
    "            owner_id = owner_id,\n",
    "            uuid     = uuid,\n",
    "            data     = json.dumps(data)\n",
    "        )\n",
    "\n",
    "        if self.saveObject(new_notification):\n",
    "            saved_notification = self.getObjects(RemoteProcedureNotification,\n",
    "                label     = label, \n",
    "                owner_id  = owner_id,\n",
    "                uuid      = uuid\n",
    "            )\n",
    "            if len(saved_notification)==1:\n",
    "\n",
    "                notification = saved_notification[0]\n",
    "\n",
    "                subscribers = self.getSubscribedPipelines(label)\n",
    "                for subscriber in subscribers:\n",
    "                    pipeline = self.manager.getActivePipeline(subscriber.pipeline_name)\n",
    "                    if pipeline is not None:\n",
    "                        executor = None\n",
    "                        kw_args = {}\n",
    "                        kw_args[\"rpn_data\"]=data\n",
    "\n",
    "                        if \"event\" in data:\n",
    "                            if data[\"event\"]==\"finished\":\n",
    "                                print(\"chained trigger for finished execution\")\n",
    "                                result = dill.loads(base64.b64decode(data[\"result\"]))\n",
    "                                if isinstance(result,list) or isinstance(result,tuple):\n",
    "                                    executor = self.manager.execute(pipeline, result, **kw_args)\n",
    "                                elif isinstance(result,dict):\n",
    "                                    kw_args.update(result)\n",
    "                                    executor = self.manager.execute(pipeline, **kw_args)\n",
    "                                else:\n",
    "                                    executor = self.manager.execute(pipeline, result, **kw_args)\n",
    "\n",
    "                            elif data[\"event\"]==\"failed\":\n",
    "                                print(\"chained trigger for failed execution\")\n",
    "                                ex = dill.loads(base64.b64decode(data[\"result\"]))\n",
    "                                executor = self.manager.execute(pipeline, ex, **kw_args)\n",
    "\n",
    "                            else:\n",
    "                                # different event\n",
    "                                executor = self.manager.execute(pipeline, result, **kw_args)\n",
    "                        else:\n",
    "                            # normal rpn. rpn_data comes into the kw_args\n",
    "\n",
    "                            executor = self.manager.execute(pipeline, **kw_args)\n",
    "\n",
    "                        print(\"rpn triggering %s\" % pipeline)\n",
    "                        print(\"execution_id: %s\" % executor.getExecutionId())\n",
    "                        notification.addTrigger(subscriber.getPipeline())\n",
    "                        self.saveObject(notification)\n",
    "                    else:\n",
    "                        print(\"no pipeline associated to notification\")\n",
    "\n",
    "                return notification\n",
    "            else:\n",
    "                raise NotificationNotRegistered(label)\n",
    "        else:\n",
    "            raise NotificationNotRegistered(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-18T20:33:30.568663Z",
     "start_time": "2024-04-18T20:33:30.490599Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "%%deploy /orch/orchestrator/AbstractRemoteProcedureNotificationSubscriber.py\n",
    "import base64\n",
    "import dill\n",
    "import json\n",
    "\n",
    "# AbstractRemoteProcedureNotificationSubscriber\n",
    "\n",
    "class AbstractRemoteProcedureNotificationSubscriber: \n",
    "    \n",
    "    def getPipeline(self):\n",
    "        #TODO: get the pipeline from manager\n",
    "        return self.pipeline_name\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return \"<RemoteProcedureNotificationSubscriber(id=%s, label='%s', owner='%s', uuid='%s', creation=%s, pipeline='%s'>\" % (\n",
    "            str(self.id), self.label, self.owner_id, self.uuid, self.creation, self.pipeline_name\n",
    "        )\n",
    "\n",
    "    def asJson(self):\n",
    "        return {\n",
    "            \"id\"            : self.id,\n",
    "            \"label\"         : self.label,\n",
    "            \"owner_id\"      : self.owner_id,\n",
    "            \"uuid\"          : self.uuid,\n",
    "            \"creation\"      : self.creation,\n",
    "            \"pipeline_name\" : self.pipeline_name\n",
    "        }\n",
    "        \n",
    "    @classmethod\n",
    "    def fromJson(cls, json_obj):\n",
    "        obj = cls()\n",
    "        obj.id            = json_obj[\"id\"]\n",
    "        obj.label         = json_obj[\"label\"]\n",
    "        obj.owner_id      = json_obj[\"owner_id\"]\n",
    "        obj.creation      = json_obj[\"creation\"]\n",
    "        obj.uuid          = json_obj[\"uuid\"]\n",
    "        obj.pipeline_name = json_obj[\"pipeline_name\"]\n",
    "        \n",
    "        return obj\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-18T20:33:30.645915Z",
     "start_time": "2024-04-18T20:33:30.570648Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "%%deploy /orch/orchestrator/RemoteProcedureNotificationSubscriber.py\n",
    "import sqlalchemy as sal\n",
    "from sqlalchemy import create_engine, and_\n",
    "from sqlalchemy.sql import func\n",
    "from uuid import uuid4\n",
    "import base64\n",
    "import dill\n",
    "\n",
    "# Remote Procedure Notification Subscriber\n",
    "from sqlalchemy.ext.declarative import declarative_base\n",
    "from .AbstractRemoteProcedureNotificationSubscriber import *\n",
    "Base = declarative_base()\n",
    "\n",
    "class RemoteProcedureNotificationSubscriber(AbstractRemoteProcedureNotificationSubscriber, Base):\n",
    "    __tablename__ = 'rpn_subscriber'\n",
    "    \n",
    "    id            = sal.Column('id', sal.Integer, primary_key=True, nullable=False)\n",
    "    label         = sal.Column('label', sal.String)\n",
    "    owner_id      = sal.Column('owner_id', sal.String)\n",
    "    uuid          = sal.Column('uuid', sal.String)\n",
    "    creation      = sal.Column('creation', sal.DateTime(timezone=True),server_default=func.now())\n",
    "    pipeline_name = sal.Column('pipeline_name', sal.String)\n",
    "    \n",
    "    def serialize(self):            \n",
    "        obj = self.asJson()\n",
    "        # dict is serialized as b64 dill\n",
    "        sobj = { \"uuid\": self.uuid, \"sobj\": base64.b64encode(dill.dumps(obj)).decode(\"utf8\") }\n",
    "\n",
    "        return sobj\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-18T20:33:30.735496Z",
     "start_time": "2024-04-18T20:33:30.647970Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "%%deploy /orch/orchestrator/OrchestratorAccess.py\n",
    "class OrchestratorAccess(object):\n",
    "    \n",
    "    class ExecutionInfo(object):\n",
    "        def __init__(self,notify_execution=False,notification_target=None,notification_show=\"all\",vars={},report=None):\n",
    "            self.notify_execution    = notify_execution\n",
    "            self.notification_target = notification_target\n",
    "            self.notification_show   = notification_show\n",
    "            self.vars                = vars\n",
    "            self.report              = report\n",
    "                \n",
    "        def __reduce_ex__(self,protocol):\n",
    "            return OrchestratorAccess.ExecutionInfo,(self.notify_execution,self.notification_target,self.notification_show, self.vars, self.report)\n",
    "    \n",
    "    def __init__(self, manager, pipeline):\n",
    "        self.manager          = manager\n",
    "        self.pipeline         = pipeline\n",
    "        self.exec_info        = OrchestratorAccess.ExecutionInfo()\n",
    "\n",
    "    def getException(self):\n",
    "        if self.pipeline is not None:\n",
    "            args = self.pipeline.getArguments()\n",
    "            print(\"args:\",args)\n",
    "            if len(args)>0:\n",
    "                if issubclass(type(args[0]),Exception):\n",
    "                    return args[0]\n",
    "        else:\n",
    "            print(\"pipeline none in orch access\")\n",
    "\n",
    "        return None\n",
    "\n",
    "    def getCredential(self, label):\n",
    "        token = self.manager.getToken(label=label, whom=self.pipeline.name)\n",
    "        return self.manager.getRegisterCredential(label, token, whom=self.pipeline.name)\n",
    "\n",
    "    def actionPerformed(self, evt):\n",
    "        return self.manager.actionPerformed(evt)\n",
    "            \n",
    "    def getOwner(self):\n",
    "        return self.manager.getOwner()\n",
    "    \n",
    "    def getPipelines(self, name, **kw_args):\n",
    "        return self.manager.getPipelines(name, **kw_args)\n",
    "    \n",
    "    def isPipelineRegistered(self, name, **kw_args):\n",
    "        return self.manager.isPipelineRegistered(name, **kw_args)\n",
    "    \n",
    "    def getActivePipeline(self, name):\n",
    "        return self.manager.getActivePipeline(name)\n",
    "    \n",
    "    def activatePipeline(self, pipeline):\n",
    "        return self.manager.activatePipeline(pipeline)\n",
    "\n",
    "    def deactivatePipeline(self, pipeline):\n",
    "        return self.manager.deactivatePipeline(pipeline)\n",
    "    \n",
    "    def deactivateAll(self, pipeline):\n",
    "        return self.manager.deactivateAll(pipeline)\n",
    "\n",
    "    def execute(self, pipeline, *args, **kw_args):\n",
    "        return self.manager.execute(pipeline, *args, **kw_args)\n",
    "\n",
    "    def createExecutor(self, pipeline, local=True, cores=1):\n",
    "        return self.manager.createExecutor(pipeline, local, cores)\n",
    " \n",
    "    def getExecutionList(self, name, **kw_args):\n",
    "        return self.manager.getExecutionList(name, **kw_args)\n",
    "    \n",
    "    def getExecution(self, exec_id):\n",
    "        return self.manager.getExecution(exec_id)\n",
    "    \n",
    "    def getLastExecution(self, name):\n",
    "        return self.manager.getLastExecution(name)\n",
    "\n",
    "    def getScheduledExecutions(self, pipeline, **kw_args):\n",
    "        return self.manager.getScheduledExecutions(pipeline, **kw_args)\n",
    "\n",
    "    def getScheduledExecutionById(self, scheduled_event_id):\n",
    "        return self.manager.getScheduledExecutionById(scheduled_event_id)\n",
    "\n",
    "    def getLastNotification(self, label):\n",
    "        return self.manager.getLastNotification(label)\n",
    "        \n",
    "    def getNotificationList(self, label):\n",
    "        return self.manager.getNotificationList(label)\n",
    "\n",
    "    def getSubscribedPipelines(self, label):\n",
    "        return self.manager.getSubscribedPipelines(label)\n",
    "\n",
    "    def getSubscriptionsByPipeline(self, pipeline_name):\n",
    "        return self.manager.getSubscriptionsByPipeline(pipeline_name)\n",
    "    \n",
    "    def credentialExpiration(self, label):   \n",
    "        return self.manager.credentialExpiration(label)\n",
    "                    \n",
    "    def getCredentialExpirationDate(self, label):\n",
    "        return self.manager.getCredentialExpirationDate(label)\n",
    "                        \n",
    "    def getTokenExpirationDate(self, label):\n",
    "        return self.manager.getTokenExpirationDate(label, self.pipeline.name)\n",
    "    \n",
    "    def tokenExpiration(self, label):\n",
    "        return self.manager.tokenExpiration(label, self.pipeline.name)\n",
    "    \n",
    "    def getPublicKey(self):\n",
    "        return self.manager.getPublicKey()\n",
    "\n",
    "    def getAssignedToken(self, label, whom):\n",
    "        return self.manager.getAssignedToken(label, whom)\n",
    "\n",
    "    def checkProcessExpiration(self, process_name):\n",
    "        return self.manager.checkProcessExpiration(process_name)\n",
    "\n",
    "    def putInPersistentDict(self, dict_name, key, value):\n",
    "        return self.manager.putInPersistentDict(dict_name, key, value)\n",
    "    \n",
    "    def getFromPersistentDict(self, dict_name, key):\n",
    "        return self.manager.getFromPersistentDict(dict_name, key)\n",
    "    \n",
    "    def notifyExecution(self, target, show=\"all\"):\n",
    "        self.exec_info.notify_execution = True\n",
    "        self.exec_info.notification_target = target\n",
    "        self.exec_info.notification_show = show\n",
    "    \n",
    "    def createNotifycation(self, label, data={}):\n",
    "        return self.manager.createNotification(label,data=data)\n",
    "        \n",
    "    def addVariable(self,key,value):\n",
    "        self.exec_info.vars[key] = value\n",
    "        \n",
    "    def getVariable(self,key):\n",
    "        if key in self.exec_info.vars:\n",
    "            return self.exec_info.vars[key]\n",
    "        \n",
    "    def setReport(self, report):\n",
    "        self.exec_info.report = report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-18T20:33:30.823621Z",
     "start_time": "2024-04-18T20:33:30.737580Z"
    },
    "code_folding": [
     0,
     12
    ]
   },
   "outputs": [],
   "source": [
    "%%deploy /orch/orchestrator/OrchCredentialManager.py\n",
    "\n",
    "\n",
    "from credentialmanager.CredentialManager import CredentialManager\n",
    "from credentialmanager.KeyChain import KeyChain\n",
    "from credentialmanager.EncryptionKey import *\n",
    "from credentialmanager.Credential import Credential\n",
    "from ..loggers import BasicLogger\n",
    "import jsonpickle\n",
    "\n",
    "\n",
    "class OrchCredentialManager:\n",
    "    def __init__(self, db_conn_str=\"sqlite:///orchestrator.sqlite\"):\n",
    "        self.orchkey = None\n",
    "        self.db_conn_str = db_conn_str\n",
    "        self.key_manager = None\n",
    "        self.credential_manager = None\n",
    "        self.logger = BasicLogger(\"OrchCredentialManager\")\n",
    "        # starting the keychain\n",
    "        if self.key_manager is None:\n",
    "            try:\n",
    "                print(\"checking keychain...\")\n",
    "                self.key_manager = KeyChain(self.db_conn_str)\n",
    "            except Exception as e:\n",
    "                print(\"%s, instance could not be generated...\"%(e))     \n",
    "        # orchestrator validation\n",
    "        try:\n",
    "            self.orchkey = EncryptionKey.load(\"orchestrator\")\n",
    "            print(\"recovered master key for the orchestrator\")\n",
    "            status_key = \"ok\"\n",
    "\n",
    "        except LocalKeyNotFound as e:\n",
    "            try:\n",
    "                print(\"Master key don't found, generating keys...\")\n",
    "                self.orchkey = EncryptionKey(\"orchestrator\")\n",
    "                self.orchkey.save()\n",
    "                status_key = \"ok\"\n",
    "                print(\"successfully created master key\")\n",
    "            except Exception as e:\n",
    "                status_key = \"error\"\n",
    "                print(e)\n",
    "        except Exception as e:\n",
    "            status_key = \"error\"\n",
    "            raise RuntimeError(\"instance could not be generated...\")\n",
    "        # start the credential manager\n",
    "        if status_key == \"ok\":\n",
    "            if self.credential_manager is None:\n",
    "                try:\n",
    "                    print(\"checking credential manager...\")\n",
    "                    self.credential_manager = CredentialManager(self.orchkey, self.db_conn_str)\n",
    "                except Exception as e:\n",
    "                    print(\"%s, instance could not be generated...\"%(e))\n",
    "            \n",
    "    def putKey(self, key, passphrase=None):\n",
    "        \"\"\"Store public key on keychain\"\"\"\n",
    "        try:\n",
    "            self.key_manager.store(key, passphrase)\n",
    "        except Exception as e:\n",
    "            raise e\n",
    "    \n",
    "        \n",
    "    def getKey(self, label, passphrase=None):\n",
    "        \"\"\" get key form keychain \"\"\"\n",
    "        key = None\n",
    "        try:\n",
    "            key = self.key_manager.retrieve(label, passphrase)\n",
    "            key.__class__ = EncryptionKey\n",
    "        except Exception as e:\n",
    "            raise e\n",
    "        return key\n",
    "        \n",
    "        \n",
    "    def getKeyList(self, active=True):\n",
    "        \"\"\"list of keys stored on database\"\"\"\n",
    "        try:\n",
    "            return self.key_manager.getKeyList(active)\n",
    "        except Exception as e:\n",
    "            raise e\n",
    "        \n",
    "    \n",
    "    def keyExpiration(self, key):  \n",
    "        \"\"\"Expiration date of a key is verified\"\"\"\n",
    "        try:\n",
    "            return self.key_manager.checkKeyExpiration(key)\n",
    "        except Exception as e:\n",
    "            return False\n",
    "    \n",
    "    \n",
    "    def setKeyExpiration(self, key, date):\n",
    "        \"\"\"Set expiration date of a key\"\"\"\n",
    "        try:\n",
    "            self.credential_manager.setKeyExpiration(key, date)\n",
    "        except Exception as e:\n",
    "            raise e\n",
    "            \n",
    "            \n",
    "    def getKeyExpirationDate(self, key):\n",
    "        \"\"\"Get expiration date of a key\"\"\"\n",
    "        date = None\n",
    "        try:\n",
    "            date = self.key_manager.getKeyExpirationDate(key)\n",
    "        except Exception as e:\n",
    "            raise e\n",
    "        return date\n",
    "            \n",
    "            \n",
    "    def getCredentialList(self, active=True):\n",
    "        \"\"\"list of credential stored on database\"\"\"\n",
    "        try:\n",
    "            return self.credential_manager.getCredentialList(active)\n",
    "        except Exception as e:\n",
    "            raise e\n",
    "            \n",
    "            \n",
    "    def credentialExpiration(self, label):   \n",
    "        \"\"\"Expiration date of credential is verified\"\"\"\n",
    "        try:\n",
    "            return self.credential_manager.checkCredentialExpiration(label)\n",
    "        except Exception as e:\n",
    "            return False\n",
    "            \n",
    "            \n",
    "    def setCredentialExpiration(self, label, date):\n",
    "        \"\"\"Set expiration date of a credential\"\"\"\n",
    "        try:\n",
    "            self.credential_manager.setCredentialExpiration(label, date)\n",
    "        except Exception as e:\n",
    "            raise e\n",
    "    \n",
    "    \n",
    "    def getCredentialExpirationDate(self, label):\n",
    "        \"\"\"Get expiration date of a credential\"\"\"\n",
    "        date = None\n",
    "        try:\n",
    "            date = self.credential_manager.getCredentialExpirationDate(label)\n",
    "        except Exception as e:\n",
    "            raise e\n",
    "        return date\n",
    "        \n",
    "        \n",
    "    def signCredential(self, credential, key=None):\n",
    "        \"\"\"Sing Credential of current instance and key\"\"\"\n",
    "        if key is None:\n",
    "            key = self.orchkey\n",
    "        self.credential_manager.signCredential(credential, key)\n",
    "        print(\"Credential has been signed\")\n",
    "        \n",
    "    \n",
    "    def putCredential(self, credential, n_unlock=2, shared_users=4):\n",
    "        \"\"\"Register pipelines credentials\"\"\"\n",
    "        try:\n",
    "            self.credential_manager.store(credential, n_unlock, shared_users)\n",
    "        except CredentialAlreadyExists:\n",
    "            print(\"%s already exists\"%(credential.getLabel()))\n",
    "        except Exception as e:\n",
    "            raise e\n",
    "        \n",
    "    \n",
    "    def getCredential(self, label, decrypt=True, token=None, whom=None):\n",
    "        \"\"\"credential is retrieved from credential manager\"\"\"\n",
    "        credential= None\n",
    "        try:\n",
    "            credential= self.credential_manager.retrieve(label, decrypt, token, whom)\n",
    "            credential.__class__ = Credential\n",
    "            print(\"Credential has been retrieve\")\n",
    "        except Exception as e:\n",
    "            raise e\n",
    "        return credential\n",
    "    \n",
    "    \n",
    "    def verifyCredential(self, credential):\n",
    "        \"\"\"Verify Credential of current instance and key\"\"\"\n",
    "        try:\n",
    "            return self.credential_manager.verifyCredential(credential, self.orchkey)\n",
    "        except Exception as e:\n",
    "            raise e\n",
    "        \n",
    "    def encryptCredential(self, credential, recipient_key):\n",
    "        \"\"\"Encrypt credential with recipient key\"\"\"\n",
    "        credential_encrypted = self.credential_manager.encryptCredential(credential, recipient_key)\n",
    "        credential_encrypted.__class__ = Credential\n",
    "        return credential_encrypted\n",
    "    \n",
    "    def createToken(self, credential, n_unlock=2, shared_users=4):\n",
    "        \"\"\"Decrypt credential encoded with Shamir\"\"\"\n",
    "        try:\n",
    "            return self.credential_manager.createToken(credential, n_unlock, shared_users)\n",
    "        except Exception as e:\n",
    "            raise e\n",
    "        \n",
    "        \n",
    "    def putToken(self, credential, token_list):\n",
    "        \"\"\"Stores generated token for credential on database\"\"\"\n",
    "        try:\n",
    "            return self.credential_manager.storeToken(credential, token_list)    \n",
    "        except Exception as e:\n",
    "            raise e\n",
    "        \n",
    "    def registerToken(self, token_list):\n",
    "        \"\"\"register of retrieved tokens (strings) in the orchestrator\"\"\"\n",
    "        try:\n",
    "            for token in token_list:\n",
    "                b64_token = base64.b64decode(token)\n",
    "                token_decode = b64_token.decode('ascii')                             \n",
    "                token_object = jsonpickle.loads(token_decode)\n",
    "                token_object= token_object[0]\n",
    "                credential = self.getCredential(token_object.getLabel(), decrypt=False, token=None, whom=None)\n",
    "                self.credential_manager.storeReceivedToken(credential, token)\n",
    "        except Exception as e:\n",
    "            raise e\n",
    "    \n",
    "    def getToken(self, label=None, whom=None, active=True):\n",
    "        \"\"\"Retrieve token stored on database for credential\"\"\"\n",
    "        try:\n",
    "            return self.credential_manager.retrieveTokens(label, whom, active)\n",
    "        except Exception as e:\n",
    "            raise e\n",
    "    \n",
    "    \n",
    "    def assignToken(self, whom, label, exp_date, comment=\"\"):\n",
    "        \"\"\" Assign inactive tokens to a process \"\"\"\n",
    "        try:\n",
    "            self.credential_manager.assignToken(whom, label, exp_date, comment)\n",
    "        except Exception as e:\n",
    "            raise e\n",
    "    \n",
    "    \n",
    "    def getAssignedToken(self, label=None, whom=None):\n",
    "        \"\"\" Retrieve assigned tokens to share via string \"\"\"\n",
    "        try:\n",
    "            return self.credential_manager.getAssignedToken(label, whom)\n",
    "        except Exception as e:\n",
    "            raise e\n",
    "    \n",
    "    \n",
    "    def signToken(self, label, whom):\n",
    "        \"\"\"Sign credential with key from credential manager\"\"\"\n",
    "        try:\n",
    "            return self.credential_manager.signToken(label, whom)\n",
    "        except Exception as e:\n",
    "            raise e\n",
    "    \n",
    "    \n",
    "    def verifyToken(self, token):\n",
    "        \"\"\"\n",
    "        Check if signed token has been modified\n",
    "        \"\"\"\n",
    "        try:\n",
    "            return self.credential_manager.verifyToken(token)\n",
    "        except Exception as e:\n",
    "            raise e \n",
    "    \n",
    "    \n",
    "    def getTokenList(self, active=False):\n",
    "        \"\"\"Get list of tokens form vault\"\"\"\n",
    "        try:\n",
    "            return self.credential_manager.getTokenList(active)\n",
    "        except Exception as e:\n",
    "            raise e\n",
    "    \n",
    "    \n",
    "    def getTokenExpirationDate(self, label, whom):\n",
    "        \"\"\"Get Date expiration on the related token\"\"\"\n",
    "        try:\n",
    "            return self.credential_manager.getTokenExpirationDate(label, whom)\n",
    "        except Exception as e:\n",
    "            raise e\n",
    "    \n",
    "    \n",
    "    def tokenExpiration(self, label, whom):\n",
    "        \"\"\"Check expiration of the token related to the user\"\"\"\n",
    "        try:\n",
    "            return self.credential_manager.checkTokenExpiration(label, whom)\n",
    "        except Exception as e:\n",
    "            return False\n",
    "        \n",
    "        \n",
    "    def getPublicKey(self):\n",
    "        \"\"\"Public key of the orchestrator is obtained\"\"\"\n",
    "        try:\n",
    "            return EncryptionKey.importPublicKey(self.orchkey.exportPublicKey())\n",
    "        except Exception as e:\n",
    "            raise e\n",
    "            \n",
    "    def getRegisterCredential(self, label, token=None, whom=None):\n",
    "        \"\"\"obtains the credential registered with the orchestrator\"\"\"\n",
    "        token = self.getToken(label=label, whom=whom, active=True)\n",
    "        credential = self.getCredential(label=label,decrypt=True,token=token, whom=whom)\n",
    "        return credential\n",
    "    \n",
    "    def checkProcessExpiration(self, process_name):\n",
    "        \"\"\"Verifies the expiration of credentials and tokens of a pipeline\"\"\"\n",
    "        flag_credential_expired = False\n",
    "        flag_token_expired = False\n",
    "        expired_credential=[]\n",
    "        expired_token=[]\n",
    "        whom = process_name\n",
    "        try:\n",
    "            token_list=self.getToken(label=None, whom=whom, active=True)\n",
    "            for token in token_list:\n",
    "                label = token.getLabel()\n",
    "                status_credential= self.credentialExpiration(label)\n",
    "                status_token= self.tokenExpiration(label, whom)\n",
    "                if status_credential is False:\n",
    "                    flag_credential_expired = True\n",
    "                    expired_credential.append(label)\n",
    "                if status_token is False:\n",
    "                    flag_token_expired = True\n",
    "                    expired_token.append(label)\n",
    "            if flag_credential_expired is True and flag_token_expired is False:\n",
    "                self.logger.info(\"credentials with label:%s has been expired\" % (expired_credential))\n",
    "                return False\n",
    "            elif flag_credential_expired is False and flag_token_expired is True:\n",
    "                self.logger.info(\"Tokens with label:%s for process: %s has been expired\" % (expired_token, whom))\n",
    "                return False\n",
    "            elif flag_credential_expired is True and flag_token_expired is True:\n",
    "                self.logger.info(\"credentials with label:%s and Tokens with label:%s for process:%s has been expired\"\\\n",
    "                    % (expired_credential, expired_token, whom))\n",
    "                return False\n",
    "            elif flag_credential_expired is False and flag_token_expired is False:\n",
    "                 return True\n",
    "        except TokenNotFound as e:\n",
    "            self.logger.info(\"there is no registered token for this pipeline\")\n",
    "            return \"TokenNotFound\"\n",
    "        except Exception as e:\n",
    "            raise e\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-18T20:33:30.913045Z",
     "start_time": "2024-04-18T20:33:30.825751Z"
    },
    "code_folding": [
     0,
     19,
     39,
     82,
     85,
     91,
     94,
     97,
     106,
     109,
     112,
     115,
     122,
     125,
     128,
     131,
     134,
     137,
     140,
     147,
     150,
     155,
     158,
     161,
     164,
     167,
     170,
     181,
     190,
     193,
     196,
     200,
     203,
     206,
     209,
     212,
     215,
     218,
     221,
     224,
     227,
     230,
     233,
     236,
     239,
     242,
     245,
     248,
     251,
     254,
     257,
     260,
     263,
     266,
     269,
     272,
     275,
     278,
     281,
     284,
     287,
     301,
     320
    ]
   },
   "outputs": [],
   "source": [
    "%%deploy /orch/orchestrator/OrchestratorManager.py\n",
    "from datetime import datetime\n",
    "import getpass\n",
    "import json\n",
    "import os\n",
    "import dill\n",
    "import base64\n",
    "\n",
    "from ..base import ActionListener\n",
    "from ..scheduler import SchedulerManager, ScheduledEvent\n",
    "from ..scheduler.Events import *\n",
    "from ..pipelinemanager.Events import *\n",
    "from ..pipelinemanager import PipelineManager\n",
    "from ..exceptions import MultipleActivePipelineRegistered, NoActivePipelineRegistered\n",
    "from ..exceptions import NoSuchKeyInDictionary, NoSuchDictionary\n",
    "from .OrchCredentialManager import OrchCredentialManager\n",
    "from .RemoteProcedureNotificationManager import RemoteProcedureNotificationManager\n",
    "from ..base import PersistentDict\n",
    "\n",
    "class OrchestratorManager(ActionListener):\n",
    "    def __init__(self,db_conn_str=\"sqlite:///orchestrator.sqlite\", smtp_crd=None):\n",
    "        self.owner_id = getpass.getuser()\n",
    "        self.smtp_crd = smtp_crd\n",
    "        self.schm = SchedulerManager(self,db_conn_str=db_conn_str)\n",
    "        self.pm   = PipelineManager(self,db_conn_str=db_conn_str)\n",
    "\n",
    "        #self.ocm  = OrchCredentialManager(db_conn_str=db_conn_str)\n",
    "        # use the default vaults for credential manager\n",
    "        self.ocm  = OrchCredentialManager(db_conn_str = \"sqlite:///./.credentials/credentialVault.sqlite\")\n",
    "\n",
    "        self.rpnm = RemoteProcedureNotificationManager(self,db_conn_str=db_conn_str)\n",
    "        \n",
    "        self.schm.addActionListener(self)\n",
    "        self.pm.addActionListener(self)\n",
    "        self.rpnm.addActionListener(self)\n",
    "        self.db_conn_str = db_conn_str\n",
    "\n",
    "        self.persistent_dict_list = {}\n",
    "        \n",
    "    def actionPerformed(self, evt):\n",
    "        \n",
    "        if isinstance(evt, ExecutePipeline):\n",
    "            # trigger pipeline from SchedulerManager\n",
    "            print(\"OrchestratorManager: trigger\", evt)\n",
    "            try:\n",
    "                pipeline = self.getActivePipeline(evt.pipeline)\n",
    "                \n",
    "                print(\"executing %s with args: %s kw_args: %s\" % (pipeline, evt.args, evt.kw_args))\n",
    "                # include the scheduled_event_uuid in the pipeline instance \n",
    "                # in order ot allow executor to assocaite the execution to the \n",
    "                # scheduled event who triggered the execution\n",
    "                pipeline.scheduled_event_uuid = evt.sch_evt_uuid\n",
    "                self.execute(pipeline, *evt.args, **evt.kw_args)\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(\"Error:\",e)\n",
    "        elif isinstance(evt, ExecutionStarted):\n",
    "            # pipeline manager informing the execution has begun\n",
    "            print(\"execution of pipeline %s started\" % evt.pipeline_name)\n",
    "        elif isinstance(evt, ExecutionFinished):\n",
    "            # pipeline manager informing the execution has finished\n",
    "            print(\"execution of pipeline %s finished\" % evt.pipeline_name)\n",
    "            \n",
    "            pipeline_vars   = evt.pipeline.getVariables()\n",
    "            execution_state = evt.pipeline.state\n",
    "            pipeline_result = evt.pipeline.result.decode(\"utf-8\") \n",
    "           \n",
    "            result_value    = dill.loads(base64.b64decode(pipeline_result))\n",
    "            event_type = \"finished\"\n",
    "            if issubclass(type(result_value),Exception) or execution_state==5:\n",
    "                event_type = \"failed\"\n",
    "            elif execution_state==6:\n",
    "                event_type = \"cancelled\"\n",
    "\n",
    "            pipe_notif_label = \"EP_%s\" % evt.pipeline_name\n",
    "            pipe_exec_data   = {\"event\":event_type, \"pipeline\":evt.pipeline_name, \"variables\":pipeline_vars,\"state\": execution_state, \"result\":pipeline_result}\n",
    "            # trigger RPN for allowing chaining\n",
    "            self.createNotification(pipe_notif_label,data=pipe_exec_data)\n",
    "            \n",
    "        else:\n",
    "            print(\"actionEvent\",evt)\n",
    "            \n",
    "    def getOwner(self):\n",
    "        return self.owner_id\n",
    "    \n",
    "    def register(self, label, pipeline_fn, token_list=None, new_version=False):\n",
    "        if new_version is False or new_version is None:\n",
    "            if token_list is not None:\n",
    "                self.ocm.registerToken(token_list)\n",
    "        return self.pm.register(label,pipeline_fn,new_version)\n",
    "    \n",
    "    def getPipelines(self,name, **kw_args):\n",
    "        return self.pm.get(name,**kw_args)\n",
    "    \n",
    "    def isPipelineRegistered(self,name,**kw_args):\n",
    "        return self.pm.isRegistered(name,**kw_args)\n",
    "    \n",
    "    def getActivePipeline(self, name):\n",
    "        pipelines = self.pm.get(name, active = True)\n",
    "        if len(pipelines)==1:\n",
    "            return pipelines[0]\n",
    "        elif len(pipelines)>1:\n",
    "            raise MultipleActivePipelineRegistered(name)\n",
    "        else:\n",
    "            raise NoActivePipelineRegistered(name)\n",
    "    \n",
    "    def activatePipeline(self, pipeline):\n",
    "        return self.pm.activate(pipeline)\n",
    "\n",
    "    def deactivatePipeline(self, pipeline):\n",
    "        return self.pm.deactivate(pipeline)\n",
    "    \n",
    "    def deactivateAll(self, pipeline):\n",
    "        return self.pm.deactivateAll(pipeline)\n",
    "\n",
    "    def execute(self, pipeline, *args, **kw_args):\n",
    "        # verify expiration of credentials and tokens associated with pipeline\n",
    "        status = self.ocm.checkProcessExpiration(pipeline.name)\n",
    "        if status is False:\n",
    "            raise Exception('Credentials or tokens for pipeline has been expired')\n",
    "        return self.pm.execute(pipeline, *args, **kw_args)\n",
    "\n",
    "    def createExecutor(self, pipeline, *args, **kw_args):\n",
    "        return self.pm.createExecutor(pipeline, *args, **kw_args)   \n",
    " \n",
    "    def getExecutionList(self, name, **kw_args):\n",
    "        return self.pm.get_execution_list(name, **kw_args)\n",
    "\n",
    "    def getExecutionsBy(self, where):\n",
    "        return self.pm.get_executions_by(where)\n",
    "        \n",
    "    def getRunningExecutions(self):\n",
    "        return self.pm.get_running_executions()\n",
    "        \n",
    "    def getExecution(self, exec_id):\n",
    "        return self.pm.get_execution(exec_id)\n",
    "    \n",
    "    def cancelExecution(self, exec_id):\n",
    "        return self.pm.cancel_execution(exec_id)\n",
    "    \n",
    "    def getLastExecution(self, name):\n",
    "        exec_list = self.getExecutionList(name)\n",
    "        if len(exec_list)>0:\n",
    "            last_exec_id = exec_list[-1].getExecutionId()            \n",
    "            return self.getExecution(last_exec_id)\n",
    "        return None\n",
    "    \n",
    "    def scheduleAt(self, pipeline, label = None, trigger_time=datetime.now().strftime(\"%H:%M:%S\"), recurrency=None, tags=[]):\n",
    "        return self.schm.scheduleAt(pipeline, label, trigger_time, recurrency, tags)\n",
    "    \n",
    "    def cancelScheduledExecution(self, scheduled_event):\n",
    "        if isinstance(scheduled_event, ScheduledEvent):\n",
    "            return self.schm.cancelEvent(scheduled_event.uuid)\n",
    "        return None\n",
    "    \n",
    "    def getScheduledExecutions(self, pipeline, **kw_args):\n",
    "        return self.schm.getScheduledEvents(pipeline,**kw_args)\n",
    "\n",
    "    def getScheduledExecutionById(self, scheduled_event_id):\n",
    "        return self.schm.getScheduledEventById(scheduled_event_id)\n",
    "\n",
    "    def createNotification(self,label, data={}):\n",
    "        return self.rpnm.createNotification(label,data=data)\n",
    "        \n",
    "    def getLastNotification(self,label):\n",
    "        return self.rpnm.getLastNotification(label)\n",
    "        \n",
    "    def getNotificationList(self,label):\n",
    "        return self.rpnm.getNotifications(label)\n",
    "\n",
    "    def subscribePipelineNotification(self, label, pipeline_name):\n",
    "\n",
    "        try:\n",
    "            pipeline = self.getActivePipeline(pipeline_name)\n",
    "            if pipeline is not None:\n",
    "                return self.rpnm.subscribePipeline(label, pipeline.name)\n",
    "\n",
    "            raise NoActivePipelineRegistered(pipeline_name)\n",
    "        except Exception as e:\n",
    "            raise e\n",
    "\n",
    "    def unsubscribePipelineNotification(self, label,pipeline_name):\n",
    "\n",
    "        subscriptions = self.rpnm.getSubscribedPipelines(label)\n",
    "        for s in subscriptions:\n",
    "            if s.pipeline_name == pipeline_name:\n",
    "                return self.rpnm.unsubscribrePipeline(s.uuid)\n",
    "\n",
    "        return False\n",
    "\n",
    "    def getSubscribedPipelines(self, label):\n",
    "        return self.rpnm.getSubscribedPipelines(label)\n",
    "\n",
    "    def getSubscriptionsByPipeline(self, pipeline_name):\n",
    "        return self.rpnm.getSubscriptionsByPipeline(pipeline_name)\n",
    "\n",
    "    def stop(self):\n",
    "        print(\"stopping OrchestratorManager\")\n",
    "        self.schm.stop()\n",
    "        \n",
    "    def putKey(self, key, passphrase=None):\n",
    "        self.ocm.putKey(key, passphrase)\n",
    "        \n",
    "    def getKey(self, label, passphrase=None):\n",
    "        return self.ocm.getKey(label, passphrase)\n",
    "        \n",
    "    def getKeyList(self, active=True):\n",
    "        return self.ocm.getKeyList(active)\n",
    "    \n",
    "    def keyExpiration(self, key):\n",
    "        return self.ocm.keyExpiration(key)\n",
    "        \n",
    "    def setKeyExpiration(self, key, date):   \n",
    "        self.ocm.setKeyExpiration(key, date)\n",
    "        \n",
    "    def getKeyExpirationDate(self, key):\n",
    "        return self.ocm.getKeyExpirationDate(key)\n",
    "    \n",
    "    def getCredentialList(self, active=True):\n",
    "        return self.ocm.getCredentialList(active)\n",
    "    \n",
    "    def credentialExpiration(self, label):   \n",
    "        return self.ocm.credentialExpiration(label)\n",
    "            \n",
    "    def setCredentialExpiration(self, label, date):\n",
    "        self.ocm.setCredentialExpiration(label, date)\n",
    "        \n",
    "    def getCredentialExpirationDate(self, label):\n",
    "        return self.ocm.getCredentialExpirationDate(label)\n",
    "        \n",
    "    def signCredential(self, credential, key=None):\n",
    "        self.ocm.signCredential(credential, key)  \n",
    "    \n",
    "    def putCredential(self, credential, n_unlock=2, shared_users=4):\n",
    "        self.ocm.putCredential(credential, n_unlock, shared_users)\n",
    "        \n",
    "    def getCredential(self, label, decrypt=True, token=None, whom=None):\n",
    "        return self.ocm.getCredential(label, decrypt, token, whom)\n",
    "    \n",
    "    def verifyCredential(self, credential):\n",
    "        return self.ocm.verifyCredential(credential)\n",
    "        \n",
    "    def encryptCredential(self, credential, recipient_key):\n",
    "        return self.ocm.encryptCredential(credential, recipient_key)\n",
    "    \n",
    "    def createToken(self, credential, min_unlock=2, shared_users=4):\n",
    "        return self.ocm.createToken(credential, min_unlock, shared_users)\n",
    "\n",
    "    def putToken(self, credential, token_list):\n",
    "        self.ocm.putToken(credential, token_list)\n",
    "        \n",
    "    def registerToken(self, token_list):\n",
    "        self.ocm.registerToken(token_list)\n",
    "\n",
    "    def getToken(self, label=None, whom=None, active=True):\n",
    "        return self.ocm.getToken(label, whom, active)\n",
    "    \n",
    "    def assignToken(self, whom, label, exp_date, comment=\"\"):\n",
    "        return self.ocm.assignToken(whom, label, exp_date, comment)\n",
    "    \n",
    "    def getAssignedToken(self, label, whom):\n",
    "        return self.ocm.getAssignedToken(label, whom)\n",
    "    \n",
    "    def signToken(self, label, whom):\n",
    "        return self.ocm.signToken(label, whom)\n",
    "        \n",
    "    def verifyToken(self, token):\n",
    "        return self.ocm.verifyToken(token)\n",
    "    \n",
    "    def getTokenList(self, active=False):\n",
    "        return self.ocm.getTokenList(active)\n",
    "    \n",
    "    def getTokenExpirationDate(self, label, whom):\n",
    "        return self.ocm.getTokenExpirationDate(label, whom)\n",
    "    \n",
    "    def tokenExpiration(self, label, whom=None):\n",
    "        return self.ocm.tokenExpiration(label, whom)\n",
    "    \n",
    "    def getPublicKey(self):\n",
    "        return self.ocm.getPublicKey()\n",
    "    \n",
    "    def getRegisterCredential(self, label, token=None, whom=None):\n",
    "        return self.ocm.getRegisterCredential(label, token, whom)\n",
    "    \n",
    "    def checkProcessExpiration(self, process_name):\n",
    "        return self.ocm.checkProcessExpiration(process_name)\n",
    "\n",
    "    def putInPersistentDict(self, dict_name, key, value):\n",
    "        if dict_name not in self.persistent_dict_list:\n",
    "            self.persistent_dict_list[dict_name] = PersistentDict(storage_file=\"./.persistentdict/%s.dbm\" % dict_name)\n",
    "\n",
    "        try:\n",
    "            pers_dict = self.persistent_dict_list[dict_name]\n",
    "            pers_dict.put(key,value)\n",
    "            return True\n",
    "\n",
    "        except Exception as e:\n",
    "            raise e\n",
    "\n",
    "        return False\n",
    "    \n",
    "    def getFromPersistentDict(self, dict_name, key):\n",
    "        pdict = None\n",
    "        if not os.path.exists(\"./.persistentdict/%s.dbm\" % dict_name):\n",
    "            raise NoSuchDictionary(dict_name)\n",
    "\n",
    "        if dict_name not in self.persistent_dict_list:\n",
    "            self.persistent_dict_list[dict_name] = PersistentDict(storage_file=\"./.persistentdict/%s.dbm\" % dict_name)\n",
    "\n",
    "        pdict = self.persistent_dict_list[dict_name]\n",
    "\n",
    "        try:\n",
    "            if not pdict.exists(key):\n",
    "                raise NoSuchKeyInDictionary(key)\n",
    "            value = pdict.get(key)\n",
    "\n",
    "            return value\n",
    "        except Exception as e:\n",
    "            raise e\n",
    "    \n",
    "    def notifyExecution(self, target):\n",
    "        print(\"notifyExecution does not work when executing directly the pipeline function\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-18T20:33:31.050594Z",
     "start_time": "2024-04-18T20:33:30.915480Z"
    },
    "code_folding": [
     0,
     97,
     105,
     169,
     200,
     267,
     329,
     359,
     382,
     406,
     439,
     521,
     578,
     616,
     651,
     680,
     724,
     781,
     806,
     809,
     829,
     864,
     884,
     906,
     932,
     954,
     957,
     967,
     1000,
     1028,
     1048,
     1073,
     1112,
     1146,
     1184,
     1214,
     1245,
     1277,
     1302,
     1330,
     1353,
     1380,
     1407,
     1432,
     1459,
     1491,
     1517,
     1539,
     1561,
     1593,
     1619,
     1652,
     1673,
     1708,
     1744
    ]
   },
   "outputs": [],
   "source": [
    "%%deploy /orch/orchestrator/OrchestratorService.py\n",
    "from flask import request, jsonify\n",
    "from multiprocessing import Process, Queue, Manager\n",
    "from datetime import date, datetime, timezone\n",
    "from tzlocal import get_localzone\n",
    "import jsonpickle\n",
    "import inspect\n",
    "import time\n",
    "import dill\n",
    "import base64\n",
    "import ast\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "from ..base import AbstractApiService\n",
    "from ..loggers import BasicLogger\n",
    "from ..scheduler import ScheduledEvent\n",
    "from ..exceptions import MultipleActivePipelineRegistered, NoActivePipelineRegistered,PipelineExecutionError\n",
    "from ..exceptions import NoSuchKeyInDictionary, NoSuchDictionary\n",
    "from .OrchestratorManager import OrchestratorManager\n",
    "from .OrchestratorAccess import OrchestratorAccess\n",
    "\n",
    "from credentialmanager.exceptions import *\n",
    "\n",
    "class OrchestratorService(AbstractApiService):\n",
    "    def __init__(self,address=\"127.0.0.1\", port=8020, db_conn_str=\"sqlite:///orchestrator.sqlite\", smtp_crd=None):\n",
    "        super().__init__(\"OrchestratorService\", bind_addr=address, bind_port=port)\n",
    "        self.smtp_crd = smtp_crd\n",
    "        self.addRule(\"/\",\"status\",self.status)\n",
    "        self.addRule(\"/stop\",\"stop\",self.stop)\n",
    "        self.addRule(\"/register\",\"register\",self.register, methods=[\"POST\"])\n",
    "        self.addRule(\"/get\",\"get\",self.get, methods=[\"POST\"])\n",
    "        self.addRule(\"/activate\",\"activate\",self.activate, methods=[\"POST\"])\n",
    "        self.addRule(\"/deactivate\",\"deactivate\",self.deactivate, methods=[\"POST\"])\n",
    "\n",
    "        # execution\n",
    "        self.addRule(\"/execute\",\"execute\",self.execute, methods=[\"POST\"])\n",
    "        self.addRule(\"/execution/running\",\"running_executions\",self.get_running_executions, methods=[\"GET\"])\n",
    "        self.addRule(\"/execution/getby\",\"get_executions_by\",self.get_executions_by, methods=[\"POST\"])\n",
    "        self.addRule(\"/execution/<exec_id>/status\",\"execution_status\",self.execution_status, methods=[\"GET\"])\n",
    "        self.addRule(\"/execution/<exec_id>/output\",\"execution_output\",self.get_execution_output, methods=[\"GET\"])\n",
    "        self.addRule(\"/execution/<exec_id>/get\",\"get_execution\",self.get_execution, methods=[\"GET\"])\n",
    "        self.addRule(\"/execution/<exec_id>/cancel\",\"cancel_execution\",self.cancel_execution, methods=[\"GET\"])\n",
    "        self.addRule(\"/execution/<pipeline_name>/list\",\"get_execution_list\",self.get_execution_list, methods=[\"GET\"])\n",
    "        self.addRule(\"/execution/<pipeline_name>/last\",\"get_last_execution\",self.get_last_execution, methods=[\"GET\"])\n",
    "        self.addRule(\"/execution/<pipeline_name>/scheduled\",\"get_scheduled_executions\",self.get_scheduled_executions, methods=[\"GET\"])\n",
    "\n",
    "        # scheduling\n",
    "        self.addRule(\"/schedule/<scheduled_execution_id>/cancel\",\"cancel_scheduled_execution\",self.cancel_scheduled_execution, methods=[\"GET\"])\n",
    "        self.addRule(\"/schedule/<scheduled_execution_id>/get\",\"get_scheduled_execution_by_id\",self.get_scheduled_execution_by_id, methods=[\"GET\"])\n",
    "        self.addRule(\"/scheduleAt\",\"scheduleAt\",self.scheduleAt, methods=[\"POST\"])\n",
    "        \n",
    "        # remote procedure notiications\n",
    "        \n",
    "        self.addRule(\"/rpn/<label>/notify\",\"create_notification\",self.create_notification, methods=[\"GET\",\"POST\"])\n",
    "        self.addRule(\"/rpn/<label>/last\",\"get_last_notification\",self.get_last_notification, methods=[\"GET\"])\n",
    "        self.addRule(\"/rpn/<label>/list\",\"get_notification_list\",self.get_notification_list, methods=[\"GET\"])\n",
    "        self.addRule(\"/rpn/<label>/subscribe\",\"subscribe_notification_pipeline\",self.subscribe_notification_pipeline, methods=[\"POST\"])\n",
    "        self.addRule(\"/rpn/<label>/unsubscribe\",\"unsubscribe_notification_pipeline\",self.unsubscribe_notification_pipeline,methods=[\"POST\"])\n",
    "        self.addRule(\"/rpn/<label>/subscribed\",\"get_subscribed_pipelines\",self.get_subscribed_pipelines, methods=[\"GET\"])\n",
    "        \n",
    "        # credential manager\n",
    "        self.addRule(\"/putKey\",\"put_key\",self.put_key, methods=[\"POST\"])\n",
    "        self.addRule(\"/putCredential\",\"put_credential\",self.put_credential, methods=[\"POST\"])\n",
    "        self.addRule(\"/putToken\",\"put_token\",self.put_token, methods=[\"POST\"])\n",
    "        self.addRule(\"/signCredential\",\"sign_credential\",self.sign_credential, methods=[\"POST\"])\n",
    "        self.addRule(\"/verifyCredential\",\"verify_credential\",self.verify_credential, methods=[\"POST\"])\n",
    "        self.addRule(\"/keyExpiration\",\"key_expiration\",self.key_expiration, methods=[\"POST\"])\n",
    "        self.addRule(\"/keyExpirationDate\",\"get_key_expiration_date\",self.get_key_expiration_date, methods=[\"POST\"])\n",
    "        self.addRule(\"/encryptCredential\",\"encrypt_credential\",self.encrypt_credential, methods=[\"POST\"])\n",
    "        self.addRule(\"/createToken\",\"create_token\",self.create_token, methods=[\"POST\"])\n",
    "        self.addRule(\"/key/<label>/<passphrase>/getKey\",\"get_key\",self.get_key, methods=[\"GET\"])\n",
    "        self.addRule(\"/key/getPublicKey\",\"get_public_key\",self.get_public_key, methods=[\"GET\"])\n",
    "        self.addRule(\"/KeyList/<active>\",\"get_key_list\",self.get_key_list, methods=[\"GET\"])\n",
    "        self.addRule(\"/credentialList/<active>\",\"get_credential_list\",self.get_credential_list, methods=[\"GET\"])\n",
    "        self.addRule(\"/getCredential\",\"get_credential\",self.get_credential, methods=[\"POST\"])\n",
    "        self.addRule(\"/credential/<label>/<whom>/<active>/getToken\",\"get_token\",self.get_token, methods=[\"GET\"])\n",
    "        self.addRule(\"/credential/<label>/credentialExpiration\",\"credential_expiration\",self.credential_expiration, methods=[\"GET\"])\n",
    "        self.addRule(\"/credential/<label>/credentialExpirationDate\",\"get_credential_expiration_date\",self.get_credential_expiration_date, methods=[\"GET\"])\n",
    "        self.addRule(\"/credential/<label>/<token>/<whom>/getRegisterCredential\",\"get_register_credential\",self.get_register_credential, methods=[\"GET\"])\n",
    "        self.addRule(\"/assignToken\",\"assign_token\",self.assign_token, methods=[\"POST\"])\n",
    "        self.addRule(\"/token/<label>/<whom>/getAssignedToken\",\"get_assigned_token\",self.get_assigned_token, methods=[\"GET\"])\n",
    "        self.addRule(\"/signToken\",\"sign_token\",self.sign_token, methods=[\"POST\"])\n",
    "        self.addRule(\"/verifyToken\",\"verify_token\",self.verify_token, methods=[\"POST\"])\n",
    "        self.addRule(\"/tokenList/<active>\",\"get_token_list\",self.get_token_list, methods=[\"GET\"])\n",
    "        self.addRule(\"/token/<label>/<whom>/tokenExpirationDate\",\"get_token_expiration_date\",self.get_token_expiration_date, methods=[\"GET\"])\n",
    "        self.addRule(\"/token/<label>/<whom>/tokenExpiration\",\"token_expiration\",self.token_expiration, methods=[\"GET\"])\n",
    "        \n",
    "        # Persistent Dict\n",
    "        self.addRule(\"/pd/<dict_name>/put\",\"pd_put\",self.put_persistent_dict, methods=[\"POST\"])\n",
    "        self.addRule(\"/pd/<dict_name>/get/<key>\",\"pd_get\",self.get_persistent_dict, methods=[\"GET\"])\n",
    "        self.addRule(\"/pd/<dict_name>/get/<key>/asJson\",\"pd_get_as_json\",self.get_persistent_dict_as_json, methods=[\"GET\"])\n",
    "\n",
    "        self.manager = OrchestratorManager(db_conn_str=db_conn_str, smtp_crd=self.smtp_crd)\n",
    "        \n",
    "        self.setLogger(BasicLogger(\"OrchestratorService\"))\n",
    "        \n",
    "    def status(self):\n",
    "        now = datetime.now(timezone.utc).astimezone(get_localzone())\n",
    "        return {\n",
    "            \"code\"   : 200,\n",
    "            \"status\" : \"running\",\n",
    "            \"ts\"     : now.isoformat()\n",
    "        }\n",
    "    \n",
    "    def register(self):\n",
    "        now = datetime.now(timezone.utc).astimezone(get_localzone())\n",
    "        json_input = request.json\n",
    "        \n",
    "        name         = json_input[\"name\"]\n",
    "        pipeline_fn  = dill.loads(base64.b64decode(json_input[\"pipeline\"].encode(\"utf8\")))\n",
    "        new_version  = json_input[\"new_version\"]\n",
    "        token_list   = ast.literal_eval(json_input[\"token_list\"])\n",
    "\n",
    "        if not new_version:\n",
    "            if not self.manager.isPipelineRegistered(name):\n",
    "                self.logger.info(\"registering first version for %s\" % name)\n",
    "                try:\n",
    "                    #TODO: handle the owner in the api\n",
    "                    new_pipeline = self.manager.register(name,pipeline_fn,token_list)\n",
    "\n",
    "                    return {\n",
    "                        \"code\"   : 200,\n",
    "                        \"status\" : \"registered\",\n",
    "                        \"ts\"     : now.isoformat()\n",
    "                    }\n",
    "                except Exception as e:\n",
    "                    self.logger.info(\"error registering %s: %s\" % (name,e))\n",
    "                    return {\n",
    "                        \"code\"   : 302,\n",
    "                        \"status\" : \"Could not register pipeline\",\n",
    "                        \"error\"  : \"%s\" % e,\n",
    "                        \"ts\"     : now.isoformat()\n",
    "                    }\n",
    "\n",
    "            self.logger.info(\"already registered %s\" % name)\n",
    "            return {\n",
    "                \"code\"   : 301,\n",
    "                \"status\" : \"Already Registered\",\n",
    "                \"ts\"     : now.isoformat()\n",
    "            }\n",
    "        else:\n",
    "            if self.manager.isPipelineRegistered(name):\n",
    "                self.logger.info(\"registering new version for %s\" % name)\n",
    "                try:\n",
    "                    #TODO: handle the owner in the api\n",
    "                    new_pipeline = self.manager.register(name,pipeline_fn,token_list,new_version = True)\n",
    "\n",
    "                    return {\n",
    "                        \"code\"   : 200,\n",
    "                        \"status\" : \"new version registered: %f\" % new_pipeline.version,\n",
    "                        \"ts\"     : now.isoformat()\n",
    "                    }\n",
    "                except Exception as e:\n",
    "                    self.logger.info(\"error registering %s: %s\" % (name,e))\n",
    "                    return {\n",
    "                        \"code\"   : 302,\n",
    "                        \"status\" : \"Could not register pipeline\",\n",
    "                        \"error\"  : \"%s\" % e,\n",
    "                        \"ts\"     : now.isoformat()\n",
    "                    }\n",
    "\n",
    "            self.logger.info(\"no previous versions for pipeline %s found\" % name)\n",
    "            return {\n",
    "                \"code\"   : 301,\n",
    "                \"status\" : \"No previous version found for pipeline %s\" % name,\n",
    "                \"ts\"     : now.isoformat()\n",
    "            }\n",
    "\n",
    "    def get(self): \n",
    "        now = datetime.now(timezone.utc).astimezone(get_localzone())\n",
    "        json_input = request.json\n",
    "                \n",
    "        name        = json_input[\"name\"]\n",
    "        \n",
    "        if self.manager.isPipelineRegistered(name):\n",
    "            self.logger.info(\"getting %s\" % name)\n",
    "            try:\n",
    "                pipelines = self.manager.getPipelines(**json_input)\n",
    "                return {\n",
    "                    \"code\"     : 200,\n",
    "                    \"status\"   : \"ok\",\n",
    "                    \"pipeline\" : [p.asJson() for p in pipelines],\n",
    "                    \"ts\"       : now.isoformat()\n",
    "                }\n",
    "            except Exception as e:\n",
    "                self.logger.info(\"error getting %s: %s\" % (name,e))\n",
    "                return {\n",
    "                    \"code\"   : 302,\n",
    "                    \"status\" : \"%s\" % e,\n",
    "                    \"ts\"     : now.isoformat()\n",
    "                }\n",
    "        \n",
    "        self.logger.info(\"pipeline not registered %s\" % name)\n",
    "        return {\n",
    "            \"code\"   : 301,\n",
    "            \"status\" : \"Pipeline Not Registered\",\n",
    "            \"ts\"     : now.isoformat()\n",
    "        }\n",
    "    \n",
    "    def activate(self):\n",
    "        now = datetime.now(timezone.utc).astimezone(get_localzone())\n",
    "        json_input = request.json\n",
    "\n",
    "        name        = json_input[\"name\"]\n",
    "        \n",
    "        if self.manager.isPipelineRegistered(name):\n",
    "            self.logger.info(\"getting %s\" % name)\n",
    "            try:\n",
    "                pipelines = self.manager.getPipelines(**json_input)\n",
    "                \n",
    "                if len(pipelines)==1:\n",
    "                    pipeline = pipelines[0]\n",
    "                    \n",
    "                    if pipeline.isActive():\n",
    "                        return {\n",
    "                            \"code\"     : 203,\n",
    "                            \"status\"   : \"already active\",\n",
    "                            \"ts\"       : now.isoformat()\n",
    "                        }\n",
    "                    \n",
    "                    # deactivate all the pipelines with given name\n",
    "                    self.manager.deactivateAll(pipeline)\n",
    "                    \n",
    "                    # activate the pipeline\n",
    "                    if pipeline.setActive(True):\n",
    "                        return {\n",
    "                            \"code\"     : 202,\n",
    "                            \"status\"   : \"active\",\n",
    "                            \"ts\"       : now.isoformat()\n",
    "                        }\n",
    "                    else:\n",
    "                        return {\n",
    "                            \"code\"   : 306,\n",
    "                            \"status\" : \"could not activate pipeline %s\" % name,\n",
    "                            \"ts\"     : now.isoformat()\n",
    "                        }\n",
    "                        \n",
    "                elif len(pipelines)>1:\n",
    "                    # this should never happend (multiple active pipelines)\n",
    "                    e = MultiplePipelineFound(name)\n",
    "                    return {\n",
    "                        \"code\"   : 305,\n",
    "                        \"status\" : \"%s:%s\" % (type(e).__name__,e),\n",
    "                        \"ts\"     : now.isoformat()\n",
    "                    }\n",
    "                else:\n",
    "                    return {\n",
    "                        \"code\"   : 307,\n",
    "                        \"status\" : \"pipeline not found or already active:\" % name,\n",
    "                        \"ts\"     : now.isoformat()\n",
    "                    }\n",
    "            except Exception as e:            \n",
    "                self.logger.info(\"error getting %s: %s\" % (name,e))\n",
    "                return {\n",
    "                    \"code\"   : 305,\n",
    "                    \"status\" : \"%s:%s\" % (type(e).__name__,e),\n",
    "                    \"ts\"     : now.isoformat()\n",
    "                }\n",
    "        \n",
    "        self.logger.info(\"pipeline not registered %s\" % label)\n",
    "        return {\n",
    "            \"code\"   : 301,\n",
    "            \"status\" : \"Pipeline Not Registered\",\n",
    "            \"ts\"     : now.isoformat()\n",
    "        }\n",
    "\n",
    "    def deactivate(self):\n",
    "        now = datetime.now(timezone.utc).astimezone(get_localzone())\n",
    "        json_input = request.json\n",
    "                \n",
    "        name        = json_input[\"name\"]\n",
    "        \n",
    "        if self.manager.isPipelineRegistered(name):\n",
    "            self.logger.info(\"getting %s\" % name)\n",
    "            try:\n",
    "                pipelines = self.manager.getPipelines(**json_input, active = True)\n",
    "                \n",
    "                if len(pipelines)==1:\n",
    "                    pipeline = pipelines[0]\n",
    "                    \n",
    "                    if not pipeline.isActive():\n",
    "                        return {\n",
    "                            \"code\"     : 203,\n",
    "                            \"status\"   : \"already not active\",\n",
    "                            \"ts\"       : now.isoformat()\n",
    "                        }\n",
    "                    # deactivate the pipeline\n",
    "                    if pipeline.setActive(False):\n",
    "                        return {\n",
    "                            \"code\"     : 202,\n",
    "                            \"status\"   : \"not active\",\n",
    "                            \"ts\"       : now.isoformat()\n",
    "                        }\n",
    "                    else:\n",
    "                        return {\n",
    "                            \"code\"   : 308,\n",
    "                            \"status\" : \"could not deactivate pipeline %s\" % name,\n",
    "                            \"ts\"     : now.isoformat()\n",
    "                        }\n",
    "                        \n",
    "                elif len(pipelines)>1:\n",
    "                    e = MultipleActivePipelineRegistered(name)\n",
    "                    return {\n",
    "                        \"code\"   : 305,\n",
    "                        \"status\" : \"%s:%s\" % (type(e).__name__,e),\n",
    "                        \"ts\"     : now.isoformat()\n",
    "                    }\n",
    "                else:\n",
    "                    return {\n",
    "                        \"code\"   : 307,\n",
    "                        \"status\" : \"pipeline not found or already deactivated:\" % name,\n",
    "                        \"ts\"     : now.isoformat()\n",
    "                    }\n",
    "            except Exception as e:\n",
    "                self.logger.info(\"error getting %s: %s\" % (name,e))\n",
    "                return {\n",
    "                    \"code\"   : 305,\n",
    "                    \"status\" : \"%s:%s\" % (type(e).__name__,e),\n",
    "                    \"ts\"     : now.isoformat()\n",
    "                }\n",
    "        \n",
    "        self.logger.info(\"pipeline not registered %s\" % label)\n",
    "        return {\n",
    "            \"code\"   : 301,\n",
    "            \"status\" : \"Pipeline Not Registered\",\n",
    "            \"ts\"     : now.isoformat()\n",
    "        }\n",
    "    \n",
    "    def execution_status(self, exec_id):\n",
    "        now = datetime.now(timezone.utc).astimezone(get_localzone())\n",
    "        print(\"%s : getting status for execution id %s\" % (now, exec_id))\n",
    "        \n",
    "        executor = self.manager.getExecution(exec_id)\n",
    "        \n",
    "        if executor is not None:\n",
    "            return {\n",
    "                \"code\"         : 202,\n",
    "                \"status\"       : \"executor active\",\n",
    "                \"state\"        : executor.state,\n",
    "                \"start_ts\"     : executor.start_ts,\n",
    "                \"end_ts\"       : executor.end_ts,\n",
    "                \"exec_time\"    : executor.exec_time,\n",
    "                \"state\"        : executor.state,\n",
    "                \"return_value\" : executor.pipeline_ret,\n",
    "                \"version\"      : executor.version,\n",
    "                \"creation\"     : executor.creation,\n",
    "                \"execution_id\" : exec_id,\n",
    "                \"ts\"           : now.isoformat()\n",
    "            }\n",
    "        else:\n",
    "            return {\n",
    "                \"code\"         : 310,\n",
    "                \"status\"       : \"Executor gone\",\n",
    "                \"state\"        : \"unknown\",\n",
    "                \"execution_id\" : exec_id,\n",
    "                \"ts\"           : now.isoformat()\n",
    "            }\n",
    "    \n",
    "    def get_execution(self, exec_id):\n",
    "        now = datetime.now(timezone.utc).astimezone(get_localzone())\n",
    "        print(\"%s : getting execution id %s\" % (now, exec_id))\n",
    "        \n",
    "        executor = self.manager.getExecution(exec_id)\n",
    "        \n",
    "        if executor is not None:\n",
    "            return {\n",
    "                \"code\"         : 202,\n",
    "                \"status\"       : \"ok\",\n",
    "                \"executor\"     : executor.serialize(),\n",
    "                \"execution_id\" : exec_id,\n",
    "                \"ts\"           : now.isoformat()\n",
    "            }\n",
    "        else:\n",
    "            return {\n",
    "                \"code\"         : 310,\n",
    "                \"status\"       : \"Executor does not exists\",\n",
    "                \"executor\"     : \"\",\n",
    "                \"execution_id\" : exec_id,\n",
    "                \"ts\"           : now.isoformat()\n",
    "            }\n",
    " \n",
    "    def get_execution_output(self, exec_id):\n",
    "        now = datetime.now(timezone.utc).astimezone(get_localzone())\n",
    "        print(\"%s : getting output for execution id %s\" % (now, exec_id))\n",
    "        \n",
    "        executor = self.manager.getExecution(exec_id)\n",
    "        \n",
    "        if executor is not None:\n",
    "            return {\n",
    "                \"code\"         : 202,\n",
    "                \"status\"       : \"ok\",\n",
    "                \"output\"       : executor.getOutput(),\n",
    "                \"error\"        : executor.getErrors(),\n",
    "                \"execution_id\" : exec_id,\n",
    "                \"ts\"           : now.isoformat()\n",
    "            }\n",
    "        else:\n",
    "            return {\n",
    "                \"code\"         : 310,\n",
    "                \"status\"       : \"Executor does not exists\",\n",
    "                \"executor\"     : \"\",\n",
    "                \"execution_id\" : exec_id,\n",
    "                \"ts\"           : now.isoformat()\n",
    "            }\n",
    "   \n",
    "    def cancel_execution(self, exec_id):\n",
    "        now = datetime.now(timezone.utc).astimezone(get_localzone())\n",
    "        print(\"%s : cancelling execution id %s\" % (now, exec_id))\n",
    "        \n",
    "        executor = self.manager.getExecution(exec_id)\n",
    "        if executor is not None:\n",
    "            if self.manager.cancelExecution(exec_id):\n",
    "                executor = self.manager.getExecution(exec_id)\n",
    "                return {\n",
    "                    \"code\"         : 202,\n",
    "                    \"status\"       : \"ok\",\n",
    "                    \"executor\"     : executor.serialize(),\n",
    "                    \"execution_id\" : exec_id,\n",
    "                    \"ts\"           : now.isoformat()\n",
    "                }\n",
    "            else:\n",
    "                executor = self.manager.getExecution(exec_id)\n",
    "                return {\n",
    "                    \"code\"         : 311,\n",
    "                    \"status\"       : \"Executor could not be cancelled\",\n",
    "                    \"executor\"     : executor.serialize(),\n",
    "                    \"execution_id\" : exec_id,\n",
    "                    \"ts\"           : now.isoformat()\n",
    "                }\n",
    "        else:\n",
    "            return {\n",
    "                \"code\"         : 310,\n",
    "                \"status\"       : \"No such Executor\",\n",
    "                \"executor\"     : \"\",\n",
    "                \"execution_id\" : exec_id,\n",
    "                \"ts\"           : now.isoformat()\n",
    "            }\n",
    "    \n",
    "    def execute(self):\n",
    "        now = datetime.now(timezone.utc).astimezone(get_localzone())\n",
    "        json_input = request.json\n",
    "        \n",
    "        pipeline_args   = []\n",
    "        pipeline_kwargs = {}\n",
    "        \n",
    "        name            = json_input[\"name\"]\n",
    "        version         = json_input[\"version\"]\n",
    "\n",
    "        local_job       = True\n",
    "        cores           = 1\n",
    "        partition       = None\n",
    "        memory          = None\n",
    "\n",
    "        if \"asJob\" in json_input:\n",
    "            local_job = json_input[\"asJob\"]\n",
    "\n",
    "        if \"cores\" in json_input:\n",
    "            cores = int(json_input[\"cores\"])\n",
    "\n",
    "        if \"partition\" in json_input:\n",
    "            partition = int(json_input[\"partition\"])\n",
    "\n",
    "        if \"memory\" in json_input:\n",
    "            memory = int(json_input[\"memory\"])\n",
    "\n",
    "        if \"args\" in json_input:\n",
    "            pipeline_args   = jsonpickle.loads(json_input[\"args\"])\n",
    "        \n",
    "        if \"kwargs\" in json_input:\n",
    "            pipeline_kwargs = jsonpickle.loads(json_input[\"kwargs\"])\n",
    "\n",
    "        pipelines = []\n",
    "        try:        \n",
    "            pipelines = self.manager.getPipelines(name = name, version = version)\n",
    "            \n",
    "        except Exception as e:\n",
    "            return {\n",
    "                \"code\"        : 305,\n",
    "                \"status\"      : \"%s : %s\" % (type(e).__name__, e),\n",
    "                \"ts\"          : now.isoformat()\n",
    "            }\n",
    "        \n",
    "        if len(pipelines)==1:\n",
    "            pipeline = pipelines[0]\n",
    "            try:\n",
    "                executor = None\n",
    "                if local_job:\n",
    "                    executor = self.manager.execute(pipeline, *pipeline_args,**pipeline_kwargs)\n",
    "                else:\n",
    "                    executor = self.manager.createExecutor(pipeline, local = local_job, cores=cores, partition=partition, memory=memory)\n",
    "                    executor.run(*pipeline_args,**pipeline_kwargs)\n",
    "\n",
    "                return {\n",
    "                    \"code\"         : 201,\n",
    "                    \"status\"       : executor.state,\n",
    "                    \"execution_id\" : executor.getExecutionId(),\n",
    "                    \"ts\"           : now.isoformat()\n",
    "                }\n",
    "            except Exception as e:\n",
    "                self.logger.info(\"execution failed:\",e)\n",
    "                return {\n",
    "                    \"code\"        : 303,\n",
    "                    \"status\"      : \"Execution failed. %s\" % e,\n",
    "                    \"ts\"          : now.isoformat()\n",
    "                }\n",
    "        elif len(pipelines)>1:\n",
    "            e = MultipleActivePipelineRegistered(name)\n",
    "            return {\n",
    "                \"code\"   : 305,\n",
    "                \"status\" : \"%s:%s\" % (type(e).__name__,e),\n",
    "                \"ts\"     : now.isoformat()\n",
    "            }\n",
    "        else:\n",
    "            e = NoActivePipelineRegistered(name)\n",
    "            return {\n",
    "                \"code\"   : 306,\n",
    "                \"status\" : \"%s:%s\" % (type(e).__name__,e),\n",
    "                \"ts\"     : now.isoformat()\n",
    "            }\n",
    "\n",
    "    def scheduleAt(self):\n",
    "        now = datetime.now(timezone.utc).astimezone(get_localzone())\n",
    "        json_input = request.json\n",
    "\n",
    "        name            = json_input[\"name\"]\n",
    "        label           = json_input[\"label\"]\n",
    "        trigger_time    = json_input[\"trigger_time\"]\n",
    "        recurrency      = json_input[\"recurrency\"]\n",
    "        tags            = json_input[\"tags\"]\n",
    "        pipeline_args   = jsonpickle.loads(json_input[\"args\"])\n",
    "        pipeline_kwargs = jsonpickle.loads(json_input[\"kwargs\"])\n",
    "\n",
    "        pipelines = []\n",
    "        try:        \n",
    "            pipelines = self.manager.getPipelines(name = name, active = True)\n",
    "            \n",
    "        except Exception as e:\n",
    "            return {\n",
    "                \"code\"        : 305,\n",
    "                \"status\"      : \"%s : %s\" % (type(e).__name__, e),\n",
    "                \"ts\"          : now.isoformat()\n",
    "            }\n",
    "        \n",
    "        if len(pipelines)==1:\n",
    "            pipeline = pipelines[0]\n",
    "            pipeline.setArguments(pipeline_args)\n",
    "            pipeline.setKeywordArguments(pipeline_kwargs)\n",
    "            try:\n",
    "                \n",
    "                if self.manager.scheduleAt(pipeline, trigger_time=trigger_time, label=label, recurrency=recurrency,tags=tags):\n",
    "                    return {\n",
    "                        \"code\"         : 201,\n",
    "                        \"status\"       : True,\n",
    "                        \"ts\"           : now.isoformat()\n",
    "                    }\n",
    "            except Exception as e:\n",
    "                self.logger.info(\"scheduling failed:\",e)\n",
    "                return {\n",
    "                    \"code\"        : 303,\n",
    "                    \"status\"      : \"Scheduling failed. %s\" % e,\n",
    "                    \"ts\"          : now.isoformat()\n",
    "                }\n",
    "        elif len(pipelines)>1:\n",
    "            e = MultipleActivePipelineRegistered(name)\n",
    "            return {\n",
    "                \"code\"   : 305,\n",
    "                \"status\" : \"%s:%s\" % (type(e).__name__,e),\n",
    "                \"ts\"     : now.isoformat()\n",
    "            }\n",
    "        else:\n",
    "            e = NoActivePipelineRegistered(name)\n",
    "            return {\n",
    "                \"code\"   : 306,\n",
    "                \"status\" : \"%s:%s\" % (type(e).__name__,e),\n",
    "                \"ts\"     : now.isoformat()\n",
    "            }\n",
    "    \n",
    "    def get_last_execution(self, pipeline_name):\n",
    "        now = datetime.now(timezone.utc).astimezone(get_localzone())\n",
    "        print(\"%s : getting last execution for %s\" % (now, pipeline_name))\n",
    "        \n",
    "        executor = self.manager.getLastExecution(pipeline_name)\n",
    "        \n",
    "        try:\n",
    "            if executor is not None:\n",
    "                if \"asJson\" in request.args:\n",
    "                    return {\n",
    "                        \"code\"         : 202,\n",
    "                        \"status\"       : \"ok\",\n",
    "                        \"executor\"     : executor.asJson(),\n",
    "                        \"ts\"           : now.isoformat()\n",
    "                    }\n",
    "\n",
    "                else:\n",
    "                    return {\n",
    "                        \"code\"         : 202,\n",
    "                        \"status\"       : \"ok\",\n",
    "                        \"executor\"     : executor.serialize(),\n",
    "                        \"ts\"           : now.isoformat()\n",
    "                    }\n",
    "            else:\n",
    "                return {\n",
    "                    \"code\"         : 310,\n",
    "                    \"status\"       : \"Executor does not exists\",\n",
    "                    \"executor\"     : None,\n",
    "                    \"ts\"           : now.isoformat()\n",
    "                }\n",
    "        except Exception as e:\n",
    "            return {\n",
    "                \"code\"         : 501,\n",
    "                \"status\"       : \"Exception when recovering Executor\",\n",
    "                \"exception\"    : str(e),\n",
    "                \"ts\"           : now.isoformat()\n",
    "            }\n",
    "\n",
    "    def get_execution_list(self,pipeline_name):\n",
    "        now = datetime.now(timezone.utc).astimezone(get_localzone())\n",
    "        \n",
    "        if self.manager.isPipelineRegistered(pipeline_name):\n",
    "            self.logger.info(\"getting execution list for %s\" % pipeline_name)\n",
    "            \n",
    "            executions = self.manager.getExecutionList(pipeline_name)\n",
    "            \n",
    "            if len(executions)>0:\n",
    "                executors_list_json = [ ex.serialize() for ex in executions ]\n",
    "                \n",
    "                return {\n",
    "                    \"code\"         : 204,\n",
    "                    \"status\"       : \"ok\",\n",
    "                    \"pipeline_name\": pipeline_name,\n",
    "                    \"executions\"   : executors_list_json,\n",
    "                    \"ts\"           : now.isoformat()\n",
    "                }\n",
    "            else:\n",
    "                return {\n",
    "                    \"code\"         : 311,\n",
    "                    \"status\"       : \"No executions found\",\n",
    "                    \"pipeline_name\": pipeline_name,\n",
    "                    \"executions\"   : [],\n",
    "                    \"ts\"           : now.isoformat()\n",
    "                }\n",
    "\n",
    "        self.logger.info(\"pipeline not registered %s\" % label)\n",
    "        return {\n",
    "            \"code\"         : 301,\n",
    "            \"status\"       : \"Pipeline Not Registered\",\n",
    "            \"pipeline_name\": pipeline_name,\n",
    "            \"ts\"           : now.isoformat()\n",
    "        }\n",
    "\n",
    "    def get_running_executions(self):\n",
    "        now = datetime.now(timezone.utc).astimezone(get_localzone())\n",
    "        \n",
    "        self.logger.info(\"getting running executions\")\n",
    "            \n",
    "        executions = self.manager.getRunningExecutions()\n",
    "            \n",
    "        if len(executions)>0:\n",
    "\n",
    "            if \"asJson\" in request.args:\n",
    "                executors_list_json = [ ex.asJson() for ex in executions ]\n",
    "            else:\n",
    "                executors_list_json = [ ex.serialize() for ex in executions ]\n",
    "\n",
    "            return {\n",
    "                \"code\"         : 204,\n",
    "                \"status\"       : \"ok\",\n",
    "                \"executions\"   : executors_list_json,\n",
    "                \"ts\"           : now.isoformat()\n",
    "            }\n",
    "\n",
    "        else:\n",
    "            return {\n",
    "                \"code\"         : 401,\n",
    "                \"status\"       : \"No executions running\",\n",
    "                \"executions\"   : [],\n",
    "                \"ts\"           : now.isoformat()\n",
    "            }\n",
    "\n",
    "    def get_executions_by(self):\n",
    "        \n",
    "        args = request.json\n",
    "        if \"where\" in args:\n",
    "            where = args[\"where\"]\n",
    "            now = datetime.now(timezone.utc).astimezone(get_localzone())\n",
    "\n",
    "            self.logger.info(\"getting executions by %s\" % where)\n",
    "\n",
    "            executions = self.manager.getExecutionsBy(where)\n",
    "\n",
    "            if len(executions)>0:\n",
    "                executors_list_json = []\n",
    "                if \"asJson\" in request.args:\n",
    "                    try:\n",
    "                        executors_list_json = [ ex.asJson() for ex in executions ]\n",
    "                    except Exception as e:\n",
    "                        print(e)\n",
    "                else:\n",
    "                    executors_list_json = [ ex.serialize() for ex in executions ]\n",
    "\n",
    "                return {\n",
    "                    \"code\"         : 204,\n",
    "                    \"status\"       : \"ok\",\n",
    "                    \"where\"        : where,\n",
    "                    \"executions\"   : executors_list_json,\n",
    "                    \"ts\"           : now.isoformat()\n",
    "                }\n",
    "            else:\n",
    "                return {\n",
    "                    \"code\"         : 401,\n",
    "                    \"status\"       : \"No executions found\",\n",
    "                    \"where\"        : where,\n",
    "                    \"executions\"   : [],\n",
    "                    \"ts\"           : now.isoformat()\n",
    "                }\n",
    "        else:\n",
    "            return {\n",
    "                \"code\"         : 501,\n",
    "                \"status\"       : \"no where string given\",\n",
    "                \"executions\"   : [],\n",
    "                \"ts\"           : now.isoformat()\n",
    "            }\n",
    "    \n",
    "    def get_scheduled_executions(self,pipeline_name):\n",
    "        now = datetime.now(timezone.utc).astimezone(get_localzone())\n",
    "        \n",
    "        if self.manager.isPipelineRegistered(pipeline_name):\n",
    "            self.logger.info(\"getting scheduled executions for %s\" % pipeline_name)\n",
    "            \n",
    "            pipelines = []\n",
    "            try:        \n",
    "                pipelines = self.manager.getPipelines(name = pipeline_name, active = True)\n",
    "\n",
    "            except Exception as e:\n",
    "                return {\n",
    "                    \"code\"        : 305,\n",
    "                    \"status\"      : \"%s : %s\" % (type(e).__name__, e),\n",
    "                    \"ts\"          : now.isoformat()\n",
    "                }\n",
    "        \n",
    "            if len(pipelines)==1:\n",
    "                pipeline = pipelines[0]\n",
    "\n",
    "                sch_execs = self.manager.getScheduledExecutions(pipeline)\n",
    "            \n",
    "                if len(sch_execs)>0:\n",
    "                    sch_execs_list_json = [ x.serialize() for x in sch_execs ]\n",
    "\n",
    "                    return {\n",
    "                        \"code\"         : 204,\n",
    "                        \"status\"       : \"ok\",\n",
    "                        \"pipeline_name\": pipeline_name,\n",
    "                        \"scheduled\"    : sch_execs_list_json,\n",
    "                        \"ts\"           : now.isoformat()\n",
    "                    }\n",
    "                else:\n",
    "                    return {\n",
    "                        \"code\"         : 311,\n",
    "                        \"status\"       : \"No scheduled executions found\",\n",
    "                        \"pipeline_name\": pipeline_name,\n",
    "                        \"scheduled\"    : [],\n",
    "                        \"ts\"           : now.isoformat()\n",
    "                    }\n",
    "            else:\n",
    "                self.logger.info(\"multiple active pipelines registered %s\" % pipeline_name)\n",
    "                return {\n",
    "                    \"code\"         : 303,\n",
    "                    \"status\"       : \"Multiple active pipelines registered\",\n",
    "                    \"pipeline_name\": pipeline_name,\n",
    "                    \"ts\"           : now.isoformat()\n",
    "                }\n",
    "            \n",
    "        self.logger.info(\"pipeline not registered %s\" % pipeline_name)\n",
    "        return {\n",
    "            \"code\"         : 301,\n",
    "            \"status\"       : \"Pipeline Not Registered\",\n",
    "            \"pipeline_name\": pipeline_name,\n",
    "            \"ts\"           : now.isoformat()\n",
    "        }\n",
    "    \n",
    "    def get_scheduled_execution_by_id(self,scheduled_execution_id):\n",
    "        now = datetime.now(timezone.utc).astimezone(get_localzone())\n",
    "        \n",
    "        if (scheduled_execution_id is not None and scheduled_execution_id!=\"\"):\n",
    "            sch_evt = self.manager.getScheduledExecutionById(scheduled_execution_id)\n",
    "\n",
    "            if isinstance(sch_evt,ScheduledEvent):\n",
    "                sch_exec_json = sch_evt.serialize()\n",
    "\n",
    "                return {\n",
    "                    \"code\"          : 204,\n",
    "                    \"status\"        : \"ok\",\n",
    "                    \"scheduled_evt\" : sch_exec_json,\n",
    "                    \"ts\"            : now.isoformat()\n",
    "                }\n",
    "            else:\n",
    "                return {\n",
    "                    \"code\"          : 311,\n",
    "                    \"status\"        : \"No scheduled execution found\",\n",
    "                    \"scheduled_evt\" : None,\n",
    "                    \"ts\"            : now.isoformat()\n",
    "                }\n",
    "        else:\n",
    "            raise RuntimeError(\"you must provide a valid scheduled event id\")\n",
    "    \n",
    "    def isPipelineRegistered(self, pipeline_name):\n",
    "        return self.manager.isPipelineRegistered(pipeline_name)\n",
    "\n",
    "    def cancel_scheduled_execution(self, scheduled_execution_id):\n",
    "        now = datetime.now(timezone.utc).astimezone(get_localzone())\n",
    "        \n",
    "        sch_evt = self.manager.getScheduledExecutionById(scheduled_execution_id)\n",
    "    \n",
    "        if isinstance(sch_evt, ScheduledEvent):    \n",
    "            if self.manager.cancelScheduledExecution(sch_evt):\n",
    "                return {\n",
    "                    \"code\"         : 204,\n",
    "                    \"status\"       : \"ok\",\n",
    "                    \"ts\"           : now.isoformat()\n",
    "                }\n",
    "            else:\n",
    "                return {\n",
    "                    \"code\"          : 311,\n",
    "                    \"status\"        : \"scheduled event not cancelled\",\n",
    "                    \"scheduled_evt\" : None,\n",
    "                    \"ts\"            : now.isoformat()\n",
    "                }\n",
    "\n",
    "    def create_notification(self,label):\n",
    "        data = None\n",
    "        if request.method == \"POST\":\n",
    "            data = request.json\n",
    "        else:\n",
    "            data = request.args\n",
    "\n",
    "        now = datetime.now(timezone.utc).astimezone(get_localzone())\n",
    "        try:\n",
    "            notification = self.manager.createNotification(label,data=data)\n",
    "\n",
    "            if notification is not None:\n",
    "                notif_json = notification.serialize()\n",
    "                return {\n",
    "                    \"code\"         : 204,\n",
    "                    \"status\"       : \"ok\",\n",
    "                    \"notification\" : notif_json,\n",
    "                    \"ts\"           : now.isoformat()\n",
    "                }\n",
    "            else:\n",
    "                return {\n",
    "                    \"code\"          : 311,\n",
    "                    \"status\"        : \"notification not created\",\n",
    "                    \"notification\"  : None,\n",
    "                    \"ts\"            : now.isoformat()\n",
    "                }\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            return {\n",
    "                \"code\"          : 502,\n",
    "                \"status\"        : \"Exception raised when creating notification\",\n",
    "                \"exception\"     : e,\n",
    "                \"ts\"            : now.isoformat()\n",
    "            }\n",
    "      \n",
    "    def get_last_notification(self,label):\n",
    "        now = datetime.now(timezone.utc).astimezone(get_localzone())        \n",
    "        last_notification = self.manager.getLastNotification(label)\n",
    "        \n",
    "        if last_notification is not None:\n",
    "            notif_json = last_notification.serialize()\n",
    "            return {\n",
    "                \"code\"         : 204,\n",
    "                \"status\"       : \"ok\",\n",
    "                \"notification\" : notif_json,\n",
    "                \"ts\"           : now.isoformat()\n",
    "            }\n",
    "        else:\n",
    "            return {\n",
    "                \"code\"          : 311,\n",
    "                \"status\"        : \"last notification not found\",\n",
    "                \"notification\"  : None,\n",
    "                \"ts\"            : now.isoformat()\n",
    "            }\n",
    "        \n",
    "    def get_notification_list(self,label):\n",
    "        now = datetime.now(timezone.utc).astimezone(get_localzone())\n",
    "        notification_list = self.manager.getNotificationList(label)\n",
    "        if len(notification_list)>0:\n",
    "            notif_list_json = []\n",
    "            for n in notification_list:\n",
    "                notif_list_json.append(n.serialize())\n",
    "            \n",
    "            return {\n",
    "                \"code\"              : 204,\n",
    "                \"status\"            : \"ok\",\n",
    "                \"notification_list\" : notif_list_json,\n",
    "                \"ts\"                : now.isoformat()\n",
    "            }\n",
    "        else:\n",
    "            return {\n",
    "                \"code\"              : 311,\n",
    "                \"status\"            : \"last notification not found\",\n",
    "                \"notification_list\" : [],\n",
    "                \"ts\"                : now.isoformat()\n",
    "            }\n",
    "    \n",
    "    def subscribe_notification_pipeline(self, label):\n",
    "        data = request.get_json()\n",
    "\n",
    "        now = datetime.now(timezone.utc).astimezone(get_localzone())\n",
    "\n",
    "        try:\n",
    "            pipeline_name = data[\"pipeline_name\"]\n",
    "            subscriber = self.manager.subscribePipelineNotification(label,pipeline_name)\n",
    "\n",
    "            if subscriber is not None:\n",
    "                subscriber_json = subscriber.serialize()\n",
    "                return {\n",
    "                    \"code\"         : 204,\n",
    "                    \"status\"       : \"ok\",\n",
    "                    \"subscription\" : subscriber_json,\n",
    "                    \"ts\"           : now.isoformat()\n",
    "                }\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            return {\n",
    "                \"code\"          : 501,\n",
    "                \"status\"        : \"error subscribing pipeline\",\n",
    "                \"exception\"     : base64.b64encode(dill.dumps(e)),\n",
    "                \"ts\"            : now.isoformat()\n",
    "            }\n",
    "\n",
    "    def unsubscribe_notification_pipeline(self, label):\n",
    "        data = request.get_json()\n",
    "\n",
    "        now = datetime.now(timezone.utc).astimezone(get_localzone())\n",
    "\n",
    "        try:\n",
    "            pipeline_name = data[\"pipeline_name\"]\n",
    "            if self.manager.unsubscribePipelineNotification(label,pipeline_name):\n",
    "                return {\n",
    "                    \"code\"         : 204,\n",
    "                    \"status\"       : \"ok\",\n",
    "                    \"ts\"           : now.isoformat()\n",
    "                }\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            return {\n",
    "                \"code\"          : 501,\n",
    "                \"status\"        : \"error unsubscribing pipeline\",\n",
    "                \"exception\"     : base64.b64encode(dill.dumps(e)),\n",
    "                \"ts\"            : now.isoformat()\n",
    "            }\n",
    "\n",
    "    def get_subscribed_pipelines(self, label):\n",
    "        pass\n",
    "        \n",
    "    def stop(self):\n",
    "        now = datetime.now(timezone.utc).astimezone(get_localzone())\n",
    "        self.manager.stop()\n",
    "        super().release()\n",
    "        return {\n",
    "            \"code\"   : 210,\n",
    "            \"status\" : \"stop\",\n",
    "            \"ts\"     : now.isoformat()\n",
    "        }\n",
    "    \n",
    "    def put_key(self):\n",
    "        json_input = request.json\n",
    "        label = json_input[\"label\"]\n",
    "        passphrase = json_input[\"passphrase\"]\n",
    "        key_json = json_input['key']\n",
    "        key = jsonpickle.loads(key_json)\n",
    "        key.decodeKey()\n",
    "        now = datetime.now(timezone.utc).astimezone(get_localzone())\n",
    "        try:\n",
    "            self.logger.info(\"storing key with label:%s\" % (label))\n",
    "            self.manager.putKey(key, passphrase)\n",
    "            return {\n",
    "                \"code\"   : 205,\n",
    "                \"status\" : \"ok\",\n",
    "                \"ts\"     : now.isoformat()\n",
    "            }\n",
    "        except AlreadyExists as e:\n",
    "            self.logger.info(\"%s\" % (e))\n",
    "            return {\n",
    "                \"code\"   : 312,\n",
    "                \"status\" : \"Could not store key\",\n",
    "                \"error\"  : \"%s\" % e,\n",
    "                \"ts\"     : now.isoformat()\n",
    "            }\n",
    "        except Exception as e:\n",
    "            self.logger.info(\"error storing key with label %s: %s\" % (label,e))\n",
    "            return {\n",
    "                \"code\"   : 313,\n",
    "                \"status\" : \"Could not store key\",\n",
    "                \"error\"  : \"%s\" % e,\n",
    "                \"ts\"     : now.isoformat()\n",
    "            }            \n",
    "        \n",
    "    def get_key(self, label, passphrase):\n",
    "        now = datetime.now(timezone.utc).astimezone(get_localzone())\n",
    "        try:\n",
    "            key = self.manager.getKey(label, passphrase)\n",
    "            key_encode = key.serialize()\n",
    "            return {\n",
    "                \"code\"   : 205,\n",
    "                \"status\"   : \"ok\",\n",
    "                \"key\"    : key_encode,\n",
    "                \"ts\"     : now.isoformat()\n",
    "            }\n",
    "        except KeyNotFound as e:\n",
    "            self.logger.info(\"%s\" % (e))\n",
    "            return {\n",
    "                \"code\"   : 312,\n",
    "                \"status\" : \"key not found\",\n",
    "                \"error\"  : \"%s\" % e,\n",
    "                \"ts\"     : now.isoformat()\n",
    "            }\n",
    "        except Exception as e:\n",
    "            self.logger.info(\"error retrieving  key with label %s: %s\" % (label,e))\n",
    "            return {\n",
    "                \"code\"   : 313,\n",
    "                \"status\" : \"Could not retrieve key\",\n",
    "                \"error\"  : \"%s\" % e,\n",
    "                \"ts\"     : now.isoformat()\n",
    "            }\n",
    "        \n",
    "    def get_public_key(self):\n",
    "        now = datetime.now(timezone.utc).astimezone(get_localzone())\n",
    "        try:\n",
    "            key = self.manager.getPublicKey()\n",
    "            key_encode = key.serialize()\n",
    "            return {\n",
    "                \"code\"   : 205,\n",
    "                \"status\" : \"ok\",\n",
    "                \"key\"    : key_encode,\n",
    "                \"ts\"     : now.isoformat()\n",
    "            }\n",
    "        except Exception as e:\n",
    "            self.logger.info(\"error retrieving public key :%s\" % (e))\n",
    "            return {\n",
    "                \"code\"   : 313,\n",
    "                \"status\" : \"Could not retrieve key\",\n",
    "                \"error\"  : \"%s\" % e,\n",
    "                \"ts\"     : now.isoformat()\n",
    "            }\n",
    "            \n",
    "    def put_credential(self):\n",
    "        json_input = request.json\n",
    "        now = datetime.now(timezone.utc).astimezone(get_localzone())\n",
    "        label = json_input[\"label\"]\n",
    "        credential_json = json_input['credential']\n",
    "        n_unlock = json_input[\"n_unlock\"]\n",
    "        shared_users = json_input[\"shared_users\"]\n",
    "        credential = jsonpickle.loads(credential_json)\n",
    "        try:\n",
    "            self.logger.info(\"storing credential with label:%s\" % (label))\n",
    "            self.manager.putCredential(credential, n_unlock, shared_users)\n",
    "            return {\n",
    "                \"code\"   : 205,\n",
    "                \"status\" : \"ok\",\n",
    "                \"ts\"     : now.isoformat()\n",
    "            }\n",
    "        except Exception as e:\n",
    "            self.logger.info(\"error storing credential with label %s: %s\" % (label,e))\n",
    "            return {\n",
    "                \"code\"   : 312,\n",
    "                \"status\" : \"Could not store credential\",\n",
    "                \"error\"  : \"%s\" % e,\n",
    "                \"ts\"     : now.isoformat()\n",
    "            }\n",
    "        \n",
    "    def get_credential(self):\n",
    "        json_input = request.json\n",
    "        now = datetime.now(timezone.utc).astimezone(get_localzone())\n",
    "        label = json_input['label']\n",
    "        decrypt = json_input[\"decrypt\"]\n",
    "        token_json = json_input[\"token\"]\n",
    "        token = jsonpickle.loads(token_json)\n",
    "        whom = json_input[\"whom\"]\n",
    "        try:\n",
    "            credential = self.manager.getCredential(label, decrypt, token, whom)\n",
    "            return {\n",
    "                \"code\"       : 205,\n",
    "                \"status\"     : \"ok\",\n",
    "                \"credential\" : credential.serialize(),\n",
    "                \"ts\"         : now.isoformat()\n",
    "            }\n",
    "        except CredentialNotFound as e:\n",
    "            return {\n",
    "                    \"code\"   : 312,\n",
    "                    \"status\" : \"credential not found\",\n",
    "                    \"error\"  : \"%s\" % e,\n",
    "                    \"ts\"     : now.isoformat()\n",
    "                }\n",
    "        except TokenNotFound as e:\n",
    "            return {\n",
    "                    \"code\"   : 313,\n",
    "                    \"status\" : \"Token not Found\",\n",
    "                    \"error\"  : \"%s\" % e,\n",
    "                    \"ts\"     : now.isoformat()\n",
    "                }\n",
    "        except Exception as e:\n",
    "                self.logger.info(\"error retrieving  credential with label %s: %s\" % (label,e))\n",
    "                return {\n",
    "                    \"code\"   : 314,\n",
    "                    \"status\" : \"Could not retrieve credential\",\n",
    "                    \"error\"  : \"%s\" % e,\n",
    "                    \"ts\"     : now.isoformat()\n",
    "                }\n",
    "        \n",
    "    def get_key_list(self, active):\n",
    "        now = datetime.now(timezone.utc).astimezone(get_localzone())\n",
    "        try:\n",
    "            active = ast.literal_eval(active)\n",
    "            status = 'inactive'\n",
    "            if active is True:\n",
    "                status = 'active'\n",
    "            list_keys = self.manager.getKeyList(active)\n",
    "            if len(list_keys) != 0:\n",
    "                keys = []\n",
    "                for key in list_keys:\n",
    "                    keys.append(key.serialize())\n",
    "                return {\n",
    "                    \"code\"   : 206,\n",
    "                    \"status\" : \"ok\",\n",
    "                    \"keys\"   : jsonpickle.encode(keys),\n",
    "                    \"ts\"     : now.isoformat()\n",
    "                }\n",
    "            else:\n",
    "                self.logger.info(\"no keys %s registered in the vault\"%(status))\n",
    "                return {\n",
    "                    \"code\"   : 312,\n",
    "                    \"status\" : \"there are no keys\",\n",
    "                    \"ts\"     : now.isoformat()\n",
    "                }\n",
    "        except Exception as e:\n",
    "            self.logger.info(\"error listing keys: %s\" % (e))\n",
    "            return {\n",
    "                \"code\"   : 313,\n",
    "                \"status\" : \"Could not list keys\",\n",
    "                \"error\"  : \"%s\" % e,\n",
    "                \"ts\"     : now.isoformat()\n",
    "            }\n",
    "    \n",
    "    def key_expiration(self):\n",
    "        json_input = request.json\n",
    "        label = json_input[\"label\"]\n",
    "        key_json = json_input['key']\n",
    "        key = jsonpickle.loads(key_json)\n",
    "        key.decodeKey()\n",
    "        now = datetime.now(timezone.utc).astimezone(get_localzone())\n",
    "        try:\n",
    "            status = self.manager.keyExpiration(key)\n",
    "            return {\n",
    "                \"code\"       : 206,\n",
    "                \"status\"     : \"ok\",\n",
    "                \"key_status\" : jsonpickle.encode(status),\n",
    "                \"ts\"         : now.isoformat()\n",
    "            }\n",
    "        except KeyNotFound as e:\n",
    "            return {\n",
    "                \"code\"   : 312,\n",
    "                \"status\" : \"key not found\",\n",
    "                \"error\"  : \"%s\" % e,\n",
    "                \"ts\"     : now.isoformat()\n",
    "            }\n",
    "        except ExpiredKey as e:\n",
    "            return {\n",
    "                \"code\"   : 314,\n",
    "                \"status\" : \"key expired\",\n",
    "                'key_status': jsonpickle.encode(False),\n",
    "                \"ts\"     : now.isoformat()\n",
    "            }\n",
    "        except Exception as e:\n",
    "            self.logger.info(\"error verifying expiration of key with label %s: %s\" % (label,e))\n",
    "            return {\n",
    "                \"code\"   : 313,\n",
    "                \"status\" : \"Could not verify expiration of key\",\n",
    "                \"error\"  : \"%s\" % e,\n",
    "                \"ts\"     : now.isoformat()\n",
    "            }\n",
    "    \n",
    "    def get_key_expiration_date(self):\n",
    "        json_input = request.json\n",
    "        label = json_input[\"label\"]\n",
    "        key_json = json_input['key']\n",
    "        key = jsonpickle.loads(key_json)\n",
    "        key.decodeKey()\n",
    "        now = datetime.now(timezone.utc).astimezone(get_localzone())\n",
    "        try:\n",
    "            date = self.manager.getKeyExpirationDate(key)\n",
    "            return {\n",
    "                \"code\"   : 206,\n",
    "                \"status\" : \"ok\",\n",
    "                \"date\"   : jsonpickle.encode(date),\n",
    "                \"ts\"     : now.isoformat()\n",
    "            }\n",
    "        except KeyNotFound as e:\n",
    "            return {\n",
    "                \"code\"   : 312,\n",
    "                \"status\" : \"key not found\",\n",
    "                \"ts\"     : now.isoformat()\n",
    "            }\n",
    "        except Exception as e:\n",
    "            self.logger.info(\"error geting expiration date of key with label %s: %s\" % (label,e))\n",
    "            return {\n",
    "                \"code\"   : 313,\n",
    "                \"status\" : \"Could not get key expiration date\",\n",
    "                \"error\"  : \"%s\" % e,\n",
    "                \"ts\"     : now.isoformat()\n",
    "            }\n",
    "            \n",
    "    def get_credential_list(self, active):\n",
    "        now = datetime.now(timezone.utc).astimezone(get_localzone())\n",
    "        try:\n",
    "            active = ast.literal_eval(active)\n",
    "            status = 'inactive'\n",
    "            if active is True:\n",
    "                status = 'active'\n",
    "            list_credentials = self.manager.getCredentialList(active)\n",
    "            if len(list_credentials) != 0:\n",
    "                return {\n",
    "                    \"code\"        : 206,\n",
    "                    \"status\"      : \"ok\",\n",
    "                    \"credentials\" : jsonpickle.encode(list_credentials),\n",
    "                    \"ts\"          : now.isoformat()\n",
    "                }\n",
    "            else:\n",
    "                self.logger.info(\"no credentials %s registered in the vault\"%(status))\n",
    "                return {\n",
    "                    \"code\"        : 312,\n",
    "                    \"status\"      : \"there are no credentials\",\n",
    "                    \"ts\"          : now.isoformat()\n",
    "                }\n",
    "        except Exception as e:\n",
    "            self.logger.info(\"error listing credentials: %s\" % (e))\n",
    "            return {\n",
    "                \"code\"   : 313,\n",
    "                \"status\" : \"Could not list credentials\",\n",
    "                \"error\"  : \"%s\" % e,\n",
    "                \"ts\"     : now.isoformat()\n",
    "            }    \n",
    "        \n",
    "    def credential_expiration(self, label):\n",
    "        now = datetime.now(timezone.utc).astimezone(get_localzone())\n",
    "        try:\n",
    "            status = self.manager.credentialExpiration(label)\n",
    "            return {\n",
    "                \"code\"              : 206,\n",
    "                \"status\"            : \"ok\",\n",
    "                \"credential_status\" : jsonpickle.encode(status),\n",
    "                \"ts\"                : now.isoformat()\n",
    "            }\n",
    "        except CredentialNotFound as e:\n",
    "            return {\n",
    "                \"code\"   : 312,\n",
    "                \"status\" : \"credential not found\",\n",
    "                \"ts\"     : now.isoformat()\n",
    "            }\n",
    "        except ExpiredCredential as e:\n",
    "            return {\n",
    "                \"code\"   : 314,\n",
    "                \"status\" : \"credential expired\",\n",
    "                \"credential_status\" : jsonpickle.encode(False),\n",
    "                \"ts\"     : now.isoformat()\n",
    "            }\n",
    "        except Exception as e:\n",
    "            self.logger.info(\"error checking credential: %s\" % (e))\n",
    "            return {\n",
    "                \"code\"   : 313,\n",
    "                \"status\" : \"Could not check credentials\",\n",
    "                \"error\"  : \"%s\" % e,\n",
    "                \"ts\"     : now.isoformat()\n",
    "            }\n",
    "                \n",
    "    def get_credential_expiration_date(self, label):\n",
    "        now = datetime.now(timezone.utc).astimezone(get_localzone())\n",
    "        try:\n",
    "            date = self.manager.getCredentialExpirationDate(label)\n",
    "            return {\n",
    "                \"code\"   : 206,\n",
    "                \"status\" : \"ok\",\n",
    "                \"date\"   : jsonpickle.encode(date),\n",
    "                \"ts\"     : now.isoformat()\n",
    "            }\n",
    "        except CredentialNotFound as e:\n",
    "            return {\n",
    "                \"code\"   : 312,\n",
    "                \"status\" : \"credential not found\",\n",
    "                \"ts\"     : now.isoformat()\n",
    "            }\n",
    "        except Exception as e:\n",
    "            self.logger.info(\"error listing credentials: %s\" % (e))\n",
    "            return {\n",
    "                \"code\"   : 313,\n",
    "                \"status\" : \"Could not list credentials\",\n",
    "                \"error\"  : \"%s\" % e,\n",
    "                \"ts\"     : now.isoformat()\n",
    "            }\n",
    "        \n",
    "    def sign_credential(self):\n",
    "        json_input = request.json\n",
    "        credential_json = json_input['credential']\n",
    "        credential = jsonpickle.loads(credential_json)\n",
    "        key_json = json_input['key']\n",
    "        key = json_input['key']\n",
    "        if key_json is not None:\n",
    "            key = jsonpickle.loads(key_json)\n",
    "            key.decodeKey()\n",
    "        now = datetime.now(timezone.utc).astimezone(get_localzone())\n",
    "        label= credential.getLabel()\n",
    "        try:\n",
    "            self.logger.info(\"signing credential with label:%s\" % (label))\n",
    "            self.manager.signCredential(credential, key)\n",
    "            return {\n",
    "                \"code\"   : 206,\n",
    "                \"status\" : \"ok\",\n",
    "                \"ts\"     : now.isoformat()\n",
    "            }\n",
    "        except Exception as e:\n",
    "            self.logger.info(\"error signing credential with label %s: %s\" % (label,e))\n",
    "            return {\n",
    "                \"code\"   : 313,\n",
    "                \"status\" : \"Could not sign credential\",\n",
    "                \"error\"  : \"%s\" % e,\n",
    "                \"ts\"     : now.isoformat()\n",
    "            }\n",
    "            \n",
    "    def verify_credential(self):\n",
    "        json_input = request.json\n",
    "        now = datetime.now(timezone.utc).astimezone(get_localzone())\n",
    "        label = json_input[\"label\"]\n",
    "        credential_json = json_input['credential']\n",
    "        credential = jsonpickle.loads(credential_json)\n",
    "        try:\n",
    "            self.logger.info(\"checking sign of credential with label:%s\" % (label))\n",
    "            self.manager.verifyCredential(credential)\n",
    "            return {\n",
    "                \"code\"   : 206,\n",
    "                \"status\" : \"ok\",\n",
    "                \"ts\"     : now.isoformat()\n",
    "            }\n",
    "        except Exception as e:\n",
    "            self.logger.info(\"error checking credential with label %s: %s\" % (label,e))\n",
    "            return {\n",
    "                \"code\"   : 313,\n",
    "                \"status\" : \"Could not check credential\",\n",
    "                \"error\"  : \"%s\" % e,\n",
    "                \"ts\"     : now.isoformat()\n",
    "            }\n",
    "        \n",
    "    def encrypt_credential(self):\n",
    "        json_input = request.json\n",
    "        now = datetime.now(timezone.utc).astimezone(get_localzone())\n",
    "        key_json = json_input[\"key\"]\n",
    "        key = jsonpickle.loads(key_json)\n",
    "        key.decodeKey()\n",
    "        credential_json = json_input['credential']\n",
    "        credential = jsonpickle.loads(credential_json)\n",
    "        label = credential.getLabel()\n",
    "        try:\n",
    "            self.logger.info(\"encrypt credential with label:%s\" % (label))\n",
    "            credential_encrypted = self.manager.encryptCredential(credential, key)\n",
    "            return {\n",
    "                \"code\"   : 206,\n",
    "                \"status\" : \"ok\",\n",
    "                \"credential_encrypted\" : jsonpickle.encode(credential_encrypted),\n",
    "                \"ts\"     : now.isoformat()\n",
    "            }\n",
    "        except Exception as e:\n",
    "            self.logger.info(\"error encrypting credential with label %s: %s\" % (label,e))\n",
    "            return {\n",
    "                \"code\"   : 313,\n",
    "                \"status\" : \"Could not encrypt credential\",\n",
    "                \"error\"  : \"%s\" % e,\n",
    "                \"ts\"     : now.isoformat()\n",
    "            }        \n",
    "        \n",
    "    def create_token(self):\n",
    "        json_input = request.json\n",
    "        now = datetime.now(timezone.utc).astimezone(get_localzone())\n",
    "        credential_json = json_input['credential']\n",
    "        credential = jsonpickle.loads(credential_json)\n",
    "        label = credential.getLabel()\n",
    "        min_unlock = json_input['minimum_unlock']\n",
    "        shared_users = json_input['shared_users']\n",
    "        try:\n",
    "            self.logger.info(\"creating token for credential with label:%s\" % (label))\n",
    "            token = self.manager.createToken(credential, min_unlock, shared_users)\n",
    "            return {\n",
    "                \"code\"   : 206,\n",
    "                \"status\" : \"ok\",\n",
    "                \"token\"  : jsonpickle.encode(token),\n",
    "                \"credential_encrypted\" : jsonpickle.encode(credential),\n",
    "                \"ts\"     : now.isoformat()\n",
    "            }\n",
    "        except Exception as e:\n",
    "            self.logger.info(\"error creating token for credential with label %s: %s\" % (label,e))\n",
    "            return {\n",
    "                \"code\"   : 313,\n",
    "                \"status\" : \"Could not create token\",\n",
    "                \"error\"  : \"%s\" % e,\n",
    "                \"ts\"     : now.isoformat()\n",
    "            }\n",
    "        \n",
    "    def put_token(self):\n",
    "        json_input = request.json\n",
    "        now = datetime.now(timezone.utc).astimezone(get_localzone())\n",
    "        credential_json = json_input['credential']\n",
    "        credential = jsonpickle.loads(credential_json)\n",
    "        label = credential.getLabel()\n",
    "        token_json = json_input['token_list']\n",
    "        token_list = jsonpickle.loads(token_json)\n",
    "        try:\n",
    "            self.logger.info(\"storing token for credential with label:%s\" % (label))\n",
    "            self.manager.putToken(credential, token_list)\n",
    "            return {\n",
    "                \"code\"   : 205,\n",
    "                \"status\" : \"ok\",\n",
    "                \"ts\"     : now.isoformat()\n",
    "            }\n",
    "        except Exception as e:\n",
    "            self.logger.info(\"error storing token for credential with label %s: %s\" % (label,e))\n",
    "            return {\n",
    "                \"code\"   : 312,\n",
    "                \"status\" : \"Could not store token\",\n",
    "                \"error\"  : \"%s\" % e,\n",
    "                \"ts\"     : now.isoformat()\n",
    "            }        \n",
    "        \n",
    "    def get_token(self, label, whom, active):\n",
    "        now = datetime.now(timezone.utc).astimezone(get_localzone())\n",
    "        status = ast.literal_eval(active)\n",
    "        try:\n",
    "            token = self.manager.getToken(label, whom, status)\n",
    "            return {\n",
    "                \"code\"   : 205,\n",
    "                \"status\" : \"ok\",\n",
    "                \"token\"  : jsonpickle.encode(token),\n",
    "                \"ts\"     : now.isoformat()\n",
    "            }\n",
    "        except TokenNotFound as e:\n",
    "            return {\n",
    "                    \"code\"   : 312,\n",
    "                    \"status\" : \"token not found\",\n",
    "                    \"error\"  : \"%s\" % e,\n",
    "                    \"ts\"     : now.isoformat()\n",
    "                }\n",
    "        except Exception as e:\n",
    "            self.logger.info(\"error retrieving token for credential with label %s: %s\" % (label,e))\n",
    "            return {\n",
    "                \"code\"   : 313,\n",
    "                \"status\" : \"Could not retrieve token\",\n",
    "                \"error\"  : \"%s\" % e,\n",
    "                \"ts\"     : now.isoformat()\n",
    "            }\n",
    "        \n",
    "    def assign_token(self):\n",
    "        json_input = request.json\n",
    "        now = datetime.now(timezone.utc).astimezone(get_localzone())        \n",
    "        whom = json_input['whom']\n",
    "        label = json_input['label']\n",
    "        exp_date_json = json_input['exp_date']\n",
    "        exp_date = jsonpickle.loads(exp_date_json)\n",
    "        comment = json_input['comment']\n",
    "        try:\n",
    "            assigned_token = self.manager.assignToken(whom, label, exp_date, comment)\n",
    "            return {\n",
    "                \"code\"   : 205,\n",
    "                \"status\" : \"ok\",\n",
    "                \"token\"  : jsonpickle.encode(assigned_token),\n",
    "                \"ts\"     : now.isoformat()\n",
    "            }\n",
    "        except TokenNotFound as e:\n",
    "            return {\n",
    "                \"code\"   : 312,\n",
    "                \"status\" : \"token not found\",\n",
    "                \"error\"  : \"%s\" % e,\n",
    "                \"ts\"     : now.isoformat()\n",
    "            }\n",
    "        except Exception as e:\n",
    "            self.logger.info(\"error assigning token for label %s: %s\" % (label,e))\n",
    "            return {\n",
    "                \"code\"   : 313,\n",
    "                \"status\" : \"Could not retrieve token\",\n",
    "                \"error\"  : \"%s\" % e,\n",
    "                \"ts\"     : now.isoformat()\n",
    "            }\n",
    "\n",
    "    def get_assigned_token(self, label, whom):\n",
    "        now = datetime.now(timezone.utc).astimezone(get_localzone())\n",
    "        try:\n",
    "            token = self.manager.getAssignedToken(label, whom)\n",
    "            return {\n",
    "                \"code\"   : 205,\n",
    "                \"status\" : \"ok\",\n",
    "                \"token\"  : jsonpickle.encode(token),\n",
    "                \"ts\"     : now.isoformat()\n",
    "            }\n",
    "        except TokenNotFound as e:\n",
    "            return {\n",
    "                \"code\"   : 312,\n",
    "                \"status\" : \"token not found\",\n",
    "                \"error\"  : \"%s\" % e,\n",
    "                \"ts\"     : now.isoformat()\n",
    "            }\n",
    "        except Exception as e:\n",
    "            self.logger.info(\"error retrieving token for label %s: %s\" % (label,e))\n",
    "            return {\n",
    "                \"code\"   : 313,\n",
    "                \"status\" : \"Could not retrieve token\",\n",
    "                \"error\"  : \"%s\" % e,\n",
    "                \"ts\"     : now.isoformat()\n",
    "            }\n",
    "\n",
    "    def sign_token(self):\n",
    "        json_input = request.json\n",
    "        now = datetime.now(timezone.utc).astimezone(get_localzone())        \n",
    "        label = json_input['label']\n",
    "        whom = json_input['whom']\n",
    "        try:\n",
    "            self.logger.info(\"signing token with label:%s\" % (label))\n",
    "            self.manager.signToken(label, whom)\n",
    "            return {\n",
    "                \"code\"   : 206,\n",
    "                \"status\" : \"ok\",\n",
    "                \"ts\"     : now.isoformat()\n",
    "            }\n",
    "        except Exception as e:\n",
    "            self.logger.info(\"error signing token with label %s: %s\" % (label,e))\n",
    "            return {\n",
    "                \"code\"   : 313,\n",
    "                \"status\" : \"Could not sign token\",\n",
    "                \"error\"  : \"%s\" % e,\n",
    "                \"ts\"     : now.isoformat()\n",
    "            }\n",
    "\n",
    "    def verify_token(self):\n",
    "        json_input = request.json\n",
    "        now = datetime.now(timezone.utc).astimezone(get_localzone())\n",
    "        token_json = json_input['token']\n",
    "        token = jsonpickle.loads(token_json)\n",
    "        try:\n",
    "            self.logger.info(\"checking sign of token\")\n",
    "            self.manager.verifyToken(token)\n",
    "            return {\n",
    "                \"code\"   : 206,\n",
    "                \"status\" : \"ok\",\n",
    "                \"ts\"     : now.isoformat()\n",
    "            }\n",
    "        except Exception as e:\n",
    "            self.logger.info(\"error checking token: %s\" % (e))\n",
    "            return {\n",
    "                \"code\"   : 313,\n",
    "                \"status\" : \"Could not check token\",\n",
    "                \"error\"  : \"%s\" % e,\n",
    "                \"ts\"     : now.isoformat()\n",
    "            }\n",
    "\n",
    "    def get_token_list(self, active):\n",
    "        active = ast.literal_eval(active)\n",
    "        status = 'inactive'\n",
    "        if active is True:\n",
    "            status = 'active'\n",
    "        now = datetime.now(timezone.utc).astimezone(get_localzone())\n",
    "        try:\n",
    "            token_list = self.manager.getTokenList(active)\n",
    "            if len(token_list) != 0:\n",
    "                return {\n",
    "                    \"code\"   : 206,\n",
    "                    \"status\" : \"ok\",\n",
    "                    \"token_list\"   : jsonpickle.encode(token_list),\n",
    "                    \"ts\"     : now.isoformat()\n",
    "                }\n",
    "            else:\n",
    "                self.logger.info(\"there are no %s tokens registered in the vault\" % (status))\n",
    "                return {\n",
    "                    \"code\"   : 312,\n",
    "                    \"status\" : \"there are no tokens\",\n",
    "                    \"token_list\"   : None,\n",
    "                    \"ts\"     : now.isoformat()\n",
    "                }\n",
    "        except Exception as e:\n",
    "            self.logger.info(\"error listing tokens: %s\" % (e))\n",
    "            return {\n",
    "                \"code\"   : 313,\n",
    "                \"status\" : \"Could not list tokens\",\n",
    "                \"error\"  : \"%s\" % e,\n",
    "                \"ts\"     : now.isoformat()\n",
    "            }\n",
    "\n",
    "    def get_token_expiration_date(self, label, whom=None):\n",
    "        now = datetime.now(timezone.utc).astimezone(get_localzone())\n",
    "        try:\n",
    "            date = self.manager.getTokenExpirationDate(label, whom)\n",
    "            return {\n",
    "                \"code\"   : 206,\n",
    "                \"status\" : \"ok\",\n",
    "                \"date\"   : jsonpickle.encode(date),\n",
    "                \"ts\"     : now.isoformat()\n",
    "            }\n",
    "        except TokenNotFound as e:\n",
    "            return {\n",
    "                \"code\"   : 312,\n",
    "                \"status\" : \"token not found\",\n",
    "                \"error\"  : \"%s\" % e,\n",
    "                \"ts\"     : now.isoformat()\n",
    "            }\n",
    "        except Exception as e:\n",
    "            self.logger.info(\"error geting expiration date of token with label %s: %s\" % (label,e))\n",
    "            return {\n",
    "                \"code\"   : 314,\n",
    "                \"status\" : \"Could not get token expiration date\",\n",
    "                \"error\"  : \"%s\" % e,\n",
    "                \"ts\"     : now.isoformat()\n",
    "            }\n",
    "\n",
    "    def token_expiration(self, label, whom=None):\n",
    "        now = datetime.now(timezone.utc).astimezone(get_localzone())\n",
    "        try:\n",
    "            status = self.manager.tokenExpiration(label, whom)\n",
    "            return {\n",
    "                \"code\"       : 206,\n",
    "                \"status\"     : \"ok\",\n",
    "                \"token_status\" : jsonpickle.encode(status),\n",
    "                \"ts\"         : now.isoformat()\n",
    "            }\n",
    "        except TokenNotFound as e:\n",
    "            return {\n",
    "                \"code\"   : 312,\n",
    "                \"status\" : \"token not found\",\n",
    "                \"error\"  : \"%s\" % e,\n",
    "                \"ts\"     : now.isoformat()\n",
    "            }\n",
    "        except ExpiredToken as e:\n",
    "            return {\n",
    "                \"code\"   : 313,\n",
    "                \"status\" : \"token expired\",\n",
    "                \"error\"  : \"%s\" % e,\n",
    "                \"ts\"     : now.isoformat()\n",
    "            }\n",
    "        except Exception as e:\n",
    "            self.logger.info(\"error verifying expiration of token with label %s: %s\" % (label,e))\n",
    "            return {\n",
    "                \"code\"   : 314,\n",
    "                \"status\" : \"Could not verify expiration of token\",\n",
    "                \"error\"  : \"%s\" % e,\n",
    "                \"ts\"     : now.isoformat()\n",
    "            }\n",
    "        \n",
    "    def get_register_credential(self, label, token=None, whom=None):\n",
    "        now = datetime.now(timezone.utc).astimezone(get_localzone())\n",
    "        try:\n",
    "            credential = self.manager.getRegisterCredential(label, token, whom)\n",
    "            #credential_encode = credential.serialize()\n",
    "            credential_encode = jsonpickle.encode(credential)\n",
    "            return {\n",
    "                \"code\"       : 205,\n",
    "                \"status\"     : \"ok\",\n",
    "                \"credential\" : credential_encode,\n",
    "                \"ts\"         : now.isoformat()\n",
    "            }\n",
    "        except Exception as e:\n",
    "            self.logger.info(\"error retrieving  credential with label %s: %s\" % (label,e))\n",
    "            return {\n",
    "                \"code\"   : 313,\n",
    "                \"status\" : \"Could not retrieve credential\",\n",
    "                \"error\"  : \"%s\" % e,\n",
    "                \"ts\"     : now.isoformat()\n",
    "            }\n",
    "        \n",
    "    def put_persistent_dict(self, dict_name):\n",
    "        now = datetime.now(timezone.utc).astimezone(get_localzone())\n",
    "        json_input = request.json\n",
    "        \n",
    "        if \"key\" not in json_input or \"value\" not in json_input:\n",
    "            return {\n",
    "                \"code\"   : 311,\n",
    "                \"status\" : \"No key value provided\",\n",
    "                \"ts\"     : now.isoformat()\n",
    "            }    \n",
    "\n",
    "        key = json_input['key']\n",
    "        value = json_input['value']\n",
    "        try:\n",
    "            if self.manager.putInPersistentDict(dict_name, key,value):\n",
    "                return {\n",
    "                    \"code\"       : 200,\n",
    "                    \"status\"     : \"ok\",\n",
    "                    \"ts\"         : now.isoformat()\n",
    "                }\n",
    "            else:\n",
    "                return {\n",
    "                    \"code\"   : 312,\n",
    "                    \"status\" : \"Error putting key in persistent dict\",\n",
    "                    \"ts\"     : now.isoformat()\n",
    "                }    \n",
    "        except Exception as e:\n",
    "            self.logger.info(\"error putting key in dict %s:%s\" % (dict_name,e))\n",
    "            return {\n",
    "                \"code\"   : 313,\n",
    "                \"status\" : \"Error putting key in persistent dict\",\n",
    "                \"error\"  : \"%s\" % e,\n",
    "                \"ts\"     : now.isoformat()\n",
    "            }\n",
    "    \n",
    "    def get_persistent_dict(self, dict_name, key):\n",
    "        now = datetime.now(timezone.utc).astimezone(get_localzone())\n",
    "        try:\n",
    "            value = self.manager.getFromPersistentDict(dict_name, key)\n",
    "            \n",
    "            return {\n",
    "                \"code\"     : 200,\n",
    "                \"status\"   : \"OK\",\n",
    "                \"key\"      : key,\n",
    "                \"response\" : value,\n",
    "                \"ts\"       : now.isoformat()\n",
    "           }\n",
    "\n",
    "        except NoSuchDictionary as e:\n",
    "            return {\n",
    "                \"code\"   : 313,\n",
    "                \"status\" : \"Dictionary %s does not exists\" % dict_name,\n",
    "                \"ts\"     : now.isoformat()\n",
    "            }\n",
    "        \n",
    "        except NoSuchKeyInDictionary as e:\n",
    "            return {\n",
    "                \"code\"   : 313,\n",
    "                \"status\" : \"key %s does not exists\" % key,\n",
    "                \"ts\"     : now.isoformat()\n",
    "            }\n",
    "        \n",
    "        except Exception as e:\n",
    "            self.logger.info(\"error getting key %s in dict %s:%s\" % (key, dict_name,e))\n",
    "            return {\n",
    "                \"code\"   : 313,\n",
    "                \"status\" : \"Error getting key in persistent dict\",\n",
    "                \"error\"  : \"%s\" % e,\n",
    "                \"ts\"     : now.isoformat()\n",
    "            }\n",
    "\n",
    "    def get_persistent_dict_as_json(self, dict_name, key):\n",
    "        now = datetime.now(timezone.utc).astimezone(get_localzone())\n",
    "        try:\n",
    "            value = self.manager.getFromPersistentDict(dict_name, key)\n",
    "            \n",
    "            json_value = eval(value)\n",
    "            \n",
    "            return {\n",
    "                \"code\"     : 200,\n",
    "                \"status\"   : \"OK\",\n",
    "                \"key\"      : key,\n",
    "                \"response\" : json_value,\n",
    "                \"ts\"       : now.isoformat()\n",
    "           }\n",
    "\n",
    "        except NoSuchDictionary as e:\n",
    "            return {\n",
    "                \"code\"   : 313,\n",
    "                \"status\" : \"Dictionary %s does not exists\" % dict_name,\n",
    "                \"ts\"     : now.isoformat()\n",
    "            }\n",
    "        \n",
    "        except NoSuchKeyInDictionary as e:\n",
    "            return {\n",
    "                \"code\"   : 313,\n",
    "                \"status\" : \"key %s does not exists\" % key,\n",
    "                \"ts\"     : now.isoformat()\n",
    "            }\n",
    "        \n",
    "        except Exception as e:\n",
    "            self.logger.info(\"error putting key in dict %s:%s\" % (dict_name,e))\n",
    "            return {\n",
    "                \"code\"   : 313,\n",
    "                \"status\" : \"Error getting key in persistent dict\",\n",
    "                \"error\"  : \"%s\" % e,\n",
    "                \"ts\"     : now.isoformat()\n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-18T20:33:31.089693Z",
     "start_time": "2024-04-18T20:33:31.052599Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "%%deploy /orch/orchestrator/__init__.py\n",
    "from .RemoteProcedureNotification import *\n",
    "from .RemoteProcedureNotificationManager import *\n",
    "from .RemoteProcedureNotificationSubscriber import *\n",
    "from .OrchestratorAccess import *\n",
    "from .OrchestratorManager import *\n",
    "from .OrchestratorService import *\n",
    "from .OrchCredentialManager import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-10T06:24:08.325816Z",
     "start_time": "2021-04-10T06:24:08.323472Z"
    }
   },
   "source": [
    "## Orchestrator API\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-18T20:33:31.172807Z",
     "start_time": "2024-04-18T20:33:31.091751Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "%%deploy /orch/base/AbstractApiClient.py\n",
    "import json\n",
    "import jsonpickle\n",
    "import requests\n",
    "\n",
    "from requests.exceptions import *\n",
    "\n",
    "from ..exceptions import APIResponseError\n",
    "\n",
    "class AbstractApiClient(object):\n",
    "    def __init__(self, api_url = \"http://127.0.0.1:8020\"):\n",
    "        self.api_url = api_url\n",
    "        \n",
    "    def get(self,uri, timeout=180):\n",
    "        url = \"%s%s\" % (self.api_url,uri)\n",
    "        try:\n",
    "            response = requests.get(url, timeout=timeout)\n",
    "            if response.status_code >= 200 and response.status_code <=499:\n",
    "                json_response = response.json()\n",
    "                return json_response\n",
    "            else:\n",
    "                raise(APIResponseError(\"%d:%s\" % (response.status_code,response.text)))\n",
    "                \n",
    "        except ConnectionError as e:\n",
    "            print(\"Connection Error. Technical details given below.\\n\")\n",
    "            print(str(e))            \n",
    "        except Timeout as e:\n",
    "            print(\"Timeout Error\")\n",
    "            print(str(e))\n",
    "        except RequestException as e:\n",
    "            print(\"General Error\")\n",
    "            print(str(e))\n",
    "        except KeyboardInterrupt as e:\n",
    "            print(\"Someone closed the program\")\n",
    "        except Exception as e:\n",
    "            print(str(e))\n",
    "            raise e\n",
    "            \n",
    "    def post(self,uri,timeout=180, **kwargs):\n",
    "        url = \"%s%s\" % (self.api_url,uri)\n",
    "        try:\n",
    "            response = requests.post(url,timeout=timeout,**kwargs)\n",
    "\n",
    "            if response.status_code >= 200 and response.status_code <=499:\n",
    "                json_response = response.json()\n",
    "                return json_response\n",
    "            else:\n",
    "                raise(APIResponseError(\"%d:%s\" % (response.status_code,response.text)))\n",
    "        except ConnectionError as e:\n",
    "            print(\"Connection Error. Technical details given below.\\n\")\n",
    "            print(str(e))            \n",
    "        except Timeout as e:\n",
    "            print(\"Timeout Error\")\n",
    "            print(str(e))\n",
    "        except RequestException as e:\n",
    "            print(\"General Error\")\n",
    "            print(str(e))\n",
    "        except KeyboardInterrupt as e:\n",
    "            print(\"Someone closed the program\")\n",
    "        except Exception as e:\n",
    "            print(str(e))\n",
    "            raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-18T20:33:31.264248Z",
     "start_time": "2024-04-18T20:33:31.174547Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "%%deploy /orch/api/Pipeline.py\n",
    "\n",
    "from ..pipelinemanager import AbstractPipeline\n",
    "\n",
    "class Pipeline(AbstractPipeline):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-18T20:33:31.341815Z",
     "start_time": "2024-04-18T20:33:31.265970Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "%%deploy /orch/api/Execution.py\n",
    "import base64\n",
    "import dill\n",
    "import inspect\n",
    "from ..pipelinemanager import AbstractExecutor\n",
    "\n",
    "class Execution(AbstractExecutor):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-18T20:33:31.428183Z",
     "start_time": "2024-04-18T20:33:31.343417Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "%%deploy /orch/api/Executor.py\n",
    "# Executor skeleton\n",
    "import sys\n",
    "import io\n",
    "from io import StringIO\n",
    "from uuid import uuid4\n",
    "import base64\n",
    "import dill\n",
    "import jsonpickle\n",
    "import inspect\n",
    "import time\n",
    "from datetime import date, datetime, timezone\n",
    "from tzlocal import get_localzone\n",
    "\n",
    "from ..exceptions import *\n",
    "\n",
    "class Executor():\n",
    "    def __init__(self, orch_api, pipeline, local=True, cores=1, partition=None, memory=None):\n",
    "        self.orch_api    = orch_api\n",
    "        self.pipeline    = pipeline\n",
    "        self.cores       = cores\n",
    "        self.local_job   = local\n",
    "        self.memory      = memory\n",
    "        self.partition   = partition\n",
    "   \n",
    "    def setLocalJob(self, b):\n",
    "        self.local_job = b\n",
    "\n",
    "    def setCores(self, cores):\n",
    "        self.cores = cores\n",
    "\n",
    "    def run(self, *args, **kwargs):\n",
    "        post_data = {\n",
    "            \"name\"     : self.pipeline.name,\n",
    "            \"version\"  : self.pipeline.version,\n",
    "            \"cores\"    : self.cores,\n",
    "            \"asJob\"    : self.local_job,\n",
    "            \"args\"     : jsonpickle.encode( args ),\n",
    "            \"kwargs\"   : jsonpickle.encode( kwargs )\n",
    "        }\n",
    "        \n",
    "        if self.memory is not None:\n",
    "            post_data[\"memory\"] = self.memory\n",
    "\n",
    "        if self.partition is not None:\n",
    "            post_data[\"partition\"] = self.partition\n",
    "\n",
    "        print(post_data)\n",
    "            \n",
    "        try:\n",
    "            json_response = self.orch_api.post(\"/execute\",json=post_data)\n",
    "            if json_response[\"code\"] == 201:\n",
    "                self.execution_id = json_response[\"execution_id\"]\n",
    "                return self.execution_id\n",
    "            else:\n",
    "                raise PipelineExecutionError(json_response)\n",
    "        except Exception as e:\n",
    "            raise e\n",
    "\n",
    "    def cancel(self):\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-18T20:33:31.511727Z",
     "start_time": "2024-04-18T20:33:31.430242Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "%%deploy /orch/api/ScheduledEvent.py\n",
    "import base64\n",
    "import dill\n",
    "import inspect\n",
    "from ..scheduler import AbstractScheduledEvent\n",
    "\n",
    "class ScheduledEvent(AbstractScheduledEvent):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-18T20:33:31.593162Z",
     "start_time": "2024-04-18T20:33:31.513700Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "%%deploy /orch/api/RemoteProcedureNotification.py\n",
    "import base64\n",
    "import dill\n",
    "import inspect\n",
    "from ..orchestrator import AbstractRemoteProcedureNotification\n",
    "\n",
    "class RemoteProcedureNotification(AbstractRemoteProcedureNotification):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-18T20:33:31.676921Z",
     "start_time": "2024-04-18T20:33:31.594890Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "%%deploy /orch/api/RemoteProcedureNotificationSubscriber.py\n",
    "import base64\n",
    "import dill\n",
    "import inspect\n",
    "from ..orchestrator import AbstractRemoteProcedureNotificationSubscriber\n",
    "\n",
    "class RemoteProcedureNotificationSubscriber(AbstractRemoteProcedureNotificationSubscriber):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-18T20:33:31.788870Z",
     "start_time": "2024-04-18T20:33:31.679112Z"
    },
    "code_folding": [
     0,
     34
    ]
   },
   "outputs": [],
   "source": [
    "%%deploy /orch/api/Orchestrator.py\n",
    "import jsonpickle\n",
    "from inspect import isfunction\n",
    "import dill\n",
    "import base64\n",
    "import urllib\n",
    "from datetime import datetime\n",
    "\n",
    "from .Execution import Execution\n",
    "from .ScheduledEvent import ScheduledEvent\n",
    "from .RemoteProcedureNotification import RemoteProcedureNotification\n",
    "from .Pipeline import Pipeline\n",
    "from .Executor import *\n",
    "\n",
    "from ..base import AbstractApiClient\n",
    "from ..exceptions import PipelineExecutionError, ImplementationIsNotAFunction, APIResponseError, PipelineSchedulingError\n",
    "from ..orchestrator import RemoteProcedureNotificationSubscriber\n",
    "\n",
    "from credentialmanager.Credential import Credential\n",
    "from credentialmanager.EncryptionKey import EncryptionKey\n",
    "\n",
    "class Orchestrator(AbstractApiClient):\n",
    "    def __init__(self, api_url=\"http://127.0.0.1:8020\"):\n",
    "        super().__init__(api_url)\n",
    "        \n",
    "    def status(self):\n",
    "        return self.get(\"/\")\n",
    "    \n",
    "    def stop(self):\n",
    "        # TODO: check permision to stop\n",
    "        #self.get(\"/stop\")\n",
    "        #return True\n",
    "        return False\n",
    "    \n",
    "    def subscribePipelineNotification(self, label, pipeline, *args, **kw_args):\n",
    "        if isinstance(label,str) and len(label)>0 and isinstance(pipeline,Pipeline):\n",
    "\n",
    "            subscription_data = {\n",
    "                \"pipeline_name\" : pipeline.name\n",
    "            }\n",
    "\n",
    "            response = self.post(\"/rpn/%s/subscribe\" % label, json=subscription_data)\n",
    "            obj_list = []\n",
    "            if response[\"code\"]==204:\n",
    "                sobj = response[\"subscription\"]\n",
    "                obj = RemoteProcedureNotificationSubscriber.fromJson(dill.loads(base64.b64decode(sobj[\"sobj\"].encode(\"utf8\"))))\n",
    "                return obj\n",
    "            elif response[\"code\"]==501:\n",
    "                e = dill.loads(base64.b64decode(response[\"exception\"].encode(\"urf8\")))\n",
    "                raise e\n",
    "            else:\n",
    "                raise APIResponseError(\"%d:%s\" % (response[\"code\"],response[\"status\"]))\n",
    "        else:\n",
    "            raise RuntimeError(\"you must provide a valid notification label\")\n",
    "\n",
    "    def unsubscribePipelineNotification(self, label, pipeline, *args, **kw_args):\n",
    "        if isinstance(label,str) and len(label)>0 and isinstance(pipeline,Pipeline):\n",
    "\n",
    "            subscription_data = {\n",
    "                \"pipeline_name\" : pipeline.name\n",
    "            }\n",
    "\n",
    "            response = self.post(\"/rpn/%s/unsubscribe\" % label, json=subscription_data)\n",
    "            obj_list = []\n",
    "            if response[\"code\"]==204:\n",
    "                return True\n",
    "            elif response[\"code\"]==501:\n",
    "                e = dill.loads(base64.b64decode(response[\"exception\"].encode(\"urf8\")))\n",
    "                raise e\n",
    "            else:\n",
    "                raise APIResponseError(\"%d:%s\" % (response[\"code\"],response[\"status\"]))\n",
    "        else:\n",
    "            raise RuntimeError(\"you must provide a valid notification label\")\n",
    "\n",
    "    def createNotification(self, label, data={}):\n",
    "        if isinstance(label,str) and len(label)>0:\n",
    "            \n",
    "            response = None\n",
    "            if len(data.keys())>0:\n",
    "                params = urllib.parse.urlencode(data)\n",
    "                response = self.get(\"/rpn/%s/notify?%s\" % (label,params))\n",
    "            else:\n",
    "                response = self.get(\"/rpn/%s/notify\" % label)\n",
    "                \n",
    "            obj_list = []\n",
    "            if response[\"code\"]==204:\n",
    "                sobj = response[\"notification\"]\n",
    "                obj = RemoteProcedureNotification.fromJson(dill.loads(base64.b64decode(sobj[\"sobj\"].encode(\"utf8\"))))\n",
    "                return obj\n",
    "            elif response[\"code\"]==311:\n",
    "                # notification not created\n",
    "                raise APIResponseError(\"%d:%s\" % (response[\"code\"],response[\"status\"]))\n",
    "        else:\n",
    "            raise RuntimeError(\"you must provide a valid notification label\")\n",
    "    \n",
    "    def getLastNotification(self,label):\n",
    "        if isinstance(label,str) and len(label)>0:\n",
    "            response = self.get(\"/rpn/%s/last\" % label)\n",
    "            obj_list = []\n",
    "            if response[\"code\"]==204:\n",
    "                sobj = response[\"notification\"]\n",
    "                obj = RemoteProcedureNotification.fromJson(dill.loads(base64.b64decode(sobj[\"sobj\"].encode(\"utf8\"))))\n",
    "                return obj\n",
    "            elif response[\"code\"]==311:\n",
    "                # notification not created\n",
    "                raise APIResponseError(\"%d:%s\" % (response[\"code\"],response[\"status\"]))\n",
    "        else:\n",
    "            raise RuntimeError(\"you must provide a valid notification label\")\n",
    "    \n",
    "    def getNotificationList(self,label):\n",
    "        if label is not None or label!=\"\":\n",
    "            try:\n",
    "                response = self.get(\"/rpn/%s/list\" % label)\n",
    "                obj_list = []\n",
    "                if response[\"code\"]==204:\n",
    "                    for sobj in response[\"notification_list\"]:\n",
    "                        obj = RemoteProcedureNotification.fromJson(dill.loads(base64.b64decode(sobj[\"sobj\"].encode(\"utf8\"))))\n",
    "                        obj_list.append(obj)\n",
    "                    return obj_list\n",
    "                elif response[\"code\"]==311:\n",
    "                    # no rpn found\n",
    "                    return []\n",
    "                else:\n",
    "                    raise APIResponseError(\"%d:%s\" % (response[\"code\"],response[\"status\"]))\n",
    "                \n",
    "            except Exception as e:\n",
    "                raise e\n",
    "\n",
    "        raise RuntimeError(\"you must provide a valid notification label\")\n",
    "\n",
    "    def register(self, name,fn, token_list=None, new_version =False):\n",
    "        \n",
    "        if not isfunction(fn):\n",
    "            raise ImplementationIsNotAFunction(fn)\n",
    "        \n",
    "        post_data = {\n",
    "            \"name\"        : name,\n",
    "            \"pipeline\"    : base64.b64encode(dill.dumps(fn)).decode(\"utf8\"),\n",
    "            \"token_list\"  : str(token_list),\n",
    "            \"new_version\" : new_version\n",
    "        }\n",
    "\n",
    "        return self.post(\"/register\",json=post_data)\n",
    "    \n",
    "    def getActivePipeline(self, name):\n",
    "        pipelines = self.getPipelines(name, active = True)\n",
    "        if len(pipelines)==1:\n",
    "            return pipelines[0]\n",
    "        elif len(pipelines)>1:\n",
    "            raise MultipleActivePipelineRegistered(name)\n",
    "        else:\n",
    "            raise NoActivePipelineRegistered(name)\n",
    "\n",
    "    def getPipelines(self, name, **kwargs):\n",
    "        post_data = {\n",
    "            \"name\" : name,\n",
    "        }\n",
    "\n",
    "        post_data.update(kwargs)\n",
    "        json_response = self.post(\"/get\",json=post_data)\n",
    "        \n",
    "        if \"pipeline\" in json_response:\n",
    "            pipe_json_list = json_response[\"pipeline\"]\n",
    "            pipelines_list = [ Pipeline.fromJson(pipe_json) for pipe_json in pipe_json_list]\n",
    "            return pipelines_list\n",
    "        else:\n",
    "            return None\n",
    "        \n",
    "    def activatePipeline(self, pipeline):\n",
    "        post_data = {\n",
    "            \"name\"     : pipeline.name,\n",
    "            \"version\"  : pipeline.version\n",
    "        }\n",
    "        return self.post('/activate',json=post_data)\n",
    "    \n",
    "    def deactivatePipeline(self, pipeline):\n",
    "        post_data = {\n",
    "            \"name\"     : pipeline.name,\n",
    "            \"version\"  : pipeline.version\n",
    "        }\n",
    "        return self.post('/deactivate',json=post_data)\n",
    "    \n",
    "    def getExecutionStatus(self, exec_id):\n",
    "        if exec_id is not None:\n",
    "            try:\n",
    "                return self.get(\"/execution/%s/status\" % exec_id)\n",
    "            except Exception as e:\n",
    "                raise e\n",
    "        \n",
    "        raise RuntimeError(\"you must provide a valid execution_id\")\n",
    "\n",
    "    def getExecution(self, exec_id):\n",
    "        if exec_id is not None:\n",
    "            try:\n",
    "                json_response = self.get(\"/execution/%s/get\" % exec_id)\n",
    "                if json_response[\"code\"] == 202:\n",
    "                    s_executor = dill.loads(base64.b64decode(json_response[\"executor\"][\"sobj\"]))\n",
    "                    executor = Execution.fromJson(s_executor)\n",
    "                    return executor\n",
    "                else:\n",
    "                    return json_response\n",
    "\n",
    "            except Exception as e:\n",
    "                raise e\n",
    "\n",
    "        \n",
    "        raise RuntimeError(\"you must provide a valid execution_id\")\n",
    "     \n",
    "    def cancelExecution(self, exec_id):\n",
    "        if exec_id is not None:\n",
    "            try:\n",
    "                json_response = self.get(\"/execution/%s/cancel\" % exec_id)\n",
    "                if json_response[\"code\"] == 202 or json_response[\"code\"] == 311:\n",
    "                    s_executor = dill.loads(base64.b64decode(json_response[\"executor\"][\"sobj\"]))\n",
    "                    executor = Execution.fromJson(s_executor)\n",
    "                    json_response[\"executor\"] = executor\n",
    "                    return json_response\n",
    "                else:\n",
    "                    return json_response\n",
    "\n",
    "            except Exception as e:\n",
    "                raise e\n",
    "\n",
    "        raise RuntimeError(\"you must provide a valid execution_id\")\n",
    "        \n",
    "    def notifyExecution(self, target):\n",
    "        print(\"notifyExecution only works when executing within the orchestrator\")\n",
    "        \n",
    "    def getExecutionList(self, name):\n",
    "        if name is not None or name!=\"\":\n",
    "            try:\n",
    "                response = self.get(\"/execution/%s/list\" % name)\n",
    "                obj_list = []\n",
    "                if response[\"code\"]==204:\n",
    "                    for sobj in response[\"executions\"]:\n",
    "                        obj = Execution.fromJson(dill.loads(base64.b64decode(sobj[\"sobj\"].encode(\"utf8\"))))\n",
    "                        obj_list.append(obj)\n",
    "                    return obj_list\n",
    "                elif response[\"code\"]==311:\n",
    "                    # no execution found\n",
    "                    return []\n",
    "                else:\n",
    "                    raise APIResponseError(\"%d:%s\" % (response[\"code\"],response[\"status\"]))\n",
    "                \n",
    "            except Exception as e:\n",
    "                raise e\n",
    "        \n",
    "        raise RuntimeError(\"you must provide a valid execution_id\")\n",
    "    \n",
    "    def getRunningExecutions(self):\n",
    "        try:\n",
    "            response = self.get(\"/execution/running\")\n",
    "            obj_list = []\n",
    "            if response[\"code\"]==204:\n",
    "                for sobj in response[\"executions\"]:\n",
    "                    obj = Execution.fromJson(dill.loads(base64.b64decode(sobj[\"sobj\"].encode(\"utf8\"))))\n",
    "                    obj_list.append(obj)\n",
    "                return obj_list\n",
    "            elif response[\"code\"]==401:\n",
    "                # no execution found\n",
    "                return []\n",
    "            else:\n",
    "                raise APIResponseError(\"%d:%s\" % (response[\"code\"],response[\"status\"]))\n",
    "\n",
    "        except Exception as e:\n",
    "            raise e\n",
    "      \n",
    "    def getExecutionsBy(self,where):\n",
    "        try:\n",
    "            json_data = {\n",
    "                \"where\": where\n",
    "            }\n",
    "            \n",
    "            response = self.post(\"/execution/getby\",json=json_data)\n",
    "            obj_list = []\n",
    "            if response[\"code\"]==204:\n",
    "                for sobj in response[\"executions\"]:\n",
    "                    obj = Execution.fromJson(dill.loads(base64.b64decode(sobj[\"sobj\"].encode(\"utf8\"))))\n",
    "                    obj_list.append(obj)\n",
    "                return obj_list\n",
    "            elif response[\"code\"]==401:\n",
    "                # no execution found\n",
    "                return []\n",
    "            else:\n",
    "                raise APIResponseError(\"%d:%s\" % (response[\"code\"],response[\"status\"]))\n",
    "\n",
    "        except Exception as e:\n",
    "            raise e    \n",
    "\n",
    "    def getLastExecution(self, name):\n",
    "        if name is not None:\n",
    "            try:\n",
    "                json_response = self.get(\"/execution/%s/last\" % name)\n",
    "                if json_response[\"code\"] == 202:\n",
    "                    s_executor = dill.loads(base64.b64decode(json_response[\"executor\"][\"sobj\"]))\n",
    "                    executor = Execution.fromJson(s_executor)\n",
    "                    return executor\n",
    "                else:\n",
    "                    return json_response\n",
    "                \n",
    "            except Exception as e:\n",
    "                raise e\n",
    "\n",
    "    def createExecutor(self, pipeline, *args, **kwargs):\n",
    "        executor = Executor(self, pipeline, *args, **kwargs)\n",
    "        return executor\n",
    "\n",
    "    def execute(self, pipeline, *args, **kwargs):\n",
    "        post_data = {\n",
    "            \"name\"     : pipeline.name,\n",
    "            \"version\"  : pipeline.version,\n",
    "            \"args\"     : jsonpickle.encode( args ),\n",
    "            \"kwargs\"   : jsonpickle.encode( kwargs )\n",
    "        }\n",
    "        try:\n",
    "            json_response = self.post(\"/execute\",json=post_data)\n",
    "            if json_response[\"code\"] == 201:\n",
    "                return json_response[\"execution_id\"]\n",
    "            else:\n",
    "                raise PipelineExecutionError(json_response)\n",
    "        except Exception as e:\n",
    "            raise e\n",
    "                \n",
    "    def scheduleAt(self, pipeline, label = None, trigger_time=datetime.now().strftime(\"%H:%M:%S\"), recurrency=None, tags=[]):\n",
    "        post_data = {\n",
    "            \"name\"         : pipeline.name,\n",
    "            \"label\"        : label,\n",
    "            \"trigger_time\" : trigger_time,\n",
    "            \"recurrency\"   : recurrency,\n",
    "            \"tags\"         : tags,\n",
    "            \"args\"         : jsonpickle.encode( pipeline.getArguments() ),\n",
    "            \"kwargs\"       : jsonpickle.encode( pipeline.getKeywordArguments() )\n",
    "        }\n",
    "        \n",
    "        print(post_data)\n",
    "        \n",
    "        try:\n",
    "            json_response = self.post(\"/scheduleAt\",json=post_data)\n",
    "            if json_response[\"code\"] == 201:\n",
    "                return json_response\n",
    "            else:\n",
    "                raise PipelineSchedulingError(json_response)\n",
    "        except Exception as e:\n",
    "            raise e\n",
    "\n",
    "    def getScheduledExecutions(self, pipeline):\n",
    "        if isinstance(pipeline, Pipeline):\n",
    "            name = pipeline.name\n",
    "            if name is not None or name!=\"\":\n",
    "                try:\n",
    "                    response = self.get(\"/execution/%s/scheduled\" % name)\n",
    "                    obj_list = []\n",
    "                    if response[\"code\"]==204:\n",
    "                        for sobj in response[\"scheduled\"]:\n",
    "                            obj = ScheduledEvent.fromJson(dill.loads(base64.b64decode(sobj[\"sobj\"].encode(\"ascii\"))))\n",
    "                            obj_list.append(obj)\n",
    "                        return obj_list\n",
    "                    elif response[\"code\"]==311:\n",
    "                        # no execution found\n",
    "                        return []\n",
    "                    else:\n",
    "                        raise APIResponseError(\"%d:%s\" % (response[\"code\"],response[\"status\"]))\n",
    "\n",
    "                except Exception as e:\n",
    "                    raise e\n",
    "        raise RuntimeError(\"pipeline argument must be a Pipeline instance\")\n",
    "    \n",
    "    def getScheduledExecutionById(self, scheduled_event_id):\n",
    "        if scheduled_event_id is not None and scheduled_event_id!=\"\":\n",
    "            try:\n",
    "                response = self.get(\"/schedule/%s/get\" % scheduled_event_id)\n",
    "                if response[\"code\"]==204:\n",
    "                    return ScheduledEvent.fromJson(dill.loads(base64.b64decode(response[\"scheduled_evt\"][\"sobj\"].encode(\"utf8\"))))\n",
    "                else:\n",
    "                    raise APIResponseError(\"%d:%s\" % (response[\"code\"],response[\"status\"]))\n",
    "\n",
    "            except Exception as e:\n",
    "                raise e\n",
    "        else:\n",
    "            raise RuntimeError(\"you must provide a valid scheduled event id\")\n",
    "\n",
    "    def cancelScheduledExecution(self, scheduled_event):\n",
    "        if isinstance(scheduled_event,ScheduledEvent):\n",
    "            try:\n",
    "                response = self.get(\"/schedule/%s/cancel\" % scheduled_event.uuid)\n",
    "                if response[\"code\"]==204:\n",
    "                    return True\n",
    "                else:\n",
    "                    raise APIResponseError(\"%d:%s\" % (response[\"code\"],response[\"status\"]))\n",
    "\n",
    "            except Exception as e:\n",
    "                raise e\n",
    "        else:\n",
    "            raise RuntimeError(\"you must provide a valid scheduled event\")\n",
    "\n",
    "    def putKey(self, key, passphrase=None):\n",
    "        if not isinstance(key, EncryptionKey):\n",
    "            raise RuntimeError(\"key argument must be a Key instance\")\n",
    "        if not isinstance(passphrase,(str,type(None))):\n",
    "            raise RuntimeError(\"you must provide a valid passphrase\")\n",
    "        key.encodeKey()\n",
    "        key_encode = jsonpickle.encode(key)\n",
    "        key.decodeKey()\n",
    "        post_data = {\n",
    "            \"label\"      : key.getLabel(),\n",
    "            \"key\"        : key_encode,\n",
    "            \"passphrase\" : passphrase,\n",
    "        }\n",
    "        return self.post(\"/putKey\",json=post_data)\n",
    "        \n",
    "    def getKey(self, label, passphrase=None):\n",
    "        if not isinstance(label,str):\n",
    "            raise RuntimeError(\"you must provide a valid label\")\n",
    "        if not isinstance(passphrase,(str,type(None))):\n",
    "            raise RuntimeError(\"you must provide a valid passphrase\")\n",
    "        try:\n",
    "            response = self.get(\"/key/%s/%s/getKey\" %(label, passphrase))\n",
    "            if response[\"code\"]==205:\n",
    "                key = EncryptionKey.deserialize(response['key'])\n",
    "                response['key'] = key\n",
    "                return response\n",
    "            elif response[\"code\"]==312:\n",
    "                return response\n",
    "            else:\n",
    "                raise APIResponseError(\"%d:%s\" % (response[\"code\"],response[\"status\"]))\n",
    "\n",
    "        except Exception as e:\n",
    "            raise e\n",
    "            \n",
    "    def getPublicKey(self): # NUEVA\n",
    "        try:\n",
    "            response = self.get(\"/key/getPublicKey\")\n",
    "            if response[\"code\"]==205:\n",
    "                key = EncryptionKey.deserialize(response['key'])\n",
    "                response['key'] = key\n",
    "                return response\n",
    "            else:\n",
    "                raise APIResponseError(\"%d:%s\" % (response[\"code\"],response[\"status\"]))\n",
    "\n",
    "        except Exception as e:\n",
    "            raise e\n",
    "        \n",
    "    def getKeyList(self, active=True):\n",
    "        if not isinstance(active,bool):\n",
    "            raise RuntimeError(\"you must provide a valid argument\")\n",
    "        try:\n",
    "            response = self.get(\"/KeyList/%s\" % active)\n",
    "            if response[\"code\"]==206:\n",
    "                keys = jsonpickle.loads(response['keys'])\n",
    "                list_keys=[]\n",
    "                for key in keys:\n",
    "                    list_keys.append(EncryptionKey.deserialize(key))\n",
    "                response['keys'] = list_keys\n",
    "                return response\n",
    "            elif response[\"code\"]==312:\n",
    "                #don't exist keys\n",
    "                return response\n",
    "            else:\n",
    "                raise APIResponseError(\"%d:%s\" % (response[\"code\"],response[\"status\"]))\n",
    "\n",
    "        except Exception as e:\n",
    "            raise e\n",
    "    \n",
    "    def keyExpiration(self, key):\n",
    "        if not isinstance(key, EncryptionKey):\n",
    "            raise RuntimeError(\"key argument must be a Key instance\")\n",
    "        key.encodeKey()\n",
    "        key_encode = jsonpickle.encode(key)\n",
    "        key.decodeKey()\n",
    "        post_data = {\n",
    "            \"label\"  : key.getLabel(),\n",
    "            \"key\"    : key_encode,\n",
    "        }\n",
    "        try:\n",
    "            response = self.post(\"/keyExpiration\",json=post_data)\n",
    "            if response[\"code\"]==206 or response[\"code\"]==314:\n",
    "                response['key_status'] = jsonpickle.loads(response['key_status'])\n",
    "                return response\n",
    "            elif response[\"code\"]==312:\n",
    "                return response\n",
    "            else:\n",
    "                raise APIResponseError(\"%d:%s\" % (response[\"code\"],response[\"status\"]))\n",
    "        except Exception as e:\n",
    "            raise e\n",
    "    \n",
    "    def getKeyExpirationDate(self, key):\n",
    "        if not isinstance(key, EncryptionKey):\n",
    "            raise RuntimeError(\"key argument must be a Key instance\")\n",
    "        \n",
    "        key.encodeKey()\n",
    "        key_encode = jsonpickle.encode(key)\n",
    "        key.decodeKey()\n",
    "        post_data = {\n",
    "            \"label\"  : key.getLabel(),\n",
    "            \"key\"    : key_encode,\n",
    "        }\n",
    "        try:\n",
    "            response = self.post(\"/keyExpirationDate\",json=post_data)\n",
    "            if response[\"code\"]==206:\n",
    "                response['date'] = jsonpickle.loads(response['date'])\n",
    "                return response\n",
    "            elif response[\"code\"]==312:\n",
    "                return response\n",
    "            else:\n",
    "                raise APIResponseError(\"%d:%s\" % (response[\"code\"],response[\"status\"]))\n",
    "        except Exception as e:\n",
    "            raise e\n",
    "     \n",
    "    def getCredentialList(self, active=True):\n",
    "        if not isinstance(active,bool):\n",
    "            raise RuntimeError(\"you must provide a valid argument\")\n",
    "        try:\n",
    "            response = self.get(\"/credentialList/%s\" % active)\n",
    "            if response[\"code\"]==206:\n",
    "                response['credentials'] = jsonpickle.loads(response['credentials'])\n",
    "                return response\n",
    "            elif response[\"code\"]==312:\n",
    "                #don't exist credentials\n",
    "                return response\n",
    "            else:\n",
    "                raise APIResponseError(\"%d:%s\" % (response[\"code\"],response[\"status\"]))\n",
    "\n",
    "        except Exception as e:\n",
    "            raise e\n",
    "     \n",
    "    def credentialExpiration(self, label):\n",
    "        if not isinstance(label,str):\n",
    "            raise RuntimeError(\"you must provide a valid label\")\n",
    "        try:\n",
    "            response = self.get(\"/credential/%s/credentialExpiration\" % label)\n",
    "            if response[\"code\"]==206 or response[\"code\"]==314:\n",
    "                response['credential_status'] = jsonpickle.loads(response['credential_status'])\n",
    "                return response\n",
    "            elif response[\"code\"]==312 or response[\"code\"]==313:\n",
    "                return response\n",
    "            else:\n",
    "                raise APIResponseError(\"%d:%s\" % (response[\"code\"],response[\"status\"]))\n",
    "        except Exception as e:\n",
    "            raise e\n",
    "            \n",
    "    def getCredentialExpirationDate(self, label):\n",
    "        if not isinstance(label,str):\n",
    "            raise RuntimeError(\"you must provide a valid label\")\n",
    "        try:\n",
    "            response = self.get(\"/credential/%s/credentialExpirationDate\" % label)\n",
    "            if response[\"code\"]==206:\n",
    "                response['date'] = jsonpickle.loads(response['date'])\n",
    "                return response\n",
    "            elif response[\"code\"]==312:\n",
    "                return response\n",
    "            else:\n",
    "                raise APIResponseError(\"%d:%s\" % (response[\"code\"],response[\"status\"]))\n",
    "        except Exception as e:\n",
    "            raise e\n",
    "    \n",
    "    def signCredential(self, credential, key=None):\n",
    "        if not isinstance(credential, Credential):\n",
    "            raise RuntimeError(\"credential argument must be a Credential instance\")\n",
    "        key_encode = None\n",
    "        if key is not None:\n",
    "            if not isinstance(key, EncryptionKey):\n",
    "                raise RuntimeError(\"key argument must be a Key instance\")\n",
    "            key.encodeKey()\n",
    "            key_encode= jsonpickle.encode(key)\n",
    "            key.decodeKey()\n",
    "        post_data = {\n",
    "            \"label\"       : credential.getLabel(),\n",
    "            \"credential\"  : jsonpickle.encode(credential),\n",
    "            \"key\"         : key_encode,\n",
    "        }\n",
    "        \n",
    "        return self.post(\"/signCredential\",json=post_data)\n",
    "    \n",
    "    def putCredential(self, credential, n_unlock=2, shared_users=4):\n",
    "        if not isinstance(credential, Credential):\n",
    "            raise RuntimeError(\"credential argument must be a Credential instance\")\n",
    "        if not isinstance(n_unlock, int):\n",
    "            raise RuntimeError(\"credential argument must be a Credential instance\") \n",
    "        if not isinstance(shared_users, int):\n",
    "            raise RuntimeError(\"credential argument must be a Credential instance\") \n",
    "        post_data = {\n",
    "            \"label\"         : credential.getLabel(),\n",
    "            \"credential\"    : jsonpickle.encode(credential),\n",
    "            \"n_unlock\"      : n_unlock,\n",
    "            \"shared_users\"  : shared_users,\n",
    "        }\n",
    "        return self.post(\"/putCredential\",json=post_data)\n",
    "        \n",
    "    def getCredential(self, label, decrypt=True, token=None, whom=None):\n",
    "        if not isinstance(label,str):\n",
    "            raise RuntimeError(\"you must provide a valid label\")\n",
    "        if not isinstance(decrypt,bool):\n",
    "            raise RuntimeError(\"you must provide a valid decrypt argument\")\n",
    "        if not isinstance(whom,(str,type(None))):\n",
    "            raise RuntimeError(\"you must provide a valid whom argument\")\n",
    "        token_encode = jsonpickle.encode(token)\n",
    "        try:\n",
    "            post_data = {\n",
    "                \"label\"   : label,\n",
    "                \"decrypt\" : decrypt,\n",
    "                \"token\"   : token_encode,\n",
    "                \"whom\"    : whom,\n",
    "            }      \n",
    "            response = self.post(\"/getCredential\",json=post_data)\n",
    "            if response[\"code\"]==205:\n",
    "                response['credential'] = Credential.deserialize(response['credential'])\n",
    "                return  response\n",
    "            elif response[\"code\"]==312 or response[\"code\"]==313:\n",
    "                #don't exist credential or token not found to decrypt\n",
    "                return response\n",
    "            else:\n",
    "                raise APIResponseError(\"%d:%s\" % (response[\"code\"],response[\"status\"]))   \n",
    "        except Exception as e:\n",
    "            raise e\n",
    "    \n",
    "    def verifyCredential(self, credential):\n",
    "        if not isinstance(credential, Credential):\n",
    "            raise RuntimeError(\"credential argument must be a Credential instance\")  \n",
    "        post_data = {\n",
    "            \"label\"        : credential.getLabel(),\n",
    "            \"credential\"  : jsonpickle.encode(credential),\n",
    "        }      \n",
    "        return self.post(\"/verifyCredential\",json=post_data)\n",
    "    \n",
    "    def encryptCredential(self, credential, recipient_key):\n",
    "        if not isinstance(credential, Credential):\n",
    "            raise RuntimeError(\"credential argument must be a Credential instance\")  \n",
    "        if not isinstance(recipient_key, EncryptionKey):\n",
    "                raise RuntimeError(\"key argument must be a Key instance\")\n",
    "        recipient_key.encodeKey()\n",
    "        key_encode= jsonpickle.encode(recipient_key)\n",
    "        recipient_key.decodeKey()\n",
    "        post_data = {\n",
    "            \"credential\" : jsonpickle.encode(credential),\n",
    "            \"key\"        : key_encode,\n",
    "        }\n",
    "        try:\n",
    "            response = self.post(\"/encryptCredential\",json=post_data)\n",
    "            if response[\"code\"]==206:\n",
    "                response['credential_encrypted'] = jsonpickle.loads(response['credential_encrypted'])\n",
    "                return response \n",
    "            else:\n",
    "                raise APIResponseError(\"%d:%s\" % (response[\"code\"],response[\"status\"]))\n",
    "        except Exception as e:\n",
    "            raise e        \n",
    "        \n",
    "    def createToken(self, credential, min_unlock=2, shared_users=4):\n",
    "        if not isinstance(credential, Credential):\n",
    "            raise RuntimeError(\"credential argument must be a Credential instance\")\n",
    "        if not isinstance(min_unlock, int):\n",
    "            raise RuntimeError(\"argument must be int\")\n",
    "        if not isinstance(shared_users, int):\n",
    "            raise RuntimeError(\"argument must be int\")\n",
    "        post_data = {\n",
    "            \"credential\"     : jsonpickle.encode(credential),\n",
    "            \"minimum_unlock\" : min_unlock,\n",
    "            \"shared_users\"   : shared_users, \n",
    "        }\n",
    "        try:\n",
    "            response = self.post(\"/createToken\",json=post_data)\n",
    "            if response[\"code\"]==206:\n",
    "                response[\"token\"] = jsonpickle.loads(response[\"token\"])\n",
    "                response[\"credential_encrypted\"] = jsonpickle.loads(response[\"credential_encrypted\"])\n",
    "                return response\n",
    "            else:\n",
    "                raise APIResponseError(\"%d:%s\" % (response[\"code\"],response[\"status\"]))\n",
    "        except Exception as e:\n",
    "            raise e\n",
    "\n",
    "    def putToken(self, credential, token_list):\n",
    "        if not isinstance(credential, Credential):\n",
    "            raise RuntimeError(\"credential argument must be a Credential instance\")\n",
    "        if not isinstance(token_list, list):\n",
    "            raise RuntimeError(\"argument must be a list\")\n",
    "        post_data = {\n",
    "            \"credential\"  : jsonpickle.encode(credential),\n",
    "            \"token_list\"  : jsonpickle.encode(token_list),\n",
    "        }        \n",
    "        return self.post(\"/putToken\",json=post_data)\n",
    "    \n",
    "    def getToken(self, label=None, whom=None, active=False):\n",
    "        if not isinstance(label,(str,type(None))):\n",
    "            raise RuntimeError(\"you must provide a valid label\")\n",
    "        if not isinstance(whom,(str,type(None))):\n",
    "            raise RuntimeError(\"you must provide a valid whom argument\")\n",
    "        try:\n",
    "            response = self.get(\"/credential/%s/%s/%s/getToken\" % (label, whom, active))\n",
    "            if response[\"code\"]==205:\n",
    "                response['token'] = jsonpickle.loads(response['token'])\n",
    "                return response \n",
    "            elif response[\"code\"]==312:\n",
    "                return response\n",
    "            else:\n",
    "                raise APIResponseError(\"%d:%s\" % (response[\"code\"],response[\"status\"]))\n",
    "\n",
    "        except Exception as e:\n",
    "            raise e\n",
    "    \n",
    "    def assignToken(self, whom, label, exp_date, comment=\"\"):\n",
    "        if not isinstance(whom,str):\n",
    "            raise RuntimeError(\"you must provide a valid whom argument\")\n",
    "        if not isinstance(label,str):\n",
    "            raise RuntimeError(\"you must provide a valid label\")\n",
    "        if not isinstance(comment,str):\n",
    "            raise RuntimeError(\"you must provide a valid comment argument\")\n",
    "        post_data = {\n",
    "            \"whom\"      : whom,\n",
    "            \"label\"     : label,\n",
    "            \"exp_date\"  : jsonpickle.encode(exp_date),\n",
    "            \"comment\"   : comment,\n",
    "        }\n",
    "        \n",
    "        return self.post(\"/assignToken\",json=post_data)\n",
    "    \n",
    "    def getAssignedToken(self, label, whom):\n",
    "        if not isinstance(label,str):\n",
    "            raise RuntimeError(\"you must provide a valid label\")\n",
    "        if not isinstance(whom,str):\n",
    "            raise RuntimeError(\"you must provide a valid whom argument\")\n",
    "        try:\n",
    "            response = self.get(\"/token/%s/%s/getAssignedToken\" %(label, whom))\n",
    "            if response[\"code\"]==205:\n",
    "                response['token'] = jsonpickle.loads(response['token'])\n",
    "                return response\n",
    "            elif response[\"code\"]==312:\n",
    "                return response\n",
    "            else:\n",
    "                raise APIResponseError(\"%d:%s\" % (response[\"code\"],response[\"status\"]))\n",
    "\n",
    "        except Exception as e:\n",
    "            raise e\n",
    "    \n",
    "    def signToken(self, label, whom):\n",
    "        if not isinstance(label,str):\n",
    "            raise RuntimeError(\"you must provide a valid label\")\n",
    "        if not isinstance(whom,str):\n",
    "            raise RuntimeError(\"you must provide a valid whom argument\")\n",
    "        post_data = {\n",
    "            \"label\" : label,\n",
    "            \"whom\"  : whom,\n",
    "        }\n",
    "        return self.post(\"/signToken\",json=post_data)\n",
    "        \n",
    "    def verifyToken(self, token):  \n",
    "        post_data = {\n",
    "            \"token\"  : jsonpickle.encode(token),\n",
    "        }      \n",
    "        return self.post(\"/verifyToken\",json=post_data)\n",
    "    \n",
    "    def getTokenList(self, active=False):\n",
    "        if not isinstance(active,bool):\n",
    "            raise RuntimeError(\"you must provide a valid argument\")\n",
    "        try:\n",
    "            response = self.get(\"/tokenList/%s\" % active)\n",
    "            if response[\"code\"]==206:\n",
    "                response['token_list'] = jsonpickle.loads(response['token_list'])\n",
    "                return response\n",
    "            else:\n",
    "                raise APIResponseError(\"%d:%s\" % (response[\"code\"],response[\"status\"]))\n",
    "\n",
    "        except Exception as e:\n",
    "            raise e\n",
    "    \n",
    "    def getTokenExpirationDate(self, label, whom):\n",
    "        if not isinstance(label,str):\n",
    "            raise RuntimeError(\"you must provide a valid label\")\n",
    "        if not isinstance(whom,str):\n",
    "            raise RuntimeError(\"you must provide a valid label\")\n",
    "        try:\n",
    "            response = self.get(\"/token/%s/%s/tokenExpirationDate\" %(label, whom))\n",
    "            if response[\"code\"]==206:\n",
    "                response['date'] = jsonpickle.loads(response['date'])\n",
    "                return response\n",
    "            elif response[\"code\"]==312:\n",
    "                return response\n",
    "            else:\n",
    "                raise APIResponseError(\"%d:%s\" % (response[\"code\"],response[\"status\"]))\n",
    "        except Exception as e:\n",
    "            raise e\n",
    "    \n",
    "    def tokenExpiration(self, label, whom=None):\n",
    "        if not isinstance(label,str):\n",
    "            raise RuntimeError(\"you must provide a valid label\")\n",
    "        if not isinstance(whom,(str,type(None))):\n",
    "            raise RuntimeError(\"you must provide a valid label\")\n",
    "        try:\n",
    "            response = self.get(\"/token/%s/%s/tokenExpiration\" % (label, whom))\n",
    "            if response[\"code\"]==206:\n",
    "                response['token_status'] = jsonpickle.loads(response['token_status'])\n",
    "                return response\n",
    "            elif response[\"code\"]==312 or response[\"code\"]==313:\n",
    "                return response\n",
    "            else:\n",
    "                raise APIResponseError(\"%d:%s\" % (response[\"code\"],response[\"status\"]))\n",
    "        except Exception as e:\n",
    "            raise e\n",
    "            \n",
    "    def getCredential(self, label, token=None, whom=None): # NUEVA\n",
    "        if not isinstance(label,str):\n",
    "            raise RuntimeError(\"you must provide a valid label\")\n",
    "        if not isinstance(token,(str,type(None))):\n",
    "            raise RuntimeError(\"you must provide a valid token\")\n",
    "        if not isinstance(whom,(str,type(None))):\n",
    "            raise RuntimeError(\"you must provide a valid argument\")\n",
    "        try:\n",
    "            response = self.get(\"/credential/%s/%s/%s/getRegisterCredential\" % (label, token, whom))\n",
    "            if response[\"code\"]==205:\n",
    "                #credential = Credential.deserialize(response['credential'])\n",
    "                credential = jsonpickle.loads(response['credential'])\n",
    "                response['credential'] = credential\n",
    "                return response\n",
    "            elif response[\"code\"]==312:\n",
    "                return response\n",
    "            else:\n",
    "                raise APIResponseError(\"%d:%s\" % (response[\"code\"],response[\"status\"]))\n",
    "\n",
    "        except Exception as e:\n",
    "            raise e\n",
    "            \n",
    "    def putInPersistentDict(self, dict_name, key, value):\n",
    "        post_data = {\n",
    "            \"key\"   : key,\n",
    "            \"value\" : value\n",
    "        }\n",
    "        try:\n",
    "            response = self.post(\"/pd/%s/put\" % dict_name, json=post_data)\n",
    "            if response[\"code\"]==200:\n",
    "                return response\n",
    "            else:\n",
    "                raise APIResponseError(\"%d:%s\" % (response[\"code\"],response[\"status\"]))\n",
    "        except Exception as e:\n",
    "            raise e\n",
    "\n",
    "    def getFromPersistentDict(self, dict_name, key):\n",
    "        try:\n",
    "            response = self.get(\"/pd/%s/get/%s\" % (dict_name,key))\n",
    "            if response[\"code\"]==200:\n",
    "                return response\n",
    "            else:\n",
    "                raise APIResponseError(\"%d:%s\" % (response[\"code\"],response[\"status\"]))\n",
    "        except Exception as e:\n",
    "            raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-18T20:33:31.854224Z",
     "start_time": "2024-04-18T20:33:31.790810Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "%%deploy /orch/api/__init__.py\n",
    "\n",
    "from .Execution import *\n",
    "from .Pipeline import *\n",
    "from .ScheduledEvent import *\n",
    "from .RemoteProcedureNotification import *\n",
    "from .Orchestrator import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-18T20:33:31.919319Z",
     "start_time": "2024-04-18T20:33:31.855953Z"
    }
   },
   "outputs": [],
   "source": [
    "raise StopExecution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-18T17:19:40.681861Z",
     "start_time": "2024-04-18T17:19:40.672929Z"
    }
   },
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-18T03:34:16.593960Z",
     "start_time": "2021-04-18T03:34:16.582776Z"
    },
    "heading_collapsed": true
   },
   "source": [
    "## Use case for OrchestratorManager (service side)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-18T20:33:31.923953Z",
     "start_time": "2024-04-18T20:33:31.923938Z"
    },
    "code_folding": [
     4
    ],
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import time\n",
    "from datetime import datetime, timedelta\n",
    "from orch.orchestrator import OrchestratorManager\n",
    "\n",
    "smtp_crd = {\n",
    "    \"sender\":\"\",\n",
    "    \"smtp_host\":\"\",\n",
    "    \"username\":\"\",\n",
    "    \"password\":\"\"\n",
    "}\n",
    "\n",
    "om = OrchestratorManager(smtp_crd=smtp_crd)\n",
    "#orch_access = om"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-18T20:33:31.925404Z",
     "start_time": "2024-04-18T20:33:31.925389Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "om.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-28T03:42:15.653570Z",
     "start_time": "2022-12-28T03:42:15.636052Z"
    },
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### get executions by tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-18T20:33:31.926667Z",
     "start_time": "2024-04-18T20:33:31.926651Z"
    },
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "exl = om.getExecutionsBy(\"start_ts>='2022-07-08 02:00:00'\")\n",
    "print(len(exl))\n",
    "for ex in exl:\n",
    "    print(ex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-18T20:33:31.927910Z",
     "start_time": "2024-04-18T20:33:31.927895Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "exl = om.getExecutionsBy(\"state=6\")\n",
    "print(len(exl))\n",
    "for ex in exl:\n",
    "    print(ex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-18T20:33:31.929302Z",
     "start_time": "2024-04-18T20:33:31.929285Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    om.cancelExecution(\"12b738c2-b79c-47ba-a5a4-b858954af430\")\n",
    "except Exception as e:\n",
    "    print(type(e),e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-18T20:33:31.930507Z",
     "start_time": "2024-04-18T20:33:31.930491Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "exl = om.getRunningExecutions()\n",
    "print(len(exl))\n",
    "for ex in exl:\n",
    "    print(ex)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-11T22:54:01.728811Z",
     "start_time": "2022-05-11T22:54:01.710104Z"
    },
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Notification tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-18T20:33:31.931824Z",
     "start_time": "2024-04-18T20:33:31.931809Z"
    },
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# test RemoteProcedureNotification methods\n",
    "\n",
    "n = om.createNotification(\"testssss\")\n",
    "print(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-18T20:33:31.932984Z",
     "start_time": "2024-04-18T20:33:31.932970Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "print(om.getLastNotification(\"test\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-18T20:33:31.934083Z",
     "start_time": "2024-04-18T20:33:31.934069Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "print(om.getNotificationList(\"testssss\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-11T22:54:01.708838Z",
     "start_time": "2022-05-11T22:54:01.693304Z"
    },
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Test a function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-18T20:33:31.935490Z",
     "start_time": "2024-04-18T20:33:31.935474Z"
    },
    "code_folding": [],
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# create a pipeline \n",
    "\n",
    "def test_pipeline(*args, **kw_args):\n",
    "    global orch_access\n",
    "        \n",
    "    orch_access.addVariable(\"my_var\",\"my value\")\n",
    "    \n",
    "    print(\"this is the execution of a test pipeline\")\n",
    "    \n",
    "    report = \"this is a test report:<br>\"\n",
    "    \n",
    "    orch_access.setReport(report)\n",
    "    orch_access.notifyExecution([\"\"])\n",
    "        \n",
    "    time.sleep(30)\n",
    "        \n",
    "    return {\"return value\":\"blabla\"}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-18T20:33:31.936910Z",
     "start_time": "2024-04-18T20:33:31.936895Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# register the function in the orchestrator\n",
    "\n",
    "om.register(\"test_pipeline\",test_pipeline, new_version=True)\n",
    "\n",
    "# get the registered pipeline \n",
    "pipeline = om.getPipelines(\"test_pipeline\")[-1]\n",
    "print(pipeline)\n",
    "om.activatePipeline(pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-18T20:33:31.938099Z",
     "start_time": "2024-04-18T20:33:31.938083Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# get the registered pipeline \n",
    "pipeline = om.getPipelines(\"test_pipeline\")[-1]\n",
    "print(pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-18T20:33:31.939590Z",
     "start_time": "2024-04-18T20:33:31.939574Z"
    },
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# manual execution of the pipeline\n",
    "exec_obj = om.execute(pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-18T20:33:31.940886Z",
     "start_time": "2024-04-18T20:33:31.940870Z"
    },
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# check the results of the execution\n",
    "print(exec_obj)\n",
    "print(exec_obj.getOutput())\n",
    "print(exec_obj.getErrors())\n",
    "result = exec_obj.getReturnValue()\n",
    "display(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-18T20:33:31.942115Z",
     "start_time": "2024-04-18T20:33:31.942099Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# trigger the manual execution and then cancel it\n",
    "pipeline = om.getPipelines(\"test_pipeline\")[-1]\n",
    "\n",
    "exec_obj = om.execute(pipeline)\n",
    "\n",
    "print(\"sleeping 15s before cancelling\")\n",
    "time.sleep(1)\n",
    "exec_obj.cancel()\n",
    "print(\"sleeping 2s after cancelation\")\n",
    "time.sleep(2)\n",
    "print(exec_obj)\n",
    "print(exec_obj.getOutput())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-18T20:33:31.943271Z",
     "start_time": "2024-04-18T20:33:31.943256Z"
    },
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(exec_obj)\n",
    "print(exec_obj.getOutput())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-18T20:33:31.944387Z",
     "start_time": "2024-04-18T20:33:31.944373Z"
    },
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for execution in om.getExecutionList(\"test_pipeline\"):\n",
    "    print(execution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-18T20:33:31.945888Z",
     "start_time": "2024-04-18T20:33:31.945872Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for execution in pipeline.getExecutions():\n",
    "    print(execution.getOutput())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-18T20:33:31.947130Z",
     "start_time": "2024-04-18T20:33:31.947114Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "trigger_time = (datetime.now() + timedelta(seconds=10)).strftime(\"%H:%M:%S\")\n",
    "print(trigger_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-18T20:33:31.948505Z",
     "start_time": "2024-04-18T20:33:31.948489Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "trigger_time = (datetime.now() + timedelta(seconds=10)).strftime(\"%H:%M:%S\")\n",
    "\n",
    "recurrency = \"1m\" # seconds\n",
    "\n",
    "my_pipeline = om.getActivePipeline(\"test_pipeline\")\n",
    "print(my_pipeline)\n",
    "\n",
    "my_pipeline.setArguments( (\"arg1\",\"arg2\") )\n",
    "\n",
    "if om.scheduleAt(my_pipeline, trigger_time=trigger_time, recurrency=recurrency):\n",
    "    print(\"pipeline scheduled at %s with recurrency at %s\" % (trigger_time, recurrency))\n",
    "else:\n",
    "    print(\"pipeline not scheduled\")\n",
    "\n",
    "scheduled_executions = om.getScheduledExecutions(my_pipeline)\n",
    "print(\"scheduled executions for my_pipeline\")\n",
    "for sch_exec in scheduled_executions:\n",
    "    print(sch_exec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-18T20:33:31.949708Z",
     "start_time": "2024-04-18T20:33:31.949684Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "sch_lst = om.getScheduledExecutions(my_pipeline)\n",
    "print(sch_lst)\n",
    "\n",
    "sch_evt = sch_lst[-1]\n",
    "print(sch_evt)\n",
    "\n",
    "om.cancelScheduledExecution(sch_evt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-18T20:33:31.950905Z",
     "start_time": "2024-04-18T20:33:31.950891Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "scheduled_executions = om.getScheduledExecutions(my_pipeline)\n",
    "print(\"scheduled executions for my_pipeline\")\n",
    "for sch_exec in scheduled_executions:\n",
    "    print(sch_exec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-18T20:33:31.952076Z",
     "start_time": "2024-04-18T20:33:31.952059Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "for execution in my_pipeline.getExecutions():\n",
    "    print(execution)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-18T20:33:31.953407Z",
     "start_time": "2024-04-18T20:33:31.953392Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "sch_lst = om.getScheduledExecutions(my_pipeline)\n",
    "print(sch_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-18T20:33:31.954614Z",
     "start_time": "2024-04-18T20:33:31.954598Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "om.stop()\n",
    "\n",
    "raise StopExecution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-18T06:21:31.401987Z",
     "start_time": "2021-04-18T06:21:31.387782Z"
    },
    "hidden": true
   },
   "source": [
    "### PipelineManager usage via Orchestrator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-18T20:33:31.955981Z",
     "start_time": "2024-04-18T20:33:31.955966Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "my_pipeline = om.getActivePipeline(\"test_pipeline\")\n",
    "print(my_pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-18T20:33:31.957153Z",
     "start_time": "2024-04-18T20:33:31.957138Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# execute a pipeline correctly \n",
    "executor = om.execute(my_pipeline,1,2,3)\n",
    "while executor.isPreparing() or executor.isRunning():\n",
    "    print(\"execution state:\",executor.state)\n",
    "    time.sleep(1)\n",
    "print(\"execution done. final state:\",executor.state)\n",
    "print(executor.getOutput())\n",
    "print(executor.getErrors())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-18T20:33:31.958629Z",
     "start_time": "2024-04-18T20:33:31.958604Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# execute a pipeline with less arguments\n",
    "executor = om.execute(my_pipeline,1,2)\n",
    "while executor.isPreparing() or executor.isRunning():\n",
    "    print(\"execution state:\",executor.state)\n",
    "    time.sleep(1)\n",
    "print(\"execution done. final state:\",executor.state)\n",
    "print(executor.getOutput())\n",
    "print(executor.getErrors())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-18T20:33:31.960360Z",
     "start_time": "2024-04-18T20:33:31.960332Z"
    },
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "execution_list = om.getExecutionList(\"test_pipeline\")\n",
    "for execution in execution_list:\n",
    "    print(execution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-18T20:33:31.961700Z",
     "start_time": "2024-04-18T20:33:31.961684Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# execute a non-active pipeline\n",
    "# the method getPipelines returns a list, that why we get the elements 0 from the list to get the pipeline object directly\n",
    "\n",
    "my_pipeline_v1 = om.getPipelines(\"test_pipeline\", version=1)[0]\n",
    "print(my_pipeline_v1)\n",
    "\n",
    "executor_v1 = om.execute(my_pipeline_v1,10,20)\n",
    "while executor_v1.isPreparing() or executor_v1.isRunning():\n",
    "    print(\"execution state:\",executor_v1.state)\n",
    "    time.sleep(1)\n",
    "print(\"execution done. final state:\",executor_v1.state)\n",
    "print(executor_v1.getOutput())\n",
    "print(executor_v1.getErrors())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-18T20:33:31.962869Z",
     "start_time": "2024-04-18T20:33:31.962853Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "raise StopExecution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-18T20:33:31.963968Z",
     "start_time": "2024-04-18T20:33:31.963953Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "om.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-03T03:17:10.084940Z",
     "start_time": "2021-04-03T03:17:10.082681Z"
    }
   },
   "source": [
    "## Use case of Orchestrator API (client side)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-18T20:33:31.965408Z",
     "start_time": "2024-04-18T20:33:31.965388Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from orch.orchestrator import *\n",
    "\n",
    "orch_srv = OrchestratorService(db_conn_str=\"sqlite:///orchestrator.sqlite\")\n",
    "orch_srv.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-18T20:33:31.966585Z",
     "start_time": "2024-04-18T20:33:31.966570Z"
    }
   },
   "outputs": [],
   "source": [
    "orch_srv.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-03T05:22:24.387324Z",
     "start_time": "2021-04-03T05:22:24.385073Z"
    }
   },
   "source": [
    "### status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-18T20:33:31.967851Z",
     "start_time": "2024-04-18T20:33:31.967827Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from orch.api import Orchestrator\n",
    "from datetime import timedelta\n",
    "orch = Orchestrator()\n",
    "print(orch.status())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-28T05:48:06.931299Z",
     "start_time": "2022-12-28T05:48:06.914799Z"
    }
   },
   "source": [
    "### test getting running executions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-18T20:33:31.969201Z",
     "start_time": "2024-04-18T20:33:31.969185Z"
    }
   },
   "outputs": [],
   "source": [
    "exl = orch.getRunningExecutions()\n",
    "print(exl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-28T05:50:56.977768Z",
     "start_time": "2022-12-28T05:50:56.960428Z"
    }
   },
   "source": [
    "### test getting executions by"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-18T20:33:31.970302Z",
     "start_time": "2024-04-18T20:33:31.970287Z"
    }
   },
   "outputs": [],
   "source": [
    "exl = orch.getExecutionsBy(\"state=6\")\n",
    "print(exl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-23T03:53:21.806610Z",
     "start_time": "2021-05-23T03:53:21.792977Z"
    }
   },
   "source": [
    "### test stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-18T20:33:31.971397Z",
     "start_time": "2024-04-18T20:33:31.971383Z"
    }
   },
   "outputs": [],
   "source": [
    "orch.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-18T04:09:26.551615Z",
     "start_time": "2021-07-18T04:09:26.537147Z"
    }
   },
   "source": [
    "### create notification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-18T20:33:31.972598Z",
     "start_time": "2024-04-18T20:33:31.972583Z"
    }
   },
   "outputs": [],
   "source": [
    "rpn = orch.createNotification(\"my_rpn\",data={\"p1\":10,\"p2\":\"ddfdfdf\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-18T20:33:31.973413Z",
     "start_time": "2024-04-18T20:33:31.973399Z"
    }
   },
   "outputs": [],
   "source": [
    "print(rpn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-18T20:33:31.974806Z",
     "start_time": "2024-04-18T20:33:31.974790Z"
    }
   },
   "outputs": [],
   "source": [
    "rpn = orch.createNotification(\"test_notification\",data={\"triggers\": [\"test_pipeline\"]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-18T20:33:31.976132Z",
     "start_time": "2024-04-18T20:33:31.976117Z"
    }
   },
   "outputs": [],
   "source": [
    "print(rpn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-18T04:43:57.981568Z",
     "start_time": "2021-07-18T04:43:57.966537Z"
    }
   },
   "source": [
    "### create notification via direct api call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-18T20:33:31.977651Z",
     "start_time": "2024-04-18T20:33:31.977635Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "url=\"http://localhost:8020/rpn/my_direct_rpn/notify?p1=23&p2=sdfsdfsd\"\n",
    "\n",
    "r = requests.get(url)\n",
    "print(r.json())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-18T04:28:14.209827Z",
     "start_time": "2021-07-18T04:28:14.195528Z"
    }
   },
   "source": [
    "### get last notification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-18T20:33:31.978621Z",
     "start_time": "2024-04-18T20:33:31.978606Z"
    }
   },
   "outputs": [],
   "source": [
    "last_rpn = orch.getLastNotification(\"my_direct_rpn\")\n",
    "print(last_rpn)\n",
    "print(last_rpn.getData())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-18T20:33:31.980046Z",
     "start_time": "2024-04-18T20:33:31.980031Z"
    }
   },
   "outputs": [],
   "source": [
    "last_rpn = orch.getLastNotification(\"my_rpn\")\n",
    "print(last_rpn)\n",
    "print(last_rpn.getData())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-18T04:33:44.310457Z",
     "start_time": "2021-07-18T04:33:44.296611Z"
    }
   },
   "source": [
    "### get notification list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-18T20:33:31.981131Z",
     "start_time": "2024-04-18T20:33:31.981117Z"
    }
   },
   "outputs": [],
   "source": [
    "rpn_list = orch.getNotificationList(\"my_rpn\")\n",
    "print(rpn_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-24T02:54:29.222844Z",
     "start_time": "2021-05-24T02:54:29.208867Z"
    }
   },
   "source": [
    "### registration of a test pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-18T20:33:31.982255Z",
     "start_time": "2024-04-18T20:33:31.982241Z"
    }
   },
   "outputs": [],
   "source": [
    "import base64\n",
    "\n",
    "register=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-18T20:33:31.983268Z",
     "start_time": "2024-04-18T20:33:31.983254Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "if register:\n",
    "    def test_pipeline(arg1,arg2):\n",
    "        import time\n",
    "        print(\"this is a test pipeline\")\n",
    "        print(\"arg1:\",arg1)\n",
    "        print(\"arg2:\",arg2)\n",
    "        count = 0\n",
    "        for i in range(0,30):\n",
    "            count+=1\n",
    "            time.sleep(1)\n",
    "        return count\n",
    "      \n",
    "    print(orch.register(\"test_pipeline\",test_pipeline))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-18T20:33:31.984453Z",
     "start_time": "2024-04-18T20:33:31.984437Z"
    }
   },
   "outputs": [],
   "source": [
    "# register a second version of the test_pipeline\n",
    "if register:\n",
    "    def test_pipeline(arg1,arg2,arg3):\n",
    "        import time\n",
    "        print(\"this is a test pipeline version 2\")\n",
    "        print(\"arg1:\",arg1)\n",
    "        print(\"arg2:\",arg2)\n",
    "        print(\"arg3:\",arg3)\n",
    "        count = 0\n",
    "        for i in range(0,30):\n",
    "            count+=1\n",
    "            time.sleep(1)\n",
    "        return count\n",
    "      \n",
    "    print(orch.register(\"test_pipeline\",test_pipeline, new_version=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-24T03:06:28.367103Z",
     "start_time": "2021-05-24T03:06:28.353425Z"
    }
   },
   "source": [
    "### manual execution of a pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-18T20:33:31.985715Z",
     "start_time": "2024-04-18T20:33:31.985699Z"
    }
   },
   "outputs": [],
   "source": [
    "# execute once the version 1 of my_pipeline\n",
    "\n",
    "test_pipelines = orch.getPipelines(\"test_pipeline\")\n",
    "for p in test_pipelines:\n",
    "    print(p)\n",
    "\n",
    "test_pipeline_v1 = orch.getPipelines(\"test_pipeline\",version=1)[0]\n",
    "print(test_pipeline_v1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-18T20:33:31.987482Z",
     "start_time": "2024-04-18T20:33:31.987467Z"
    }
   },
   "outputs": [],
   "source": [
    "last_exec_id = orch.execute(test_pipeline_v1, 10, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-18T20:33:31.988786Z",
     "start_time": "2024-04-18T20:33:31.988771Z"
    }
   },
   "outputs": [],
   "source": [
    "last_exec = orch.getLastExecution(\"test_pipeline\")\n",
    "print(last_exec)\n",
    "\n",
    "print(last_exec.getOutput())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-16T18:21:47.394296Z",
     "start_time": "2022-05-16T18:21:47.377722Z"
    }
   },
   "source": [
    "### test cancel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-18T20:33:31.989945Z",
     "start_time": "2024-04-18T20:33:31.989930Z"
    }
   },
   "outputs": [],
   "source": [
    "last_exec = orch.getLastExecution(\"test_pipeline\")\n",
    "exec_id = last_exec.uuid\n",
    "\n",
    "orch.cancelExecution(exec_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-23T03:54:03.279361Z",
     "start_time": "2021-05-23T03:54:03.265706Z"
    }
   },
   "source": [
    "### test pipeline schedule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-18T20:33:31.991095Z",
     "start_time": "2024-04-18T20:33:31.991081Z"
    },
    "code_folding": [],
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import time\n",
    "\n",
    "# execute once the version 1 of my_pipeline\n",
    "test_pipeline_v1 = orch.getPipelines(\"test_pipeline\",version=1)[0]\n",
    "print(test_pipeline_v1)\n",
    "\n",
    "if orch.activatePipeline(test_pipeline_v1):\n",
    "    print(\"pipeline activated\")\n",
    "else:\n",
    "    print(\"pipeline not active\")\n",
    "\n",
    "test_pipeline = orch.getActivePipeline(\"test_pipeline\")\n",
    "print(test_pipeline)\n",
    "\n",
    "# set pipeline arguments to schedule execution\n",
    "test_pipeline.setArguments( (1,2) )\n",
    "\n",
    "# trigger the pipeline in 10 seconds\n",
    "trigger_time = (datetime.now() + timedelta(seconds=10)).strftime(\"%H:%M:%S\")\n",
    "\n",
    "if orch.scheduleAt(test_pipeline, trigger_time=trigger_time):\n",
    "    print(\"pipeline scheduled at\",trigger_time)\n",
    "else:\n",
    "    print(\"pipeline not scheduled\")\n",
    "\n",
    "print(\"waiting for pipelie to be triggered\")\n",
    "time.sleep(14)\n",
    "\n",
    "print(\"execution list for my_pipeline\")\n",
    "last_exec = orch.getLastExecution(\"test_pipeline\")\n",
    "\n",
    "print(last_exec)\n",
    "\n",
    "while not last_exec.isDone():\n",
    "    print(\"waiting for pipeline execution to finish. state\",last_exec.state)\n",
    "    # at the api we need to update last_exec in order to realize when execution is done\n",
    "    # at manager, the state is automaticaly refreshed by the ORM, then, no need to refresh last_exec\n",
    "    last_exec = orch.getLastExecution(\"test_pipeline\")\n",
    "    time.sleep(5)\n",
    "\n",
    "print(\"pipeline execution done\")\n",
    "    \n",
    "print(last_exec)\n",
    "\n",
    "print(last_exec.getOutput())\n",
    "print(last_exec.getErrors())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-24T02:59:30.153005Z",
     "start_time": "2021-05-24T02:59:30.138837Z"
    }
   },
   "source": [
    "### test get last execution and output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-18T20:33:31.992199Z",
     "start_time": "2024-04-18T20:33:31.992185Z"
    }
   },
   "outputs": [],
   "source": [
    "my_pipeline_v1 = orch.getPipelines(\"test_pipeline\",version=1)[-1]\n",
    "last_exec = orch.getLastExecution(\"test_pipeline\")\n",
    "print(last_exec)\n",
    "print(last_exec.getOutput())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-18T20:33:31.993143Z",
     "start_time": "2024-04-18T20:33:31.993128Z"
    },
    "code_folding": [],
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# activate my_pipeline version 2 and execute it via scheduler\n",
    "test_pipeline_v2 = orch.getPipelines(\"test_pipeline\",version=2)[0]\n",
    "print(test_pipeline_v2)\n",
    "\n",
    "if orch.activatePipeline(test_pipeline_v2):\n",
    "    print(\"pipeline activated\")\n",
    "else:\n",
    "    print(\"pipeline not active\")\n",
    "    \n",
    "trigger_time = (datetime.now() + timedelta(seconds=10)).strftime(\"%H:%M:%S\")\n",
    "\n",
    "test_pipeline = orch.getActivePipeline(\"test_pipeline\")\n",
    "print(test_pipeline)\n",
    "\n",
    "test_pipeline.setArguments( (1,2,3) )\n",
    "\n",
    "if orch.scheduleAt(test_pipeline, trigger_time=trigger_time):\n",
    "    print(\"pipeline scheduled at\",trigger_time)\n",
    "else:\n",
    "    print(\"pipeline not scheduled\")\n",
    "\n",
    "# wait for pipeline to begin its scheduled execution\n",
    "time.sleep(11)\n",
    "    \n",
    "print(\"execution list for my_pipeline\")\n",
    "last_exec = orch.getLastExecution(\"test_pipeline\")\n",
    "\n",
    "while not last_exec.isDone():\n",
    "    print(\"waiting for pipeline execution to finish. state\",last_exec.state)\n",
    "    last_exec = orch.getLastExecution(\"test_pipeline\")\n",
    "    time.sleep(5)\n",
    "\n",
    "print(\"pipeline execution done\")\n",
    "    \n",
    "print(last_exec)\n",
    "\n",
    "print(last_exec.getOutput())\n",
    "print(last_exec.getErrors())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-18T20:33:31.994390Z",
     "start_time": "2024-04-18T20:33:31.994376Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# schedule a recurrent execution, execute the pipeline twice and then cancel the execution\n",
    "\n",
    "test_pipeline_v2 = orch.getPipelines(\"test_pipeline\",version=3)[0]\n",
    "print(test_pipeline_v2)\n",
    "\n",
    "if orch.activatePipeline(test_pipeline_v2):\n",
    "    print(\"pipeline activated\")\n",
    "else:\n",
    "    print(\"pipeline not active\")\n",
    "    \n",
    "trigger_time = (datetime.now() + timedelta(seconds=10)).strftime(\"%H:%M:%S\")\n",
    "\n",
    "recurrency = \"20s\" # seconds\n",
    "\n",
    "test_pipeline = orch.getActivePipeline(\"test_pipeline\")\n",
    "print(test_pipeline)\n",
    "\n",
    "test_pipeline.setArguments( (1,2,3) )\n",
    "\n",
    "if orch.scheduleAt(test_pipeline, trigger_time=trigger_time, recurrency=recurrency):\n",
    "    print(\"pipeline scheduled at %s with recurrency at %s\" % (trigger_time, recurrency))\n",
    "else:\n",
    "    print(\"pipeline not scheduled\")\n",
    "\n",
    "scheduled_executions = orch.getScheduledExecutions(test_pipeline)\n",
    "print(\"scheduled executions for my_pipeline\")\n",
    "for sch_exec in scheduled_executions:\n",
    "    print(sch_exec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-18T20:33:31.995489Z",
     "start_time": "2024-04-18T20:33:31.995474Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# wait for pipeline to begin its scheduled execution\n",
    "time.sleep(11)\n",
    "\n",
    "execution_times = 2\n",
    "\n",
    "for t in range(0,execution_times):\n",
    "    last_exec = orch.getLastExecution(\"test_pipeline\")\n",
    "    print(\"last execution for my_pipeline at time %d\" % t)\n",
    "    print(last_exec)\n",
    "    \n",
    "    while not last_exec.isDone():\n",
    "        print(\"waiting for pipeline execution to finish. state\",last_exec.state)\n",
    "        time.sleep(5)\n",
    "        last_exec = orch.getLastExecution(\"test_pipeline\")\n",
    "\n",
    "    print(\"pipeline execution done\")\n",
    "    time.sleep(16)\n",
    "    print(\"sleep ends\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-18T20:33:31.996771Z",
     "start_time": "2024-04-18T20:33:31.996757Z"
    }
   },
   "outputs": [],
   "source": [
    "test_pipeline = orch.getActivePipeline(\"test_pipeline\")\n",
    "print(test_pipeline)\n",
    "scheduled_executions = orch.getScheduledExecutions(test_pipeline)\n",
    "for scex in scheduled_executions:\n",
    "    print(scex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-18T20:33:31.998030Z",
     "start_time": "2024-04-18T20:33:31.998014Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# cancel the execution\n",
    "if orch.cancelScheduledExecution(scheduled_executions[-1]):\n",
    "    sch_evt = orch.getScheduledExecutionById(scheduled_executions[-1].uuid)\n",
    "    print(\"%s cancelled\" % sch_evt)\n",
    "\n",
    "scheduled_executions = orch.getScheduledExecutions(test_pipeline)\n",
    "print(\"scheduled executions for my_pipeline\")\n",
    "for sch_exec in scheduled_executions:\n",
    "    print(sch_exec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-18T20:33:31.999196Z",
     "start_time": "2024-04-18T20:33:31.999181Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "orch_srv.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-02T04:48:14.771016Z",
     "start_time": "2021-05-02T04:48:14.756625Z"
    }
   },
   "source": [
    "# END"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
